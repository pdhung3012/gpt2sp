issuekey,title,description,storypoint,raw predictions
DM-5869,Assessment of current state-of-the-stack diffim implementation,"The existing diffim implementation in the stack defaults to the (2000) version of the Alard/Lupton algorithm. Other recent improvements such as ""pre-convolution"", delta-function basis, model selection via BIC, others, seem to be implemented but are not turned on. We need a good understanding of the existing implementation so we can assess how straightforward it is to implement the ZOGY algorithm in real-space in the stack.",6,5.852687
DM-5870,Update testdata_subaru to support calib changes,Merging DM-5124 broke obs_subaru because the test data in testdata_subaru wasn't updated.  Fix it.,1,1.1651202
DM-5872,"Incorporate ""Bickerton algorithm"" for detecting & masking satellite trails","In [HSC-1272|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1272], [~bick] proposed an algorithm for detecting and masking satellite trails. This has undergone some review on HSC, but has never been incorporated into an HSC software or data release (and hence is not part of the ""HSC port"").    However: the algorithm is certainly relevant to LSST. Please convert it to work with the LSST stack.",5,4.630018
DM-5874,Produce document describing flavors of coadds,"[~zivezic] has requested a description of the different flavors of coadds, and the tradeoffs between the more experimental optimal coadds and the non-optimal standard ones.    I'll try to do this as both a presentation for the DMLT and a DMTN (with essentially the same content).    This will include a bit of toy-model simulation work to try to predict some of the tradeoffs; this could make the discussion quite a bit more quantitative and I have an idea for how to do it that is pretty easy.",10,2.8375971
DM-5875,Propose text for alternate galaxy models in DPDD,Write a paragraph or two describing alternatives to the constrained bulge+disk model currently in the DPDD.,1,2.8863475
DM-5877,Use Afterburners to clean up aperture correction logic,"This issue has several components; I'm combining them into a single issue because they need to be done atomically:   - Rewrite the base_ClassificationExtendedness SingleFramePlugin/ForcedPlugin as an AfterburnerPlugin (and remove the old versions).   - Move the ""applyApCorr"" subtask out of SingleFrameMeasurementTask and ForcedMeasurementTask, making it instead a subclass of their parent Tasks.   - Add afterburner subtask stages to ProcessCcdTask (within DetectAndMeasureTask) and the multiband tasks wherever measurement is currently being run.  The afterburner tasks should be run after aperture corrections are measured and/or applied.    After these changes, throughout the stack, whenever a MeasurementTask is run, we also run ApplyApCorrTask and AfterburnerTask (in that order), while possibly running MeasureApCorrTask immediately after the MeasurementTask.    This may or may not enable significant cleanups in DetectAndMeasureTask (I haven't looked closely).  If so, they should be done on this issue.    Given all the moving parts, it's important to check that the actual behavior of the pipeline (in the aperture correction and extendedness values) does not change, so it might be useful to start by creating some reference outputs to compare against.",6,2.8929405
DM-5878,Add chi plots to validate_drp output to compare nominal error,"Make histograms of Deltas / nominal error.    where ""nominal"" error is that reported by the pipeline.    Are they distributed with a sigma=1?",2,0.8734413
DM-5879,Remove use of Boost smart pointers throughout the Science Pipelines,Replace all use of Boost smart pointers through the stack with their standard library equivalents.    This will require an RFC.,10,4.896053
DM-5880,Audit use of Boost in the stack and remove it where possible,"Consider use of Boost in the stack, and investigate where it can be eliminated by using std library equivalents. Create tickets to remove it, then work on them.",10,1.7985682
DM-5881,Recover from processCcd refactor,"Now that DM-5771 is closed and processCcd runs again, get back to the point where the things are not just not crashing but are actually working correctly (given that this is a non-standard use-case).",10,3.4902656
DM-5884,Create MySQL account for monitoring,A MySQL account needs to be created in configuration procedure and on existing data on IN2P3 cluster in order to enable ELK access. MySQL password/secret has to be shared accross all containers.,4,2.7797718
DM-5885,Create a JSON file for monitoring stack,"Create a JSON or YAML file with:    - Qserv version  - libraries/deps version  - other idea welcome    This will interesting ""GROUP BY"" in monitoring tool (performance for each Qserv or xrootd version for example)",3,1.8939545
DM-5886,Provide ngmix-based MCMC galaxy fitting,"DM-2250 provided for ""simple"" fitting of galaxies in single frame measurement using ngmix. Extend this to fit galaxies using ngmix's MCMC sampling facilities. This may include defining a mechanism to store MCMC samples in source records.    This should be available through (an) lsst_apps (or _distrib) based meas_extension package(s).",60,2.701969
DM-5889,"Suppress gcc warnings about ""unused local typedefs""","We should add {{\-Wno\-unused\-local\-typedefs}} to our gcc options.  This cleans up the build significantly, because there's a flood of warnings of this type coming from boost.  If we suppress those, it might become possible to notice warnings that we care about.",1,2.583232
DM-5893,LSST the Docs Fastly should redirect /en/latest/ to /,"Previously we deployed documentation on Read the Docs. By default, Read the Docs would show the master version of documentation on ""/en/latest/"". Many links with that endpoint may already exist. We should configure Fastly to redirect such paths to ""/"".",1,2.4179177
DM-5894,LSST the Docs Fastly Courtesy Redirects for directory paths,Currently if a user browses {{example.lsst.io/v/main/some-directory}} instead of {{example.lsst.io/v/main/some-directory}} they will receive an error.    We should develop a scheme where Fastly can detect that such a path is a directory and redirect to the directory's index.html page.,4,1.7875755
DM-5897,Robustify coadd,"In running the processing from the Twinkles data challenge in DESC we found that it was very easy to use the wrong skymap when making a coadd.  Since the coadd code doesn't even make a cursory check that the coordinate system it is using is the same as that of the coaddTempExps, it is very possible to mess this up.    Adding a check that the coadd WCS is that of each input tempCoaddExp is would solve this.",2,3.0472565
DM-5898,Python EUPS package can use $PYTHON,The {{python}} eups package has a script that checks that the python being used is version 2.7. This script can optionally check {{$PYTHON}} rather than the python in the path but I am confused as to what that test is going to do for us. The problem is that {{sconsUtils}} uses {{python}} and most of the shebangs use {{/bin/env python}} (although shebang rewriting on all platforms could help with that). I think the check script should have the {{$PYTHON}} support removed due to excessive confusion.    It would also help if the check script worked with python 3 so that the wrong python could be caught.,1,2.2253904
DM-5900,Create psutil EUPS package,Add the python {{psutil}} package to the stack as {{python_psutil}}.,1,1.6349008
DM-5901,LTD Keeper: More Robust Edition purges,LTD Keeper needs to purge Fastly when an Edition is rebuilt. Currently the surrogate-key for the build is also used to cover editions. This means that the key needed to purge an edition is the same as that for an build. Hence purging an edition means that the system needs to purge the surrogate key of the previous build.    We're seeing situations where the surrogate key that Keeper is purging is not the one that needs to be purged. A more robust configuration would be for each edition to have a stable surrogate-key that can be unambiguously purged.    This ticket covers the following work:    # Diagnose the issue.  # Enable Alembic migrations for Flask (Flask-Migrate)  # Add a surrogate-key column to the Edition model  # Change the S3 copy rebuild code to change the surrogate-key header  # Change the rebuild code to purge based on the edition's surrogate-key.,3,3.5387726
DM-5903,Finish technical note on galaxy shear experiments,"In the review of DM-5447 we decided it made sense for [~jbosch] to take over finishing the technote, in particular providing an introduction and concluion with more context.",4,5.3181467
DM-5904,Create focus script,"In DM-3368, we stripped out the focus calculation since it's not camera-generic, and the scatter/gather isn't necessary for general processing.  We need to reinstate the focus calculation in its own scatter/gather script.",2,1.3794214
DM-5905,Refactor DipoleFitPlugin classification into separate Classification plugin,"Currently the new DipoleFitPlugin runs measurement and then classification from a single measurement method. The classification should be moved out to a separate plugin. This will require more information be stored in the measRecord, in order to do the classification separately. Given that complication, evaluate whether this is even worthwhile.",6,5.0106587
DM-5906,Remove qmeta::QueryId and use global qserv::QueryId,Remove the qmeta::QueryId and use the typedef of QueryId in global/intTypes.h instead. Also try to verify that QueryId is used instead of uint64_t where applicable.,6,0.726707
DM-5907,Replace the heap in ScanScheduler with a list.,"ScanScheduler is using heaps to order Tasks by chunkId. This makes it difficult to add Tasks to actively running chunks, which causes a significant delay to the start of query execution. Using a list of buckets of Tasks where each bucket is for one chunkId will make it easy to add Tasks to chunks being. Within each bucket it will still be necessary to order Tasks by tables used in the query.",9,2.4051259
DM-5908,Alter the worker thread pool to allow threads to leave the pool and continue.,There are times when it is desirable for a thread to continue but effectively leave the thread pool and be considered finished by the scheduler. util::ThreadPool needs to modified to do this.,9,2.7797158
DM-5909,"After the first result set is returned, have the thread leave the pool.","When large results are returned from the worker to the czar, the thread should leave the thread pool and the Task should indicate to the scheduler that it is done.   ",6,2.0154884
DM-5910,Add code to the czar to throttle incoming large results.,The czar needs code to limit the number of Tasks sending back large results at any given time.,9,2.8089395
DM-5911,Fix circular references in Mapper objects,"Whilst running tests with pytest and the new file descriptor leak checker it became clear that Mapper objects were not freeing their resources when they were deleted. In particular, the registry objects remained and the associated sqlite database files were opened. This led to pytest running out of file descriptors when large test suites were being executed.    The problem turns out to be the dynamically created map functions. These are created as functions (not bound methods) attached to an instance. Since they are not bound methods the instance object (self) has to be passed in to closure. This leads to self containing a reference to a function that contains a reference to self and this prevents the Mapper from ever being garbage collected (leading to all the resources being retained).    A short term fix is pass the mappers into the closures using {{weakref}}.    Eventually it would be nice to consistently make the {{map_}} items bound methods rather than attaching them as functions but that is beyond the scope of this ticket.",1,2.2818887
DM-5912,"Add ""everything"" scan",Add a low priority ScanScheduler to the worker to handle very slow scans or scans that do not  work well on the other schedulers.,3,1.8968803
DM-5913,Add ability for workers to switch slow queries to the everything scan.,Give the workers the ability to move user queries to the everything scan if they are taking too long to complete a Task or several Tasks.,9,2.2306101
DM-5914,Document planned implementation of toy model of Lupton(ZOGY),"Develop a better understanding of the planned implementation of ZOGY in real space by implementing the kernel correction in k-space and investigating its characteristics when transformed back into real space. Do this either symbolically (if possible) or numerically in an ipython notebook. First in 1-D, then in 2-D, both assuming a constant kernel. Include documentation in the ipython notebook describing the current understanding of how this will be implemented",6,5.400488
DM-5915,Decide how to rework afw:Wcs guts with AST,"Following the to-be-written recommendation for DM-4157, we plan to rework the guts of afw:Wcs to use AST. We need to decide how afw:Wcs will use AST, whether as a wrapper or as a complete replacement with AST.    The product is a design",8,1.359461
DM-5916,Decide how to rework XYTransform/GTransfo guts with AST,"We want to better connect our other transforms with the WCS system, which means reworking the guts of XYTransform/GTransfo to work with AST. This could involve making one or both of them a wrapper, complete replacement, or writing a converter that turns our transform object into an AST map or FrameSet.    The product is a design",10,1.8388232
DM-5917,Design an API for the new Wcs and Transform system,"We need to design a new API for the WCS/Transform system. This is somewhat independent of the question of how the low-level code is used: we want a clean and simple API that lets the components of the stack create, manipulate, use, and persist the necessary transformations. Related to this question is whether we will still need skyToPixel/pixelToSky or whether the necessary operations with those can be subsumed into some Frame-to-Frame transformation (e.g. pixel-to-pixel or tan-to-tan).    The product is an RFC",16,7.8934846
DM-5918,What transforms do we currently need?,"In order to use AST in the stack, we may need to add mappings to it. We also need to be able to describe our transforms at a high level so that we know how to create them.    We need a list of the currently necessary transformations (e.g. from afw:wcs, XYTransform, GTransfo and any other relevant stack packages), and some concrete ideas about the kinds of transforms we may need in the future. These should be described in a high-level mathematical manner, independent of our wcs/transform system.    This can be informed by DMTN-005 and the requirements section of DMTN-010",4,3.048849
DM-5919,Describe our composite mappings and transformation endpoints (Frames),"To use AST in the stack, we need to be clear what our different transformations (AST:Mappings) and endpoints (AST:Frames) are going to be so we can create the chain of transformations (AST:FrameSets) that will be used throughout the stack. This applies to both images and CameraGeom. We may want to produce similar descriptions for other stack objects.    This ticket is the high-level Frames equivalent to the mathematical Mapping description in DM-5918.    This will help us determine how we can put our current input/output image frames into the new system.",4,3.828657
DM-5920,Create DCR metric using new dipole measurement,"In order to evaluate DCR correction algorithms we need a metric that defines the severity of DCR in a residual image. This ticket is to run the new dipole measurement task on simulated difference images affected by DCR, and to define a useful metric. The result will be a brief technical note defining the process and the metric, with a few examples.",6,6.842978
DM-5921,Clarify how to work with ci_hsc's astrometry_net_data,"ci_hsc's {{README.rst}} contains [a note|https://github.com/lsst/ci_hsc/blob/87b6ecb1cc0157cac8dafb356520f49f971bb1ec/README.rst#reference-catalog] on declaring & setting up the included reference catalogue data.    I believe this was rendered obsolete by DM-5135, which automatically sets up the reference catalogue when ci_hsc itself is set up. Attempting to follow the documentation therefore produces confusing warning messages, and may break things.    Please check if my understanding is correct and, if so, fix the documentation.",1,2.217921
DM-5922,Rework camera geometry to use the replacement for XYTransform,"As part of overhauling XYTransform we will likely need to replace the way we describe the transformations supported by camera geometry and {{Detector}}. This is likely to include a new way of describing the coordinate frames (e.g. {{PIXEL}}. {{FOCAL_PLANE}} and {{PUPIL}}).    If we adopt AST (as seems likely) then these frames will be AST {{Frames}}, the transforms will be AST {{Mappings}} and the collection described by {{Camera}} and {{Detector}} will be one or more AST {{FrameSets}}.    An RFC for the redesigned API for camera geometry will be required and this ticket is to implement the resulting design.",8,5.3317075
DM-5923,Support arbitrary sky rotation angles in StarFast,"Currently, if a region of sky is simulated in StarFast the stars must always have the same x,y coordinates (before DCR effects). This ticket is to support arbitrary rotations and offsets of the simulated stars to mimic realistic repeated observations of the same field.",2,2.964693
DM-5924,Improve overscan correction,"Overscan correction can be improved.  Specifically, some systems have sharp discontinuities in the bias section.",6,3.036182
DM-5925,Implement fringe correction in ISR,There is an initial implementation of fringe correction in the obs_subaru package.  It should be ported and generalized.,6,3.1887128
DM-5926,networking in strange state for newly created instances,"When starting a new instance, occasionally something strange seems to happen with the  network setup.  The instance will come up but is inaccessible (icmp, ssh). When this happens, the console log shows that a DHCP address was obtained and cloud-init injected ssh-keys, so it isn't a total network setup failure.    I have seen this happen a few times in the last couple of weeks but I can't reliably reproduce it.  I'm wondering if neutron is logging anything interesting when this happens.    This failure mode happened  again a few minutes ago with 7adffa82-7221-454c-acfe-5f21cdd34ea8.  Which I killed and recreated as instance b6f64981-099b-46e5-a27e-e3694372f447 with the same private IP address.   The new instance is accessible as expected.",1,2.493578
DM-5927,API errors when trying to start up multiple instances,"I am attempting to start up 20 {{m1.medium}} instances without floating IPs to take available of the new instance cap from DM-5840.  This consistently fails after starting a few instances with an HTTP 403.    {code:java}  Error creating OpenStack server: Expected HTTP response code [201 202] when accessing [POST http://nebula.ncsa.illinois.edu:8774/v2/8c1ba1e0b84d486fbe7a665c30030113/servers], but got 403 instead  {""forbidden"": {""message"": ""Maximum number of ports exceeded"", ""code"": 403}}  {code}    Of the instances that do manage to start, most end up in an error state with.      {code:java}  (openstack) server show 134b69dc-56fc-4249-b92f-e958e561ae3b  +--------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+  | Field                                | Value                                                                                                                                               |  +--------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+  | OS-DCF:diskConfig                    | MANUAL                                                                                                                                              |  | OS-EXT-AZ:availability_zone          | nova                                                                                                                                                |  | OS-EXT-STS:power_state               | 0                                                                                                                                                   |  | OS-EXT-STS:task_state                | None                                                                                                                                                |  | OS-EXT-STS:vm_state                  | error                                                                                                                                               |  | OS-SRV-USG:launched_at               | None                                                                                                                                                |  | OS-SRV-USG:terminated_at             | None                                                                                                                                                |  | accessIPv4                           |                                                                                                                                                     |  | accessIPv6                           |                                                                                                                                                     |  | addresses                            |                                                                                                                                                     |  | config_drive                         |                                                                                                                                                     |  | created                              | 2016-05-02T20:29:54Z                                                                                                                                |  | fault                                | {'code': 500, 'message': 'No valid host was found. Exceeded max scheduling attempts 3 for instance 134b69dc-56fc-4249-b92f-e958e561ae3b. Last       |  |                                      | exception: [u\'Traceback (most recent call last):\\n\', u\'  File ""/usr/lib/python2.7/site-packages/nova/compute/manager.py"", line 2235, in _do',   |  |                                      | 'created': '2016-05-02T20:29:57Z'}                                                                                                                  |  | flavor                               | m1.medium (3)                                                                                                                                       |  | hostId                               | b383eddb06f7a1cc5929e5fa8b6982cc523f5ac1cbe3c9c40120a700                                                                                            |  | id                                   | 134b69dc-56fc-4249-b92f-e958e561ae3b                                                                                                                |  | image                                | centos-7-slurm-20160422210744 (7364ada7-263e-4fb0-a9f4-219ab19e0be0)                                                                                |  | key_name                             | jhoblitt-slurm                                                                                                                                      |  | name                                 | slurm-slave4                                                                                                                                        |  | os-extended-volumes:volumes_attached | []                                                                                                                                                  |  | project_id                           | 8c1ba1e0b84d486fbe7a665c30030113                                                                                                                    |  | properties                           | slurm_node_type='slave'                                                                                                                             |  | status                               | ERROR                                                                                                                                               |  | updated                              | 2016-05-02T20:29:57Z                                                                                                                                |  | user_id                              | 83bf259d1f0c4f458e03f9002f9b4008                                                                                                                    |  +--------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+  {code}      ",2,1.6627975
DM-5928,April 2016 LAAIM work,"Drafted documentation for Web SSO capabilities: https://confluence.lsstcorp.org/display/LAAIM/Web+SSO  Began testing new NCSA IAM capabilities (group management, user self-registration).  Registered NCSA with InCommon as a sub-org of UIUC to ease future IdP/SP registrations.  Attended local NCSA LSST coordination meetings.",4,3.296975
DM-5929,April Work for ConOps,"Work on developing, editing and providing feedback for various ConOps.  Converted existing ConOps to new format.",33,6.6441708
DM-5930,Replace exiting DipoleMeasurementTask with DipoleFitTask,"The goal of this ticket is to replace the existing DipoleMeasurementTask with the new  DipoleFitTask, subsequent to ticket DM-5413.    TBD: does this include completely removing all remnants of DipoleMeasurementTask code?",6,1.8509041
DM-5931,Test planned implementation of Lupton(ZOGY) algorithm in real space,Develop a (1-D?) simple toy model and test the effects of the correction for varying I1 and I2 noise levels and different image PSFs and matching kernel(s). This will be done first in an ipython notebook.    See DM-5914.,6,2.5835073
DM-5932,Trial implementation of Lupton(ZOGY) in stack,The Lupton reinterpretation of the ZOGY algorithm in real-space is essentially a post-convolution that implements noise whitening (or decorrelation) of the image difference. We will make a first-pass at implementing this in the existing diffim codebase in order to perform future evaluations on real data.,16,4.2912226
DM-5933,Replace jointcal.StarSelector with meas_algorithms.starSelector,jointcal has its own custom star selector. This should be removed and replaced with a star selector based on meas_algorithms.starSelector. A good choice might be meas_algorithms.objectSizeStarSelector.,2,2.5615015
DM-5934,Update developer guide with Astropy guidance,Once RFC-178 is adopted the developer guide has to be updated to include guidance as to how Astropy can be used in the stack (similar to how Boost is documented).,1,2.468046
DM-5935,Package Astropy for the stack,Once RFC-178 is adopted Astropy needs to be packaged in an EUPS container. Given the complexity of Astropy dependencies the packaging will be done as for {{numpy}} and {{scipy}} by checking that Astropy is available (v1.1 will be the minimum version).,1,2.3426967
DM-5936,Make afw rgb unit test PEP440 compliant for matplotlib check,"If a user has a version of matplotlib installed from a git clone, the afw rgb unit test fails at the matplotlib version check. The versioning scheme for this type of install is determined by pep 440. Make the unit test properly handle this type of version comparison.",1,1.4569087
DM-5937,April work for middleware,Participated in requirements definition,1,5.666833
DM-5938,Redirect non HTTPS requests on LSST the Docs to TLS,See https://docs.fastly.com/guides/securing-communications/allowing-only-tls-connections-to-your-site,1,1.3376398
DM-5939,Pre-release versions of matplotlib 2.0 break afw unit tests,"In the afw rgb unit test, testWriteStarsLegacyAPI checks to make sure that a file name with an unknown extension raises a value error. In current version of matplotlib, saving a file with an unknown extension causes this error:  {code}  *** ValueError: Format ""unknown"" is not supported.  Supported formats: eps, jpeg, jpg, pdf, pgf, png, ps, raw, rgba, svg, svgz, tif, tiff.  {code}    In matplotlib 2.0 prerelease the file is saved as a png when an unknown extension is specified. Since the write call success the unit test fails as it is expecting a failure.     If nothing depends on this behavior, the unit test should probably be removed.",1,2.7590659
DM-5940,Create new build based on the converted firefly code.,"- remove all of the gwt code except for a few remaining files.  - create separate build for the new firefly viewer, leaving the old fftools as it was before the JS conversion.  - repackage files as needed moving forward.",8,2.532478
DM-5941,Private network not available across all instances,"I'm setting up an ELK system. Part of that is an Elasticsearch system. When I bring up the system the private network is bisected. I attempted creating a security group, in case that was a problem but it didn't help. Note that the work around is to create security groups or use a firewall and use floating ips. This is far from ideal. I think the right solution is to use the private network.    Example:    First section {{p-es-1}} {{p-es-3}} {{p-es-k}}    {code:bash}  vagrant@es-1:~$ ifconfig  ens3      Link encap:Ethernet  HWaddr fa:16:3e:47:28:a7            inet addr:10.0.42.30  Bcast:10.0.42.255  Mask:255.255.255.0            inet6 addr: fe80::f816:3eff:fe47:28a7/64 Scope:Link            UP BROADCAST RUNNING MULTICAST  MTU:1454  Metric:1            RX packets:363265 errors:0 dropped:0 overruns:0 frame:0            TX packets:304215 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1000            RX bytes:95396177 (95.3 MB)  TX bytes:238466304 (238.4 MB)    lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0            inet6 addr: ::1/128 Scope:Host            UP LOOPBACK RUNNING  MTU:65536  Metric:1            RX packets:850 errors:0 dropped:0 overruns:0 frame:0            TX packets:850 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1            RX bytes:138411 (138.4 KB)  TX bytes:138411 (138.4 KB)    vagrant@es-1:~$ ping 10.0.42.32  PING 10.0.42.32 (10.0.42.32) 56(84) bytes of data.  64 bytes from 10.0.42.32: icmp_seq=1 ttl=64 time=0.284 ms  64 bytes from 10.0.42.32: icmp_seq=2 ttl=64 time=0.266 ms  64 bytes from 10.0.42.32: icmp_seq=3 ttl=64 time=0.265 ms  64 bytes from 10.0.42.32: icmp_seq=4 ttl=64 time=0.302 ms  ^C  --- 10.0.42.32 ping statistics ---  4 packets transmitted, 4 received, 0% packet loss, time 2998ms  rtt min/avg/max/mdev = 0.265/0.279/0.302/0.019 ms  vagrant@es-1:~$ ping 10.0.42.34  PING 10.0.42.34 (10.0.42.34) 56(84) bytes of data.  64 bytes from 10.0.42.34: icmp_seq=1 ttl=64 time=0.333 ms  64 bytes from 10.0.42.34: icmp_seq=2 ttl=64 time=0.325 ms  64 bytes from 10.0.42.34: icmp_seq=3 ttl=64 time=0.322 ms  64 bytes from 10.0.42.34: icmp_seq=4 ttl=64 time=0.319 ms  ^C  --- 10.0.42.34 ping statistics ---  4 packets transmitted, 4 received, 0% packet loss, time 2998ms  rtt min/avg/max/mdev = 0.319/0.324/0.333/0.022 ms  vagrant@es-1:~$ ping 10.0.42.31  PING 10.0.42.31 (10.0.42.31) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.31 ping statistics ---  4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3017ms  pipe 3  vagrant@es-1:~$ ping 10.0.42.33  PING 10.0.42.33 (10.0.42.33) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.33 ping statistics ---  4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3008ms  pipe 3  vagrant@es-1:~$ ping 10.0.42.35  PING 10.0.42.35 (10.0.42.35) 56(84) bytes of data.  From 10.0.42.30 icmp_seq=1 Destination Host Unreachable  From 10.0.42.30 icmp_seq=2 Destination Host Unreachable  From 10.0.42.30 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.35 ping statistics ---  5 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3999ms  pipe 3  {code}    Second section {{p-es-2}} {{p-es-4}} {{p-lfr}}    {code:bash}  vagrant@es-2:~$ ifconfig  ens3      Link encap:Ethernet  HWaddr fa:16:3e:6f:30:2c            inet addr:10.0.42.31  Bcast:10.0.42.255  Mask:255.255.255.0            inet6 addr: fe80::f816:3eff:fe6f:302c/64 Scope:Link            UP BROADCAST RUNNING MULTICAST  MTU:1454  Metric:1            RX packets:196344 errors:0 dropped:0 overruns:0 frame:0            TX packets:160561 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1000            RX bytes:47667399 (47.6 MB)  TX bytes:7135345 (7.1 MB)    lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0            inet6 addr: ::1/128 Scope:Host            UP LOOPBACK RUNNING  MTU:65536  Metric:1            RX packets:97268 errors:0 dropped:0 overruns:0 frame:0            TX packets:97268 errors:0 dropped:0 overruns:0 carrier:0            collisions:0 txqueuelen:1            RX bytes:8558096 (8.5 MB)  TX bytes:8558096 (8.5 MB)    vagrant@es-2:~$ ping 10.0.42.33  PING 10.0.42.33 (10.0.42.33) 56(84) bytes of data.  64 bytes from 10.0.42.33: icmp_seq=1 ttl=64 time=0.311 ms  64 bytes from 10.0.42.33: icmp_seq=2 ttl=64 time=0.309 ms  64 bytes from 10.0.42.33: icmp_seq=3 ttl=64 time=0.300 ms  ^C  --- 10.0.42.33 ping statistics ---  3 packets transmitted, 3 received, 0% packet loss, time 2000ms  rtt min/avg/max/mdev = 0.300/0.306/0.311/0.020 ms  vagrant@es-2:~$ ping 10.0.42.30  PING 10.0.42.30 (10.0.42.30) 56(84) bytes of data.  From 10.0.42.31 icmp_seq=1 Destination Host Unreachable  From 10.0.42.31 icmp_seq=2 Destination Host Unreachable  From 10.0.42.31 icmp_seq=3 Destination Host Unreachable  From 10.0.42.31 icmp_seq=4 Destination Host Unreachable  ^C  --- 10.0.42.30 ping statistics ---  5 packets transmitted, 0 received, +4 errors, 100% packet loss, time 4014ms  pipe 3  vagrant@es-2:~$ ping 10.0.42.32  PING 10.0.42.32 (10.0.42.32) 56(84) bytes of data.  From 10.0.42.31 icmp_seq=1 Destination Host Unreachable  From 10.0.42.31 icmp_seq=2 Destination Host Unreachable  From 10.0.42.31 icmp_seq=3 Destination Host Unreachable  From 10.0.42.31 icmp_seq=4 Destination Host Unreachable  From 10.0.42.31 icmp_seq=5 Destination Host Unreachable  ^C  --- 10.0.42.32 ping statistics ---  5 packets transmitted, 0 received, +5 errors, 100% packet loss, time 4023ms  pipe 3  vagrant@es-2:~$ ping 10.0.42.34  PING 10.0.42.34 (10.0.42.34) 56(84) bytes of data.  From 10.0.42.31 icmp_seq=1 Destination Host Unreachable  From 10.0.42.31 icmp_seq=2 Destination Host Unreachable  From 10.0.42.31 icmp_seq=3 Destination Host Unreachable  ^C  --- 10.0.42.34 ping statistics ---  4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 3006ms  pipe 3  vagrant@es-2:~$ ping 10.0.42.35  PING 10.0.42.35 (10.0.42.35) 56(84) bytes of data.  64 bytes from 10.0.42.35: icmp_seq=1 ttl=64 time=0.387 ms  64 bytes from 10.0.42.35: icmp_seq=2 ttl=64 time=0.278 ms  64 bytes from 10.0.42.35: icmp_seq=3 ttl=64 time=0.288 ms  ^C  --- 10.0.42.35 ping statistics ---  3 packets transmitted, 3 received, 0% packet loss, time 1998ms  rtt min/avg/max/mdev = 0.278/0.317/0.387/0.053 ms  {code}    This can be reproduced by sourcing your OpenStack credentials and running this [{{Vagrantfile}}|https://gist.github.com/jmatt/7b6eb6a042c4e63531d40d1a68069f33]. Use {{vagrant ssh p-es-1}} to connect to the {{p-es-1}} instance.  ",2,2.1364448
DM-5942,Public elasticsearch configuration using SSL/TLS and basic auth,Create a (relatively) secure way to use Elasticsearch from outside of Nebula using Ansible. See:    https://www.elastic.co/blog/playing-http-tricks-nginx    Note that this will not allow another Elasticsearch to join but will allow the usual admin and client queries using basic auth.,1,2.5411398
DM-5943,Add Git refs to Jobs Table of QA Dashboard,The Level 0 QA DB should know what Stack Git refs correspond to each job. This will enable plots to filter jobs based on development ticket so that a developer can understand how a branch compares to master.    This ticket will add jobs to the schema (http://sqr-009.lsst.io/en/latest/#level-0-qa) and create the necessary migration script.,5,2.6098523
DM-5945,Implement validate_drp plot in Bokeh as proof-of-concept for QA Dashboard,This ticket will implement a plot from validate_drp in the QA Dashboard as a proof-of-concept for how existing matplotlib plots can be re-implemented in Bokeh with data from the QA database.    Stretch goals (maybe for a future ticket) will be to overplot the validate_drp output of one job against anotherâ€™s to understand performance changes.,2,3.0435665
DM-5946,SUIT design ,"Finish SUIT design, produce a design document",75,4.887894
DM-5947,Jupyter widget using Firefly,"Jupyter widget using Firefly visualization components.   To better support the user community in using Jupyter notebook with Python packages, we want to start exploring the process of creating Jupyter widget, using Firefly visualization capabilities. ",26,7.2900248
DM-5948,Workspace design,workspace design   * ,30,6.785594
DM-5949,Testing framework setup and more unit test,Testing framework setup and more unit test code   ,45,4.1342444
DM-5951,Make obs_subaru PEP8 (pyflakes) compliment,"Running pyflakes on obs_subaru revels many places where the code is not (LSST specific) PEP8 compliment. Actual coding bugs reviled by pyflakes were fixed in DM-5474, however many of the formatting issues need to be fixed. Once DM-4740 and DM-4668 are done, all remaining code should be brought into coding standard compliance.",3,0.9678243
DM-5952,Initial draft(s) of the Data Backbone ConOps,"Initial drafts of the data backbone concept of operations. Versions 0.1, 0.2. Produced document that is ready for friendly, internal review although document is not complete.",8,7.0905175
DM-5953,Internal review of Data Backbone ConOps and revision(s),,2,5.773242
DM-5954,Watch Boot Camp materials,Videos from the [DM Boot Camp|https://community.lsst.org/t/dm-boot-camp-announcement/249] cover a lot of topics a newbie like me is interested in.,4,4.7567124
DM-5955,Build LSST Software Stack from the source,Create a virtual machine with functioning LSST Software Stack to have an environment where I can see and play with its code.,3,3.3454902
DM-5958,Integration Environment: top level design,"Working with SUI/QServ teams to create a plan that includes deployment schedules, levels of support, discussions of administrative requirements in integration environment, detailed documentation before procurement, security reviews, reviews with deployment team.",26,6.053174
DM-5959,Integration Environment: Procurement,Discussions with vendors. Quote selection. Budget tracking. Quote submission to finance. GCO follow up questions. OBFS follow up questions. Finance follow up questions. Overall tracking of purchase progression.,10,6.5439
DM-5960,Node delivery to racking,"Node delivery acceptance, unpacking, inventory, rack builds, pdu placement, node racking, bios updates, power connections, ",16,3.2950888
DM-5961,Networking,"Unpacking networking equipment, inventory, ordering/procure/unpack cabling, equipment racking, cabling, config creation and management.",6,4.2531595
DM-5962,OpenStack deployment,"This activity is outside of LSST project; this story is a placeholder for demonstrating progression toward completion of the epic.    Some activities that are likely to occur:  Software installation, OS installation/updates, RAID configurations, software configuration, monitoring and notification system(s) installation and configuration, integration testing and friendly uses evaluation. ",24,2.5088687
DM-5963,Compute Upgrade,Discussions and planning for the creation of an LSST service-only tenant for better isolation (hence protection) from ad hoc services. Further discussions with LSST DM interested stakeholders about this feature. Policy development for use and monitoring of use of this feature.,10,5.64751
DM-5964,Object Storage Installation,Discussions and planning for allocating the 1PB storage increase within Nebula between object storage and block storage. Further discussions with LSST DM interested stakeholders about this feature. Policy development for use and monitoring of use of this feature.,5,5.184046
DM-5966,Remove use of Boost smart pointers in meas extensions,"Removal of boost smart pointers in DM-5879 missed some meas extensions which are not built as part of {{lsst_distrib}}. Namely: {{meas_extensions_shapeHSM}}, {{meas_extensions_simpleShape}} and {{meas_extensions_photometryKron}}.  Update these too.",1,1.679402
DM-5967,Provide docker swarm POC for Qserv containers orchestration,,10,3.05489
DM-5968,Split secondary index loading from qserv_data_loader.py to separate unit test,"To isolate development and validation of secondary index loading strategies, encapsulate loading of ""pure"" secondary index data via qserv_data_loader.py, without using entire datasets.",8,1.5515987
DM-5969,Deploy any secondary index loader mods into qserv_data_loader.py,"Following completion of DM-5968, any modifications to the top-level data loading procedure for the secondary index need to be deployed back to the main qserv_data_loader.py driver.",5,1.3689183
DM-5970,Slurm deployment preparation,Installation and familiarization with the supported level of service of slurm installation. Includes rolling that configuration into puppet modules/manifests. Also includes documentation of the installation and configuration requirements.    This is month-of-April work; a new story continues into May.,20,5.5266223
DM-5972,Inventory to racking,"Inventory, unpacking, bios updating, racking, rack building, pdu installation, power cabling, OS installation, RAID configuration, xCAT deployment planning, Puppet deployment planning, puppet module/manifest creation, puppet config versioning, cabling strategies discussions, additional cable purchases (minor).",30,3.3947115
DM-5973,Update developer guide with pytest guidance,Now that DM-5561 explains how to migrate to pytest compatibility the developer guide must be updated to state how to use pytest in unittests.,5,1.8150196
DM-5976,Change SubtractBackgroundConfig.isNanSafe default to True,[~price] suggests that the default value for {{SubtractBackgroundConfig.isNanSafe}} be changed from False to True.,1,1.0168674
DM-5977,Create and deploy Beats for Logstash and Elasticsearch.,Create and deploy Beats for Logstash and Elasticsearch. These beats are used to transport logs and monitoring data to ELK.    See: https://www.elastic.co/products/beats,3,2.746215
DM-5978,Miscellaneous Nebula service items for x16,"This story is for miscellaneous Nebula service items that do not have individual LSSTDM JIRA issues (often handled in the RT ticket system)  including account creation requests, reporting on hanging/errant processes for cleanup, response & communiques on security incidents, etc. ",8,3.9167309
DM-5979, tests in testArgumentParser.py fail Jenkins run-rebuild on nfs,"(1) {{testOutputs}} fails because paths are compared literally  Jenkins run-rebuild #139 failed with pipe_base  https://ci.lsst.codes/job/run-rebuild/139//console  {code:java}  FAIL: testOutputs (__main__.ArgumentParserTestCase)  Test output directories, specified in different ways  ----------------------------------------------------------------------  Traceback (most recent call last):    File ""tests/testArgumentParser.py"", line 497, in testOutputs      self.assertEqual(args.input, DataPath)  AssertionError: '/nfs/home/lsstsw/stack/Linux64/obs_test/2016_01.0-3-gafa6dd0+10/data/input' != '/home/lsstsw/stack/Linux64/obs_test/2016_01.0-3-gafa6dd0+10/data/input'  {code}    Please make the comparison more robust.     (2) File descriptor leaks  Jenkins run-rebuild #138 failed with pipe_base  https://ci.lsst.codes/job/run-rebuild/138//console  {code:java}  FAIL: testFileDescriptorLeaks (lsst.utils.tests.MemoryTestCase)  ----------------------------------------------------------------------  Traceback (most recent call last):    File ""/home/lsstsw/stack/Linux64/utils/2016_01.0-2-g97a6e33/python/lsst/utils/tests.py"", line 133, in testFileDescriptorLeaks      self.fail(""Failed to close %d files"" % len(diff))  AssertionError: Failed to close 1 files  {code}    {code:java}  File open: /nfs/home/lsstsw/build/pipe_base/.nfs000000000a20a3f700005679  {code}  This test passes on local disk.  ",2,1.3942859
DM-5980,update jenkins to 2.x,,10,1.8973283
DM-5983,Stop cleanly MySQL if configuration step fails,Next scripts doesn't stop cleanly MySQL if configuration step fails:    {code:bash}  admin/templates/configuration/tmp/configure/scisql.sh  admin/templates/configuration/tmp/configure/tools/sql-loader.sh  {code},2,0.39017713
DM-5984,Use RO MySQL account in qserv_testdata,"It seems integration tests datasets are now loaded with Loader. So using MySQL root account is no more required in integration tests, an account with SELECT access on test databases (like qsmaster), should be enough.     Furthermore, all code related to MySQL writes can be removed from   {code:bash}  python/lsst/qserv/tests/sql/cmd.py  python/lsst/qserv/tests/sql/connection.py  {code}",4,2.364262
DM-5985,Add unicode support for Qserv password,Qserv password must be encoded in ASCII for now in qserv-meta.conf. Unicode passwords should be supported.,6,0.9227019
DM-5986,Use sagas in place of side-effects in chart-related controllers ,"Replace side-effects with saga and clean-up chart related controllers (TableStats, XYPlot and Histogram).",3,3.5297976
DM-5988,Support Monocam reduction,"Monocam is being used on a telescope, and we want to reduce the data obtained.  This is made difficult by the fact that the camera and the telescope are not talking to each other so the usual header keywords are in separate files from the data.",6,5.238835
DM-5991,A look at the overall performance of the application,Investigate the overall performance of the application and improve it where possible.  It is pointed out that triview is especially slow compare to expanded.  Need to investigate.,4,6.2015333
DM-5992,Reception and Placement,"Receive, unbox, inventory, inspect, build racks, rack nodes and power.",10,3.5927663
DM-5993,Networking Configuration,"Unbox, inspect, rack, power networking equipment, cables ordered, alternate cable purchase options tested, initial switch configuration(s), cabliing.",15,5.983064
DM-5994,Provisioning,"OS + updates installation, imaging building, stateless/stateful node provisioning, test of image, security configurations, networking bandwidth tuning, file system tuning, file system installation and tuning.",39,5.5475097
DM-5995,Disaster Recovery Implementation,Testing/practicing recovery of node/image/software after various types of faults.,30,12.19994
DM-5996,Documentation,Document each component sufficient enough for transfer of knowledge and system recovery as needed.,5,2.992436
DM-5997,Capability Validation,Review that design was implemented successfully including recover and supporting documentation exists.,10,7.8991957
DM-5998,Security Vetting,Review of capability by site security team,3,4.347973
DM-5999,Acceptance by Stakeholders,"Review with stakeholders (target users, release manager, others as necessary) to confirm that capability fulfills original requirements. ",2,2.737503
DM-6004,Acceptance by Stakeholders,"Review of services (compute, storage, networking) by LSST project before considering work final.",5,2.737503
DM-6005,Procurement,,8,5.3200245
DM-6006,Reception and Placement,,3,3.5927663
DM-6007,Networking Configuration,,10,5.983064
DM-6008,Provisioning,,30,5.5475097
DM-6009,Disaster Recovery Implementation,,20,12.19994
DM-6010,Documentation,,15,2.992436
DM-6011,Capability Validation	,,15,5.178169
DM-6012,Security Vetting,,10,4.347973
DM-6013,Acceptance by Stakeholders,,20,2.737503
DM-6014,Reception and Placement,,2,3.5927663
DM-6015,Networking Configuration,,3,5.983064
DM-6016,Provisioning,,10,5.5475097
DM-6017,Disaster Recovery Implementation,,4,12.19994
DM-6018,Documentation,,4,2.992436
DM-6019,Capability Validation,,5,7.8991957
DM-6020,Security Vetting,,6,4.347973
DM-6021,Acceptance by Stakeholders,,6,2.737503
DM-6022,Lazy load related chart data on table data update,"When new table data received, the related chart data should be updated only for the components on display. Hidden components' data should be lazily updated when a component becomes visible.",3,2.214274
DM-6025,ingest.py throwing away errors,"Line 118 of ingest.py has a problem try block which is currently just throwing away errors, which has made for some confusing/frustrating debugging.    This should be changed to either warn or raise, but not silently dispose of errors.",1,1.6408356
DM-6026,Make it possible to distinguish TABLE_NEW_LOADED actions triggered by sort,"It would be beneficial to have in the TABLE_NEW_LOADED payload a  trigger field, which would differentiate actions triggered by sort (where  data do not change, only their order) or filter from other loads. We don't  need to reload table statistics or histogram on sort. But we do need to to  reload them on filter.      created TABLE_SORT action to distinguish sorting from filtering.  sorting should not reload xyplot nor catalog overlay.    Also:  - disable history when in api mode.  - ensure tableMeta.source reflects the file on the server.  - fix TablePanelOptions not resetting columns selection.  - remove 'Fits Data' tab when no images available.  - fix 'Coverage' appearing when it should.",2,0.8203252
DM-6028,Validation is not performed on unchanged fields,"Currently, validation is performed only if a field has changed. We need to be able to validate all fields on form submit.    The issue is not limited to initial (ex. empty) value being invalid. The invalid message is lost when a field is unmounted/re-mounted.    You can test the following way:  - http://localhost:8080/firefly/;a=layout.showDropDown?view=AnyDataSetSearch  - Open chart settings, enter 1000 into X/Y ratio - the field is shown as invalid  - Switch to histogram and back, the invalid message is gone, the field appears to be valid    Another test case is Example Dialog tab 'X 3', 'X 3'  tab test field initial value 88 is invalid (it should be between 22 and 23), but it appears valid. ",2,2.7385678
DM-6029,Error message is not shown,The error message is not showing consistently when mouse is over tha exclamation icon.,1,1.5183638
DM-6030,Investigate possibilty of cosmic ray muons (etc) for precision gain calibration,"In the era of CBPs, we care about absolute system throughput, and thus need to accurately know the gain of amplifiers in the CCDs.    Initially, this can be done by lab-based Fe55 characterisation (modulo the non-linearity, though that itself will need to be need to be characterised and corrected for), but changes in the relative gains of the various amplifiers need to be monitored, and this must be done in a way that is not degenerate with the optical transmission in any way.    Theoretically it should be possible to use cosmic ray muon tracks, and tracks from radioisotope contamination of the glass/dewar, to measure the (change in the) relative gains of the amplifiers.    Early work has shown that this does work in principle, but this ticket is for some further effort to see whether this method can provide the necessary accuracy given the amount of data available remains to be seen.    This ticket would normally need to be significantly more points, but as it builds on earlier work, it can, at least for initial results, be done quite cheaply.    Initial investigation will inform further work.    1st order: histogram all pixels in dark images after careful bias subtraction. Look at shape of spectrum. Fit some arbitrary function, and correlate with Fe55 gain measurements.    2rd order: Separate muon tracks from soft electron tracks/nuclear recoil events. Can cutting one of more of these types out improve the correlation? Or can treating them separately improve the resolution?    3rd order: Recalculate the histogram in terms of the dE/dx for the muon tracks, i.e. taking into account their track lengths and thus angle through the silicon.",10,3.6895523
DM-6031,Create documentation for bright object masks,"The bright object mask code ported from hsc bought the ability to mask regions, during coaddition, by providing mask files. How to create these files, and where they should be placed in the file system is documented on and HSC ticket (https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1351) but not on the LSST side. The information on how to create and use bright object masks should be put into LSST documentation.",3,1.2382843
DM-6033,Support sphinxcontrib-bibtex in technotes,Allow bibtex-based references in technotes using [sphinxcontrib-bibtex|https://github.com/mcmtroffaes/sphinxcontrib-bibtex].    DMTN-010 will be used as a pilot case.,1,2.3482406
DM-6036,Produce and ingest master calibs for USNO monocam data.,"Use the construct*.py scripts added to pipe_drivers to produce temporally relevant master biases, darks, flats (and fringe frames?) for the recent USNO observing with monocam.    A small amount of hacking will be required due to the fact that the current ingestion model assumes that each CCD frame has a USNO counterpart which tells about the telescope pointing etc, but the bias frames do not have these.    Once the master calibs are produced, get them ingested.",2,3.4299133
DM-6037,Reduce sky data from USNO monocam run,"Using the master calibs produced in DM-6036, push all the monocam data through processCcd.    Others will run sanity checks on the output (initial astrometry & photometry). From there I believe people will look at using the data to test jointcal & sim_astrom etc, but this ticket just related to the initial reduction.    As more data comes in from the 2nd telescope, a little further hacking may be necessary to keep everything running. Some of this will likely be hacky or need one-off solutions/header modification, hence the higher-than-normal number of story points assigned to what one might expect to be an hour-long job.",3,2.5479426
DM-6038,Monocam bias structure analysis,"Estimates of the noise in the bias frames coming from the USNO monocam run around ~20e- RMS. This is higher than with the same readout configuration in the lab, and could be due to several things.    This ticket is to take a look at a few bias frames and investigate the structure of the noise. If it is periodic and at a constant phase then using master biases will significantly improve the SNR in the calexps produced, but if it is not, then whether or not bias frames should be used at all should be considered.",1,4.5618205
DM-6039,Download temporally relevant raw calibs for CTIO DECam data,"Go to the NOAO portal and download a sufficient number of darks, biases and flats (in each band) from around the time of the CTIO trip to produce master calibs.",1,4.747246
DM-6040,Create and ingest master calibs for DECam CBP reduction,"Having collected data in DM-6039, push all this through the master calib creation scripts and ingest master calibs into registry.    This is a necessary but not-necessarily-sufficient ingredient for making progress on DM-5465.",2,4.4490843
DM-6041,Functional use cases for tools,"Work with Vandana Desai (IRSA) to tabulate science use cases for tools. Then transform the science use cases to functional use cases (""this is how we want the tool/interface to behave"").    This work is  to identify common functional and scientific use cases between PTF/ZTF and LSST to inform LSST on how the SUIT web portal might be organized for user interaction with LSST data. ",1,4.5164595
DM-6042,Add viewer launching API,"Add ability to launch the viewer and load images, xyplots, and tables from the api. We use to call this firefly.getExternalViewer()  Also, we have this concept of 'root path' through out the code. The api use can set a root path so he can use his when we are cross site. Need to implement.  ",6,4.188202
DM-6043,Change mouse readout to use supports MouseReadoutCntlr & add an API readout,"Change mouse readout to use MouseReadoutCntlr.     * Use {{VerySimpleMouseReadout}} as a reference.   * Change to use {{MouseReadoutCntlr}} for options instread of ImagePlotCnltr  * Add a second (vertical) Mouse readout to be used in the api mode. The readout should be set into {{ApiUtilImage.jsx}}, {{initAutoReadout}}.  It should replace {{VerySimpleMouseReadout}}       & add an API readout",10,2.3854847
DM-6048,Bundle up more HSC data for validate_drp,We would like to include a larger set of HSC data for validation.  I tested this while in Tucson.  My working dir was {{/tigress/pprice/frossie}}.  The raw and processed data should be stuffed into validation_data_hsc,1,2.0111456
DM-6050,Table caching optimizations,"We need to avoid duplicate requests which result from minor differences in TableRequest parameters, which are not used to get data.  For example, loading catalog table, which triggers table statistics, and then getting an XY plot, results in 3 requests, returning identical data.    1. RequestClass=ServerRequest; *tbl_id=tbl_id-1;* UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; catalog=wise_allwise_p3as_psd; RequestedDataSet=wise_allwise_p3as_psd; radius=200; use=catalog_overlay; catalogProject=WISE    2. RequestClass=ServerRequest;RequestedDataSet=wise_allwise_p3as_psd; catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; catalogProject=WISE; radius=200; SearchMethod=Cone    3. RequestClass=ServerRequest; *tbl_id=xyplot-tbl_id-1;* catalog=wise_allwise_p3as_psd; use=catalog_overlay; UserTargetWorldPt=10.68479;41.26906;EQ_J2000;m31;ned; SearchMethod=Cone; RequestedDataSet=wise_allwise_p3as_psd; catalogProject=WISE; radius=200; *decimate=decimate=ra,dec,10000,1,,,,*    The difference between 1 and 2 is tbl_id parameter. The difference between 2 and 3 is tbl_id and decimate parameters. As well as the order of the parameters. None of which change the catalog search result.    Test Case: Test Searches, Test catalog, AllWISE Source, radius=200",2,4.8371596
DM-6051,Add extendedness vs. star selector test to single-visit validation in ci_hsc,"ci_hsc has a test that verifies that extendedness as measured on coadds broadly agrees with the star selection done for PSF estimation on individual frames.  This tests a bunch of stuff, including aperture corrections on the coadds and propagation of flags from visits to coadds.    It doesn't test that aperture correction vs. extendedness logic is correct in processCcd.py, but just copying this test to the appropriate validation function in ci_hsc should do the trick.  This is currently broken, but should be fixed in DM-5877.",2,1.5614369
DM-6052,Improve password management for Qserv MySQL accounts,"Qserv passwords management for MySQL account (i.e. root, monitor, qsmaster) should be improved. See wmgr password management to have a good example. Furthermore qsmaster use currently empty password, this must be fixed.",8,2.395353
DM-6053,Allow use of other MySQL account thant 'qsmaster',"'qsmaster' value can't be changed in qserv-meta.conf, this must be fixed    {code}  diff --git a/admin/templates/installation/qserv-meta.conf b/admin/templates/installation/qserv-meta.conf  index 81b6ca9..203ebda 100644  --- a/admin/templates/installation/qserv-meta.conf  +++ b/admin/templates/installation/qserv-meta.conf  @@ -103,7 +103,7 @@ user_monitor = monitor   password_monitor = CHANGEMETOO      # Used to access Qserv data and metadata (like indexes)  -user_qserv = qsmaster  +user_qserv = qservdata  {code}    Above change leads to next error in integration tests:    {code:bash}  154 [0x7f1beacf9700] ERROR lsst.qserv.sql.SqlConnection null - connectToDb failed to connect!  154 [0x7f1beacf9700] ERROR lsst.qserv.sql.SqlConnection null - runQuery failed connectToDb: START TRANSACTION  2016-05-10 14:55:09,684 - root - CRITICAL - Exception occured: Error from mysql: (-999) Error connecting to mysql with config:[host=127.0.0.1, port=13306, user=qsmaster, password=XXXXXX, db=qservCssData, socket=]  Traceback (most recent call last):    File ""/home/dev/src/qserv/bin/qserv-data-loader.py"", line 274, in <module>      loader = Loader()    File ""/home/dev/src/qserv/bin/qserv-data-loader.py"", line 225, in __init__      css_inst = css.CssAccess.createFromConfig(config, """")  CssError: Error from mysql: (-999) Error connecting to mysql with config:[host=127.0.0.1, port=13306, user=qsmaster, password=XXXXXX, db=qservCssData, socket=]  2016-05-10 14:55:09,810 - lsst.qserv.admin.commons - CRITICAL - Error code returned by command : qserv-data-loader.py -v --config=/qserv/stack/Linux64/qserv_testdata/2016_01-1-g7b10791+7/datasets/case05/data/common.cfg --host=127.0.0.1 --port=5012 --secret=/home/dev/qserv-run/git/etc/wmgr.secret --delete-tables --config=/qserv/stack/Linux64/qserv_testdata/2016_01-1-g7b10791+7/datasets/case05/data/Object.cfg --css-remove --skip-partition --chunks-dir=/home/dev/qserv-run/git/tmp/qservTest_case05/chunks/Object --config=/qserv/stack/Linux64/qserv_testdata/2016_01-1-g7b10791+7/datasets/case05/data/Object.cfg --empty-chunks=/home/dev/qserv-run/git/var/lib/qserv/empty_qservTest_case05_qserv.txt qservTest_case05_qserv Object /qserv/stack/Linux64/qserv_testdata/2016_01-1-g7b10791+7/datasets/case05/data/Object.sql /home/dev/qserv-run/git/tmp/qservTest_case05/chunks/Object/Object.txt   ERROR  {code}  ",4,2.117582
DM-6054,Minor updates in suptertask from following DMTN-002,Some examples in the DMTN-002 seem slightly out of date.    Update supertask documentation and code to catch up with some recent developments in the stack. ,2,2.980405
DM-6057,v12.0 [Winter 2016 / Extra 2016] release,This is the ticket for the v12.0 release prep.     Edit: Release announcement at https://community.lsst.org/t/lsst-stack-version-12-0-winter-2016-extra-2016-release/874  ,12,1.3500867
DM-6062,Launch integration tests using Docker+Openstack,vagrant and packer will be replaced by openstack python API and cloud-init which are more flexible.    - A pseudo-DNS will be provided thanks to avahi/mdns  - Only one public/floating IP willl be used (in order to allow booting large clusters laters),10,4.796361
DM-6063,Fix how aperture correction is applied,[~lauren] committed a fix Jan 15 to how aperture correction is applied that I accidentally lost when refactoring in DM-4692. https://github.com/lsst/pipe_tasks/commit/d904e3d188698b4f57bf3dad1516b0bf201078f5 Restore the fix.    The need for this fix suggests a design flaw in measurement that will be fixed as part of DM-5877,1,1.906138
DM-6064,"Define, design, and RFC repository refactor.",Includes support for   * butler manages input & output repos  * repo tagging  ,18,3.020955
DM-6065,design work for butler storage & format factorization,,5,6.1805186
DM-6069,Camera team visualization support (F16),Support the camera team to use Firefly for their visualization needs.,12,8.450013
DM-6071,L1 Messaging path status,"All principle entities for L1 are in place and the messaging is working as intended. The message dictionary includes some message types for prototyping and will likely double in size as the interface between OCS is firmed up in the coming weeks. The implementation thus far is a 'ready, set, go' set of states. Test files from 10 Forwarders are sent to 10 distributors thru a WAN emulation device, and the result can be timed. The DMCS component is a simple CLI to initiate messages as currently written. This component will be expanded as requirements are determined.    Still under development is a component layer between the Condor controller and the NCSA Foreman entity so that resource availability can be queried and provide a communication link for ancillary information as needed.",40,3.5587327
DM-6072,Li prototype code and the Wan Emulator,"L1 Forwarder components and Distributor components are located on opposite sides of the Emulator (the Long Haul network component) and move files across the path when configured and  given a 'go' signal via messaging. Forwarder/Distributor pairs are set up dynamically for each file transfer (similar to a readout event). Results are temporarily forwarded to a status queue sink, where messages are processed for the publishing of results.",30,8.18613
DM-6073,Pass background to NoiseReplacerTask,"Implement RFC-180:    `NoiseReplacerTask` wants some statistics about the background that was subtracted from the exposure, but it gets these in a fragile and roundabout fashion: it expects the code that measures the background to put the mean and variance into the exposure's metadata, using special keys. It is difficult to enforce correctness because background is measured several times while processing an exposure.    To solve this, pass the background directly to `NoiseReplacerTask`. This will require passing the background through the various measurement tasks, which will require small changes to code that calls the measurement tasks.    In addition, remove computation of background statistics from the background fitting code.",4,2.0822146
DM-6074,Add RegistryField support to Task.makeSubtask,As part of implementing RFC-183 add support for tasks specified in {{lsst.pex.config.RegistryField}} to {{lsst.pipe.base.Task.makeSubtask}}  ,2,1.3388208
DM-6075,Document the need for abstract base tasks for tasks,"As part of RFC-183 document the fact that variant tasks should have a common abstract base class that defines the API. If we add future tasks that we feel are likely to have variants, then we should create an abstract base class.    Candidates include star selectors, PSF determiners and ISR tasks.    Note that this applies to tasks LSST provides in its stack, not to variants users produce and other obscure one-off code.    Also document the desire that tasks with anticipated many variants, such as star selectors, and PSF determiners should be in registries. This explicitly excludes tasks such as ISR where only one task is likely to be useful for a given set of data.  ",2,2.8201926
DM-6076,Create a registry for star selectors,Create a registry for star selectors and use the registry instead of ConfigurableField in tasks that call a star selector.    Update config overrides in obs_* packages and unit tests accordingly.,3,2.6651604
DM-6077,Change PSF determiners into tasks,"PSF determiners are already configurables, and some benefit from having a log. Take the logical next step and make them instances of {{lsst.pipe.base.Task}}.",1,2.9894137
DM-6078,Aperture correction fails to measure a correction for the final plugin in the list and reports misleading errors,"Since the refactoring of DM-4692, runs of *processCcd.py* detail the following in their logs:    {code:title=With base_PsfFlux and base_GaussianFlux plugins registered}  processCcd.charImage.detectAndMeasure.measureApCorr WARNING: Only 0 sources for calculation of aperture correction for 'base_PsfFlux'; setting to 1.0  processCcd.charImage.detectAndMeasure.measurement: Measuring 65 sources (65 parents, 0 children)   processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 1 flux fields  processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  ...  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 2 flux fields  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr WARNING: Could not find base_GaussianFlux_flux or base_GaussianFlux_fluxSigma in apCorrMap  {code}    {code:title=With base_PsfFlux, base_GaussianFlux, and ext_photometryKron_KronFlux plugins registered}  processCcd.charImage.detectAndMeasure.measureApCorr: Measuring aperture corrections for 2 flux fields  processCcd.charImage.detectAndMeasure.measureApCorr WARNING: Only 0 sources for calculation of aperture correction for 'base_PsfFlux'; setting to 1.0  processCcd.charImage.detectAndMeasure.measureApCorr WARNING: Only 0 sources for calculation of aperture correction for 'base_GaussianFlux'; setting to 1.0  processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 2 flux fields  processCcd.charImage.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  ...  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Applying aperture corrections to 3 flux fields  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr: Use naive flux sigma computation  processCcd.calibrate.detectAndMeasure.measurement.applyApCorr WARNING: Could not find ext_photometryKron_KronFlux_flux or ext_photometryKron_KronFlux_fluxSigma in apCorrMap  {code}    I can confirm that for the latter, running HSC data with the fix on DM-6063, the aperture corrections are being measured and applied for the PsfFlux and GaussianFlux measurements, but NOT for the KronFlux measurements.      Looking at the output from the current ""expected"" values for the {{lsst_dm_stack_demo}} we see that there is an offset in the Psf-Gaussian fluxes, implying the Gaussian fluxes are not being measured (and hence not applied):  !demo_current.png|width=500!    From this I conclude that the aperture corrections are indeed being measured for all but the final entry in the plugin list.  This implies that the report of ""Only 0 sources for calculation of aperture correction for 'xxx_xxFlux'; setting to 1.0"" is incorrect for all but the final plugin measurement.    The demo previously successfully calculated aperture corrections and, after the logic fix of DM-4836, applied them in the correct order:  !demo_previous.png|width=500!    The sources of these issues and fixes for them are the goal of this issue.",2,1.7765708
DM-6079,description of archive in a box,"Please put in more detailed description of the ""Archive in a box"" concept",1,1.661999
DM-6082,Add Sublime Text configuration tips to Developer Documentation,"[~rowen] and [~Parejkoj] have some good tips about setting up Sublime Text.  [~jsick] suggested that we add these configuration tips to the Developer Documentation.    http://developer.lsst.io/en/latest/#part-tools    Both want to include info about recommended packages, but also the linter configurations to support the DM styles.    I paste in here various helpful parts from the HipChat Software Development room discussion of this.  Both verbatim, and summarized.    1. Install {{Package Control}}    2. Packages:  {{Git}}, {{GitGutter}}, {{SideBarEnhancements}}, {{SublimeLinter}}, {{SublimeLinter-flake8}}, {{SublimeLinter-html-tidy}}, {{SumNumbers}}, {{Gist}}, {{BracketHighlighter}}, {{TrailingSpaces}}, {{Trimmer}}, {{OmniMarkupPreviewer}}, {{ReStructuredTextImproved}}, {{MarkDown Editing}}, {{Colorsublime}}    3. Themes:  {{Sunburst}} color scheme    * VIM users:  {{Vintageous}}  + Mac OS X configuration:  {{defaults write com.sublimetext.3 ApplePressAndHoldEnabled -bool false}}  so that holding down 'j' moves downward.  Note that {{Vintageous}} is not a complete implementation of {{vim}}, but it at least allows enough basics so that one doesn't go crazy switching back and forth.    link the {{subl}} command to {{/usr/local/bin}}     Quick Tips:  ""option-select (to select blocks) and select something then cmd-D are both extremely useful for modifying lots of things at once.""    ""Similarly, ctrl-shift-up/down arrow.""    ""cmd-click on multiple lines to have multiple synchronized cursors""    Configurations:  1. [~rowen]'s SublimeText Preferences file: https://jira.lsstcorp.org/secure/attachment/27846/Preferences.sublime-settings  2. Configuration {{flake8}} so that it works in the linting can take a bit of work if {{flake8}} isn't in your default path.  See SublimeLinter.sublime-settings attachment for [~rowen]'s configuration: https://jira.lsstcorp.org/secure/attachment/27845/SublimeLinter.sublime-settings    The above are useful, but we'll need someone to detail the linter stuff more.",1,3.4661877
DM-6083,Enable websocket client to pickup channel parameter from url,send websocket channel information via url.  keep channel information on browser reload.    This is needed for Firefly Python API and external (when Firefly viewer is invoked trough URL) API.  ,1,0.8710353
DM-6086,JSON Schema for metric data from validate_drp to be ingested by the QA Dashboard app,"A well-defined JSON schema is needed for {{validate_drp}}â€™s JSON output so that it can be easily, and consistently ingested into the QA Database. The schema will also make the JSON more self-describing, and potentially useful for other tools to build upon as well.    The schema is being drafted in a thread at https://community.lsst.org/t/json-schema-for-squash/777?u=jsick. Once an informal consensus is reached the schema will be implemented in {{validate_drp}} on this ticket.",8,2.8306239
DM-6087,jenkins job to execute validate_drp and push results to qa dashboard,"This is the initial jenkins job that ""ties"" all the components together.    It needs to:    * execute validate_drp  * push metadata about the jenkins build to qa dashboard  * push the validate_drp metrics to qa dashboard",7,1.7317877
DM-6089,Use fixed width integer types from std instead of boost,The following fixed width integer types are used in the stack:    * {{boost::int16_t}}  * {{boost::int32_t}}  * {{boost::int64_t}}  * {{boost::int8_t}}  * {{boost::uint16_t}}  * {{boost::uint32_t}}  * {{boost::uint64_t}}  * {{boost::uint8_t}}    This ticket aims to replace them with their equivalents from {{cstdint}}.,1,1.9149307
DM-6098,draw a diagram of DRP data flow,"Study Jim Bosch's diagrams and descriptions (Parallelization in Data Release Production, Data Release Production Top-Level Overview), consider inputs/outputs of high level pipelines and parallelization of the DRP, draw a diagram to illustrate the data flow. ",4,5.7493715
DM-6099,Improve afw.table Astropy view support,"DM-5641 completed the first version of Astropy view support, but there is still room for improvement:   - Make {{Footprint}} s in {{SourceCatalog}} s available as a {{dtype=object}} column.  Same for {{Psf}} , {{Wcs}} , {{Calib}} in {{ExposureCatalog}}.   - Use Astropy's coordinate classes for Coord fields (may require an RFC to determine how much we want to use Astropy's coordinate classes).  ",4,3.9670165
DM-6100,afw/tests/rgb.py fails due to .ttf files,"afw/tests/rgb.py fails for me with the below error. We likely shouldn't be trying to track system resources like fonts, as we don't have any control over them.    {code}  [2016-05-12T19:46:12.528961Z] Failed test output:  [2016-05-12T19:46:12.536029Z] tests/rgb.py  [2016-05-12T19:46:12.536057Z]  [2016-05-12T19:46:12.536070Z] ...s......ss...F.  [2016-05-12T19:46:12.536106Z] ======================================================================  [2016-05-12T19:46:12.536138Z] FAIL: testFileDescriptorLeaks (lsst.utils.tests.MemoryTestCase)  [2016-05-12T19:46:12.536173Z] ----------------------------------------------------------------------  [2016-05-12T19:46:12.536192Z] Traceback (most recent call last):  [2016-05-12T19:46:12.536261Z]   File ""/Users/parejkoj/lsst/lsstsw/stack/DarwinX86/utils/2016_01.0-4-g52f464f/python/lsst/utils/tests.py"", line 134, in testFileDescriptorLeaks  [2016-05-12T19:46:12.536330Z]     self.fail(""Failed to close %d file%s"" % (len(diff), ""s"" if len(diff) != 1 else """"))  [2016-05-12T19:46:12.536352Z] AssertionError: Failed to close 2 files  [2016-05-12T19:46:12.536356Z]  [2016-05-12T19:46:12.536391Z] ----------------------------------------------------------------------  [2016-05-12T19:46:12.536404Z] Ran 17 tests in 3.451s  [2016-05-12T19:46:12.536407Z]  [2016-05-12T19:46:12.536424Z] FAILED (failures=1, skipped=3)  [2016-05-12T19:46:12.536445Z] File open: /Library/Fonts/NISC18030.ttf  [2016-05-12T19:46:12.536479Z] File open: /System/Library/Fonts/Apple Color Emoji.ttf  [2016-05-12T19:46:12.536495Z] The following tests failed:  [2016-05-12T19:46:12.539928Z] /Users/parejkoj/lsst/lsstsw/build/afw/tests/.tests/rgb.py.failed  [2016-05-12T19:46:12.540060Z] 1 tests failed  {code}",1,1.3563172
DM-6102,implement basic oauth2 authentication for qa-dashboard,"Per discussion at the SQRE co-working session on Thursday, we agreed to implement minimal authentication for the MVP version of the qa dashboard as an external reverse proxy, such as https://github.com/bitly/oauth2_proxy.",6,2.7153704
DM-6105,Implement the post_save mechanism to update bokeh sessions when new data is available,In tickets/DM-5750 the bokeh python library was integrated in the squash django project. In order to exemplify its use the KPM CI chart is showing only hardcoded values for now.    In this ticket we will implement methods to read the data from the database and the post_save mechanism to update the bokeh session when new data is available.   ,4,1.9302852
DM-6106,color map in visualization,"the four new colormaps introduced in matplotlib last year  http://bids.github.io/colormap/    d3js cmap: http://bl.ocks.org/mbostock/3289530    D3 supports CIELAB (Lab) and CIELCH (HCL) color spaces, which are designed for humans rather than computers. http://bl.ocks.org/mbostock/3014589    ",4,4.169053
DM-6107,Firefly performance profiling and code refactoring if needed,We need to dedicate some effort in each cycle to do the performance profiling and code refactoring needed to improve performance,22,4.2854586
DM-6108,More work on firefly viewer layout control,"More work needs to be done on the triview layout controlling:    * When there is a table with image meta data is loaded, the images need to show with the meta data tab selected  * When any data is pushed then drop downs needs to close  * when a table a catalog table is loaded and there are no plots then then the tri-view should be up with the coverage tab selected. When there is plots then the coverage tab should not be selected.  * we need a way to remove load a table and then only see the table, same with xy-plots  * catalog and image meta data are determined by looking at the data.  However, we might need this logic in a single function  * when a table is loaded and we cannot determine what type it is then the table and the xyplots only should some up.  * When all data is deleted the default tab should open.  (in IRSAViewer case the is the select image panel)",8,5.0163746
DM-6111,Browsers should cache editions for a shorter time period than Fastly,"Currently we set {{Cache-Control: max-age=31536000}} so that Fastly caches uploads from LTD Mason for a year on its POPs. This has the side-effect of also having browsers potentially cache documentation on the client for up to a year. In practice, browsers churn through their cache space more quickly, but I've noticed that Safari has no cap on its cache space, and therefore can hold onto pages for a long time.    The solution is to set a {{Surrogate-Control}} max age to 1 year, and have {{Cache-Control: max-age=0, private, must-revalidate}}. This will be done on LTD Keeper during the copy phase of a build into an edition (since it is reasonable for a client to cache a build forever), but then give us the flexibility to update an edition instantly.    In the future we may want a more nuanced solution where CSS and JavaScript, for example, are cached longer on the browser.",1,2.5258613
DM-6112,Provide minimal documentation for meas_extensions_photometryKron,"Please provide a minimal level of documentation for meas_extensions_photometryKron, to include:  * A doc directory with the usual content so that docstrings get generated by Doxygen;  * A package overview;  * All docstrings should be appropriate for parsing by Doxygen (ie, should start with {{""""""!}} where necessary).  ",1,0.8069584
DM-6113,Calibration Products Pipeline work during F17,"This will need to be properly fleshed out before scheduling: for now, it's a bucket for stories that [~mfisherlevine] is unlikely to complete in X16. [~rhl], [~mfisherlevine] & [~swinbank] to provide further definition.",65,8.24446
DM-6118,The color stretch dialog box does not work properly,"There are a few issues in the Color Stretch dialog box:  # When the asinh or gamma algorithm is selected,  the asinh parameters and gamma parameters are always reset to the default.  The user-entered values can not be kept and used.   # When there are two or more images, when the lower/upper range in one of the image is set, the lower/upper range in all the rest images are set to the same lower/upper range.    # The rangeValues are always reset each time when the Color Stretch dialog is open.  ",5,0.94649214
DM-6119,"update ""newinstall.sh"" nebula images & docker containers - w_2016_20",,1,1.4842083
DM-6121,Remove old DipoleMeasurementAlgorithm from imageDifference.py,"Currently the new algorithm is run alongside the old. This ticket will deprecate the old algorithm, making the new one the default. This will be done after the new algorithm is vetted on real data (DM-5412).  It may also be blocked by the pending SFM overhaul so that it can be implemented as a standard registered plugin.",4,0.86437315
DM-6123,Build SFM housing for PSF approximation using ngmix code,"Build a measurement plugin which allows PSF approximation to be done using ngmix.  After consulting with Erin, it was decided that this would make use of the EM code and would produce as its output some variable number of Gaussians.  These will be turned into MultiShapeletFunction outputs.    A suitable set of configuration options and output failure flags will also be provided.",6,3.9162047
DM-6124,Testing ngmix Psf plugin with CModel,Test that the ngmix PSF approx plugin works correctly in our measurement framework by testing it with CModel and comparing results with those produced with ShapeletPsfApprox.,6,4.251739
DM-6125,Do robustness tests of ngmix PSF approx plugin,"Run tests on the ngmix PSF approx plugin similar to those which were run on ShapeletPsfApprox.  We will test both for how long the plugin takes to run, and how often it fails.    Note previous report on CModel and SPA was DM-4368",6,4.342499
DM-6126,LSST's version of Astrometry.net doesn't build on Ubuntu 16.04,"Reproduced building on Ubuntu 16.04.    https://groups.google.com/forum/#!topic/astrometry/aDCjhfMYhpE    The current version (0.67) does build successfully standalone.    These two patches fix 0.5.0:  https://github.com/dstndstn/astrometry.net/commit/7ded70917d7cf1efa1d3af6d0da8b336ebbf9d92.diff and https://github.com/dstndstn/astrometry.net/commit/7c65b3cefc4f33c59af90c1a40b5f246002cdf28.diff  Though only the first one is needed, I believe the second one is part of the build already.",1,2.107669
DM-6127,ngmix has no license,"ngmix does not have a license, which means we shouldn't distribute it. Work with Erin Sheldon to see if he is willing to add one.",1,1.6142424
DM-6128,Expanded view not doing fit/fill consistently ,"Expanded view not doing fit/fill consistently. Sometimes is seems to fit/fill and resize it correctly, other times it stays at the zoom level.  It should always fit/fill and change zoom level with resize when in expanded mode. (unless zoom type is FORCE_STANDARD).",2,3.8701525
DM-6130,Fix docker git script: providing both -R and QSERV_DIR make it fails,,2,0.5716443
DM-6133,mpi4py does not compile under Yosemite due to hardcoded MACOSX_DEPLOYMENT_TARGET,"{{mpi4py}} build on Yosemite (Mac OS X 10.10) fails with   {code}  _build.log:[2016-05-17T16:51:55.847161Z] error: $MACOSX_DEPLOYMENT_TARGET mismatch: now ""10.9"" but ""10.10"" during configure  {code}    For details see attached build log.    The {{MACOSX_DEPLOYMENT_TARGET}} is being set in {{ups/eupspkg.cfg.sh}}    {code}  [serenity mpi4py] cat ups/eupspkg.cfg.sh  # If MACOSX_DEPLOYMENT_TARGET is not set, we force it to be at least 10.9  # (Mavericks). This is the earliest version of OS X expected to work with  # release 11 of the LSST stack.  # This works around DM-5409, wherein mpi4py was attempting to use an OS X 10.5  # SDK, based on querying Anaconda, and failing.  export MACOSX_DEPLOYMENT_TARGET=${MACOSX_DEPLOYMENT_TARGET:-10.9}  {code}    What is it that is supposed to be setting {{MACOSX_DEPLOYMENT_TARGET}}?  And why is it not set at the time when {{ups/eupspkg.cfg.sh}} is run, but is set to 10.10 by the time the actually compilation is done?   ",1,2.455933
DM-6134,Fix style of catalog panel , finish up DM-5388 ticket by fixing the UI style of the panel,4,2.3105266
DM-6135,Migrate VO search panel,VO search panel is a tab part of the catalog drop down panel that should be migrated. This was an outlier of DM-5388 ticket.,16,4.729763
DM-6136,Review and connect validation part to the input area field component,Catalog panel (DM-5388) needed an input area for polygon input search but it needs a review and connect the validation reducer to it.,6,4.39199
DM-6137,Add input based on catalog DD table,"Add a panel to use DD catalog information to allow user to input catalog constraints as editable table component.    This is to get a table with one or more extra column which are input field. The extra column needs  a different default cell renderer (TextCell) - see TableRender.js.  This table component needs to be hooked up to the fieldgroup or some way so it can be used in the catalog search panel.   The catalog search panel will need to be adapted to display this table constraints to fully complete the search query options.    The implementation:  It contains the redesigned panel based on IRSA current OPS catalog search. A table with input constraints and sql area input are added.   There is a lot in that PR. In particular, usage of table renderers and 'fieldgroup' together with a changed BasicTable component to be able to get the value from input field custom column 'constraints'.   The panel will be reviewed also by IRSA and some input requirements were left out for now (mainly aesthetic details). Another left-out is the text are component and the validation of it. That should be addressed in the other ticket DM-6136. ",12,2.3273718
DM-6138,Change Fields groups to handle other actions better,"The fields group can be out of sync with actions if they are trying to use store data when that actual value is changes.  This is a classic side-effect issue.  It can be solved with sagas.    Our current example.  The color panels updating from the plot when the activePlotId changes.    More to do:  * field groups need a sega to more effective respond to out side actions  * the dispatchChangeFieldGroup needs better, more documented parameters  * update multiple fields at the same time.  * should we have the field group support reset to init state? probably not, but look into it.  * change init values?  * Check example dialog and see if the large/smaller example is validating correctly.",2,1.4798832
DM-6139,Change server side hardcopy code to work better with the non-GWT call,The server hard to make a hard copy now takes a StaticDrawInfo object.  We want to use only a region array.  Change the server side to support this.,2,1.6743212
DM-6140,Produce tech note describing detailed project management procedures,Write a technical note describing the detailed project management procedures derived by the pmp-wg. Source material is [~jbecla]'s document at https://github.com/lsst/ldm-pmt/.,8,4.302212
DM-6141,Drawing layer improvement to handle mouse selection,"Drawing layers are not handling and sharing the mouse quite  right.  Also the mechanism to determine to is priority for the mouse needs work as well. This is all necessary to make markers work correctly, since every marker is an individual drawing layer.     Also, the draw layer utilities are all in PlotViewUtil.js.  They need to be moved to something closer to the draw layers.",4,3.2309473
DM-6142,Client side Hardcopy support for png with drawing layer overlay,Add all hard copy support so we can create a png with all the overlays.,6,3.5327017
DM-6145,jenkins/qa terraform destroy fails if there is an existing rds final snapshot,AWS appears to prevent the overwrite of an existing final rds snapshot.  This scenario may arise when creating/destroying a dev env multiple times.  This can be avoided by disabling the final snapshot when destroying an rds instance.  One way to resolve this would be to add a terraform var to signal this is his is a development env.,2,0.47633642
DM-6146,Evaluate performance of dipole fitting in crowded regions,"There are legitimate concerns about performance of the new dipole fitting algorithm in crowded fields. This will be evaluated (on real data? if no existing data, then realistic simulated data) and contrasted with other possible alternatives. This is in response to Zejlko's concern and suggestion that DipoleFitTask should constrain only positions using pre-subtraction images, and only fit fluxes using the diffim.",8,5.369604
DM-6147,Set SUSPECT mask in ISR task and make saturation a double,"Implement RFC-190 and mask suspect pixels:    Add {{selectLevel}} to {{lsst.afw.cameraGeom.AmpInfoCatalog}}, as a double, and add support for it to {{lsst.ip.isr.IsrTask}}, analogously to masking saturation: iif {{suspectLevel}} is not {{nan}} then set the {{SUSPECT}} flag for pixels above the suspect level.    Also change the type of {{saturation}} in the {{AmpInfoCatalog}} from {{int}} to {{double}}, so that the existing test for {{nan}} actually works",5,0.62159353
DM-6149,Reduce memory utilization in mysql proxy,Jon is trying to run tests with large result which kills proxy/czar because it runs out of virtual memory. Would be nice to reduce memory use and find a way not to keep query result in memory.,2,2.2421086
DM-6151,Failure to fail when fallbackFilterName is None,"When no {{fallbackFilterName}} is set, we can get a confusing error message when failing to load a calib:  {code}  RuntimeError: Unable to retrieve dark for {'filter': 'U', 'date': '2016-05-12T02:58:56.591', 'ccd': 0, 'basename': '2016-05-12skyflats_02', 'object': 'FLAT', 'visit': 883, 'expTime': 20.0006, 'channel': 16} and no fallback filter specified: Unknown value type for filter: <type 'NoneType'>  {code}  This is unrelated to the calib load failure, and merely reflects the fact that {{fallbackFilterName=None}}.",1,0.8033403
DM-6153,long term re-plan,"We need to make the long term plan for FY2017 - FY2019, ready for ComCam; and more FY2020- FY2022, ready for operation.",30,1.9214051
DM-6154,New features in histogram ,". 1D histogram, maybe a special case of density plot  . new way to calculate the bin size?  ",10,2.6153195
DM-6155,Attend SciPi WG meeting,Attend the Science Pipelines Working Group meeting in Seattle.,8,1.9128327
DM-6156,Attend SciPi WG phonecon,Attend the Science Pipelines working group meeting by video con.,3,2.382111
DM-6157,Flesh out MOPS work,Work with Lynne Jones and Colin Slater to flesh out the high level MOPS design to a point where we can plane the risk associated with each component.,3,5.8731375
DM-6158,Attend SciPi WG F2F in Tucson,Attend the Science Pipelines working group face to face meeting in Tucson.,3,4.166208
DM-6159,Flesh out the Level 1 processing diagram,Andy and I need to make sure we understand the Level 1 processing.,10,5.567861
DM-6160,Adding an int to the end of CzarConfig causes a segfault error.,Adding and int to the private members of CzarConfig causes a segfault when Czar::Czar() calls LOG_CONFIG(logConfig);. gdb shows logConfig is the correct string value but somewhere in log4cxx something is corrupted and causes a segfault.    Adding an int to the end of Czar (the class where CzarConfig is instantiated) does not cause the issue. ,6,2.402931
DM-6162,Investigate how the diffim decorrelation correction works for the case of non-uniform PSFs and noise,"It is not clear whether, or how, the L(ZOGY) post-convolution kernel (PCK; see DM-5914) will work for non-uniform PSFs or noise/variance. This will be investigated using the simple implementation from DM-5914.     Tasks:  1. Determine whether variation in the PCK across the field is significant enough to matter for typical LSST images  2. If it does matter, investigate options for performing interpolation of the PCK across the field, or via calculating the PCK across the field from the spatially-varying matching kernel. ",8,3.2944694
DM-6165,Extend the capabilities of the StarFast simulator beyond the minimum needed for DCR algorithm testing,During development of the StarFast simulator for DCR correction algorithm testing several addition features were identified that would make it more general and useful. These capabilities will enable a wider range of testing of new image differencing algorithms and give greater confidence in the accuracy of the results for DCR simulations. ,14,5.0227747
DM-6166,Time AST and compare to our WCS code,"Time TAN-SIP for our code and for AST, in order to get a sense of the performance impact of switching to AST for our WCS implementation.",3,4.6442285
DM-6167,Create DMBP project in jira,"Create a new project in JIRA (DM Baseline Plan), spec provided here: https://confluence.lsstcorp.org/display/DM/ProjMgmtWG%3A+The+New+DLP  I am sure we will fine tune it, but it is a (hopefully good) start.",2,2.5570538
DM-6168,Wrap afw using pybind11,"Experiment with using pybind11 (rather than Swig) to expose afw, and the packages it depends on,  to Python.    The concrete result of this epic is an assessment of the utility gained by wrapping the rest of the stack in pybind11 and an estimate of the time that would be required to carry out that work. If those goals are reached without completing the work on afw, we can claim success. In particular, if it becomes clear early in the epic that there is no long term utility here, we should abort the rest of the work.",80,5.728788
DM-6169,Participate in DM replanning process,"Participate in the ongoing DM replanning process. This includes contributions to both the scipi-wg and pmp-wg, including such documentation writing or other tasks as the chairs of the those groups request, as well as resource loading and delivering the complete plan.",100,4.7067204
DM-6170,PSF fitting study,"Investigate the [Piff|https://github.com/rmjarvis/Piff/] PSF modelling code. Experiment with applying it to realistic LSST (or precursor) data. Discuss whether it is an improvement over existing techniques, and a recommendation as to whether it should be adopted in the stack. (NB writing the code to incorporate it into the stack is not a requirement of this epic, but may be a desirable side-effect).    If Piff is still too immature for this to be useful, investigate Kendrick Smith's [hscpsf|https://github.com/lsst-dm/meas_extensions_hscpsf/] code.",15,5.8925233
DM-6171,Service technical debt accumulated in earlier cycles,Service technical debt accumulated in earlier cycles.,100,5.547704
DM-6172,F16 DRP emergent work,Handle emergent work during F16.,55,25.565144
DM-6173,Serve as chair of the IVOA Time Domain Interest Group,[~swinbank] will serve as chair of the IVOA Time Domain Interest Group through May 2017. This epic captures work associated with that activity in F16.,20,6.472742
DM-6174,Prepare for and participate in SBAG meeting,"By request of [~zivezic], [~nlust] will participate in the June 2016 meeting of the [Small Bodies Assessment Group|http://www.lpi.usra.edu/sbag/meetings/]. This epic captures work associated with preparation for that meeting.",20,2.0748732
DM-6175,Visualization tools for Science Pipelines,[~nlust] will collaborate with the SUIT group on development of appropriate visualization tools in support of the work of the Science Pipelines group during F16.    [~xiuqin] will provide further specification of success criteria.,20,8.494376
DM-6176,Optimal coaddition,"Experiment with building ""optimal"" coadds, as defined by [DMTN-015|http://dmtn-015.lsst.io/en/latest/].    The aim here is to be able to generate coadds for experimentation with measurement algorithms. The expected output is appropriate mathematical formalism and prototype code. Polished integration of this facility with the LSST stack is not a requirement (but may be a useful by-product) of this work.",100,2.923242
DM-6177,Increase memory locked amount in container,"In order to lock memory, the memory locking limit within the container for the qserv worker needs to be raised. My understanding is the container uses whatever is the host setting so the limit has to be set for the container user and whatever the user is inside the container. The particular limits is:    memorylocked 64 kbytes    notice that by default it's 64K. That needs to be raised to say 75% of the real machine size. I wouldn't make it unlimited as a memlock mistake may crash the whole machine. The limits are specified in ""/etc/security/limits.conf"". You will know that you are successul when you ssh into the container as the qserv worker user and the ""limit"" command tell you have can lock lots of memory.    We would also set the CAP_IPC_LOCK privilege but setting the soft/hard limit above should be good enough. So, let's start with that. ",2,3.3247592
DM-6178,Add eups version for Qserv for stack package version,"For stack packaged Qserv version, version needs to be retrieved and added to monitor.yaml using next command:    dev@clrinfopc04:~/src/qserv$ eups list qserv -s -V  LOCAL:/home/dev/src/qserv    Indeed, pkgautorversion doesn't work in this case, I.e. with no git repos",2,1.7850027
DM-6179,Support Python 3 migration,"Support the migration of the DM code to Python 3. This includes writing transition documentation, integration of a new scons, migrating a handful of low-level packages and liaising with the teams on their packages.    The final outcome of this epic is that everything would be in place for the migration at the August All Hands meeting.",40,4.470631
DM-6180,Update LSE-61 requirements and traceability,"With the updates to DPDD and LDM-151 in the early part of F16, there is a need to update LSE-61 (DMSR) such that it can directly trace requirements from OSS+DPDD through LSE-61 and down to implementation LDM documents.    This will require substantial rewrites of many of the existing requirements and possible addition of new requirements. It may also be necessary to add annotations to DPDD and other LDM documents to provide traceability anchors for DMSR.    The outcome of this epic is a new baselined DMSR approved by CCB.",40,4.5240827
DM-6181,reST roles for JIRA References,"Add {{:jira:`DM-1234`}}-type roles to documenteer so that JIRA tickets, epics and RFCs can be referenced easily from all of our Sphinx-based projects.",2,3.4365172
DM-6183,sourceSelector needs a schema in ImageDifferenceTask,imageDifference.py crashes with a vague error on initializing the sourceSelector task. The problem turns out to be that sourceSelector needs a schema passed in.,1,1.0825396
DM-6184,Add a python 3 Jenkins instance,We need a Jenkins instance where the default python in the PATH is python3 (where version >= 3.4 with 3.5 preferred). The underlying OS does not matter.    A prerequisite of this is a modification to the {{lsstsw}} {{bin/deploy}} script to allow Python3 to be installed ({{miniconda3}} EUPS package?) rather than python2.    Modifying the EUPS {{scons}} and {{python}} packages is outside the scope of this ticket. A build of a third-party EUPS package is sufficient demonstration of the capability.,12,1.9647247
DM-6185,Get jointcal running on minimum data,"It is very important for other teams to have a version of jointcal running to remove the sensitivity on the errors in astrometric reference catalogs.  The suggestion is to get jointcal running with CFHT, HSC, DECam and lsstSim.",100,3.924206
DM-6186,Provide input for the update of LDM-151,We need to update the Level 1 portions of LDM-151 to be both more descriptive and close to what we actually plan to deliver.  This will involve breaking down things to a finer level of planning as well as delivering content for the document.,38,2.7125525
DM-6188,"First draft of overview (""vision"") document",See https://dmtn-016.lsst.io,3,1.1778423
DM-6189,Complete update to LDM-230,"Complete an update to LDM-230 and submit to TCT for re-baselining.  Along the way, contribute to and review other documents needed by DPS-WG.",10,1.8816508
DM-6190,Update sizing/cost model,"Contribute to the updating of the sizing/cost model, including fixing known bugs, synchronizing the inputs and models to fit the current baseline, and investigating changing the modeling technology.",10,4.5584345
DM-6191,Refine SuperTask design document,Deliver a refined SuperTask design document including reslicing to accommodate changes in the axis of parallelization between SuperTasks making up a composite SuperTask.,13,3.4123223
DM-6192,Update LSE-75 DM-TCS ICD,Submit an LCR to update LSE-75 to reflect current thinking on telemetry feedback from DM to the TCS.,5,2.925505
DM-6193,Update LSE-72 DM-OCS ICD,Submit an LCR to update LSE-72 to reflect changes discovered by work at NCSA to support early integration tests.,5,2.9818478
DM-6194,Update LSE-68 DM-Camera DAQ ICD,"Submit an LCR to update LSE-68 to reflect understandings developed between Mike Huffer and NCSA about the interface, including the image deletion policy for the camera data buffer.",5,3.153492
DM-6195,Provide input to Commissioning Plan,Provide input based on understanding of the DM interfaces to the Commissioning Plan being developed by Chuck Claver.,5,3.9403317
DM-6196,SQuaSH capability extension: multiple testdata service,"This epic covers work to deliver the following improvements to the SQuaSH prototype stood up in X16:    - drilldown 1 level (time series->histogram)    - multiple testdata options (requires jenkins, backend, dashboard extension)    - processccd + validate_drp pseudo-workflow    - pseudo-provenance (track manifest.txt - real LSST provenance system will be swapped in for extensive functionality when available)   ",92,6.4250364
DM-6197,Update LSE-76 Summit ICD,Submit an LCR to update LSE-76 based on Summit rack and power needs obtained from Ron Lambert.,2,2.541533
DM-6198,Ad-hoc Docs & Comms requests,Timeboxed epic for in-cycle ad-hoc developer or management requests. In the first half of FY16 most of these are likely to be deveoper-guide related. ,12,2.5996492
DM-6199,Stack API documentation ,Stack API Doc generation -> pipelines.lsst.io,20,2.7049007
DM-6201,Resource load F16 part II,Resource load for second half of F16    (SP estimate from first half),6,8.650183
DM-6202,"SQuare Requirement, Design, & Review Docs for DM","This is an epic to track the work required on for DM baselined documentation from SQuaRE staff, including any associated with Working Group / replan etc    [FE: 45% MWV: 45% DN: 10%]    ",35,5.24064
DM-6203,Releases and Release Engineering Improvements,  [50% FE 50% MJP],16,13.781173
DM-6204,Build/CI/Deploy improvements requested by the DAX/Qserv team,  Requests for Build/CI/Deploy improvements initiated by the DAX/Qserv team prioritised on request from the DM Project Manager.     ,24,3.3496563
DM-6205,Build/CI/Deploy improvements requested by the Architecture Team,  Build/CI/Deploy improvements requested by the Architecture Team prioritised by request from the DM System Architect.     They cover predominantly support for the Python3 support. ,4,4.883364
DM-6206,CI Improvements: Jenkins 2 upgrade etc,"  This epic covers a timeboxed maintainance of the Jenkins-based CI system, including the Jenkins 2 upgrade as well as the required updates to the Jenkins-puppet module. It also may include work done as part of DM-6204 brought over to the apps CI service. ",8,5.638214
DM-6207,CI/Build/Deploy improvements for Sims,This is a timeboxed effort to prioritise support requests from the Sims group,4,5.2421336
DM-6208,SQuaRE services disaster recovery,This is a timeboxed effort to test and improve backups and disaster recovery for SQuaRE services. It is unlikely to be sufficient in itself. ,8,8.546385
DM-6209,Ad-hoc developer requests,"This is a bucket epic for ad-hoc developer requests that cannot be postponed till the next planning cycle. In the event that it is underutilised for this purpose, it will be assigned to technical debt DM-5850",8,2.712159
DM-6210,Improve OSX support,,16,4.937615
DM-6211,Gitlfs maintenance - protocol upgrade etc,,8,5.2962656
DM-6212,Slack migration,,8,3.9775863
DM-6213,Conda binary distribution improvements,,16,7.060384
DM-6214,logging.lsst.codes improvements,,8,3.6742756
DM-6215,Verification dataset exploratory work,[DN 50% AF 50%],16,5.421694
DM-6216,F16 DAX Services Containers & Ops,,10,40.123894
DM-6217,F16 DAX Services Improvements,,10,56.421574
DM-6218,F16 NCSA Dax Services Deploy,,10,35.407883
DM-6219,F16 Replan,,33,9.3167305
DM-6221,F16 Support SUIT for Prototype DAC,,40,22.124321
DM-6222,F16 L1 DB Prototype I,,89,34.370197
DM-6223,F16 NCSA Stripe 82 Image Ingest,,36,17.554789
DM-6224,F16 Butler Repository Refactor,"Per KT, the parent/peer repository relationship scheme was not an exact fit for what we need. We discussed and decided that butler should manage its own input and output repositories. Also discussed with KT and Gregory was the ability to select inputs by 'tagging' repositories. The design discussion with the larger group is captured in RFC-184.",40,48.644558
DM-6225,F16 Butler Storage & Format Refactor,"We want a pluggable architecture that allows code that uses butler to be able to define the the storage format and location from configuration and/or run time code.  (maybe it's implicit in this epic, but we need to define, design, RFC, and implement this feature.)",35,48.093067
DM-6226,F16 Butler Composite Dataset Design,"Do design, RFC, and some prototype code for loading and saving ""composite datasets"" via butler.    Composite Dataset definition: a python objects loaded by butler from file/database/etc that is persisted in more than one physical location (e.g. more than one file on disk). Those objects should also be able to be written to more than one physical location - the design should support this but the initial implementation may not be required to have this. ",50,52.93087
DM-6227,F16 Butler Repo of Repos Design,,20,43.119118
DM-6228,F16 VO Standards Investigation,,10,51.394104
DM-6230,F16 Qserv Loader Improvements,,100,48.63629
DM-6231,F16 Qserv Containers and Ops,,16,35.483032
DM-6232,F16 QServ Improvements,,82,60.723568
DM-6233,F16 NCSA Qserv Deploy,,34,32.969345
DM-6234,F16 NCSA Stripe 82 Catalog Ingest,,20,20.578884
DM-6235,"Take part in LDM-151 Progress Meeting, 2016-05-27",,1,3.1507757
DM-6236,"Take part in LDM-151 Progress Meeting, 2016-05-27",,1,3.1507757
DM-6237,"Take part in LDM-151 Progress Meeting, 2016-05-27",,1,3.1507757
DM-6238,Familiarization with RHL calibration documentation,,4,4.6297846
DM-6239,The grid labels are not placed in the right position when the coordinate is Ecliptic coordianates,The algorithm to calculate the label position does not work well for the Ecliptic coordinate system.  The algorithm needs to be modified to work for all the coordinates.,2,2.643668
DM-6240,Support API interaction with Regions,"We now need more fine grain controls over regions:    From API, user can:    * load region file  * delete region layer  * add a region entry to a layer  * delete a region entry from a layer    When this ticket is complete, region conversion should be completed.",10,5.4341555
DM-6241,Implement the ZOGY extension to the A&L algorithm in the stack,"DM-5422 provided a test implementation of the real space extension to the A&L algorithm for a correction kernel motivated by the ZOGY paper.  This epic is to take that test algorithm and incorporate it so that it can be used by the diffim tasks.    The first step will be to incorporate it using a static PSF t compute the correction kernel.  The second will be to evaluate how that affects the resultant difference image.  This should also include an estimate of the overall performance relative to the base A&L algorithm by examining runtime, false positive rate, and accuracy of noise estimation in both the detection threshold and the reported measurement SNR.",30,3.8150673
DM-6242,Study spatial variability of ZOGY correction,DM-6241 looked at how the correction term to the A&L algorithm performs under the simplifying assumption that the science image PSF is spatially invariant (though the matching kernel is spatially varying).  This epic will focus on how to extend the correction to include spatially varying terms.,38,4.5829687
DM-6243,Study the impact of having a spatially invariant decorrelation correction factor to A&L,The initial implementation of the A&L + noise whitening correction term assumes a single matching kernel and variance value(s) for the image(s) in the correction kernel.  We should assess how well that assumption performs in simulated and real images.  One test would be the variance and covariance in the noise as a function of position in a set of typical images.,8,3.6826153
DM-6244,Assess performance of the decorrelation correction to A&L,"Study the performance when using the (currently, spatially invariant) correction term to the base A&L algorithm in terms of runtime, detection threshold, reported measurement noise, and false positive rate for similarly tuned versions of both the base algorithm and that with the correction applied.",6,3.0356665
DM-6245,Compare competing algorithms for correcting DCR in template images,DM-5455 provides an implementation of a correction algorithm that depends on a matrix inversion approach to correct for DCR.  This should provide another approach for comparison (potentially a more forward modeling based approach).    Compare the algorithms in a simplified system in 2-D where DCR is along one axis.  The algorithms should be extended to arbitrary rotations.  The bakeoff will be repeated in the case of arbitrary rotations.    The result should be a recommendation as to the algorithm to use for DCR correction in template images.,49,2.010225
DM-6246,Vertical overscan off by one again,"In DM-5524 [~price] fixed the vertical overscan by directly editing the amp info catalogs, but didn't mark the camera generating code as bad. In DM-6147 I regenerated the files, reintroducing the problem. The problem seems to be a subtle bug in the camera generating code. Rather than try to fix it, I'll convert the fixed catalogs directly and mark the generating code as broken. [~price] will issue an RFC that suggests a better way to handle generating amp info and once that is dealt with we can come up with a more permanent fix (e.g. delete the generating code or fix it).",1,2.294439
DM-6247,DRP Outline for LDM-151,"Write outline for Data Release Production section of LDM-151, using the DRP Data Flow diagram as the organizing principle.",2,5.997303
DM-6248,"DRP Top-Level Diagram and Descriptions, Draft 1","Insert the content from the DRP Data Flow diagram on Confluence into LDM-151, adjusting it to the outline developed on DM-6247.",2,4.928652
DM-6249,Implement competing algorithm,Implement a competing (potentially a forward modeling approach) algorithm for correcting DCR in templates.,12,4.458573
DM-6250,Extend competing algorithm to arbitrary rotation angles.,,6,2.6825492
DM-6251,Convert DRP Top-Level Diagram to standard conventions,"DM-6248 adds a large, complex diagram that will need to be cleaned up and converted to use the same conventions and colors as other diagrams in LDM-151.",2,3.1430216
DM-6252,Do bakeoff between the two algorithms in simplified case,"The original matrix inversion technique and the competing technique will likely have different sensitivities.  This should be a comparison of the algorithms, likely based on numbers of dipoles, along with performance (memory and runtime) considerations.    This will be done on 2-D images with DCR along one axis.",6,3.2317965
DM-6253,Bakeoff between algorithms extended to arbitrary rotation.,Redo bakeoff in the case of arbitrary rotation in DCR effect.,6,3.1418538
DM-6254,Develop standard conventions and colors for LDM-151 diagrams,"We want diagrams in LDM-151 to have consistent notation and colors, and to be produced using the same tool.  Someone needs to look at the diagrams produced so far to gather requirements, decide on and document these conventions, and select the tool we'll use to produce them.",4,3.0250635
DM-6255,Improve detail for for DRP imchar/jointcal in LDM-151,Write more detailed descriptions and possibly draw a rough diagram for the single-frame processing and simultaneous calibration components of Data Release Production.    Does not necessarily involve turning this section into prose.,6,3.0607524
DM-6256,"Improve detail for DRP background matching, coaddition, and diffim in LDM-151",,4,3.5502694
DM-6257,Improve detail for DRP coadd processing in LDM-151,,2,3.741215
DM-6258,Improve detail for DRP object characterization in LDM-151,"Includes coadd measurement, multifit, and forced photometry.    Could be faster to write than other sections because we can lift from ""blended-measurement"" document that already exists in LDM-151 repo; could be harder because that document has already exposed a number of unresolved questions that may need to be addressed (by at least getting agreement among pundits on the best-bet approaches) before we can plan.",4,4.119114
DM-6259,Improve detail for DRP afterburners and level-3 gathering in LDM-151,,2,3.824844
DM-6260,Cleanup and standardize DRP imchar/jointcal diagrams,"DM-6255 will produce some rough, draft-level diagrams that will need cleanup and standardization.",1,3.037997
DM-6261,"Cleanup and standardize DRP background matching, coaddition, and diffim diagrams","DM-6256 will produce rough diagrams that will require cleanup and standardization.    [~ctslater] has made some suggestions for the current diagram that I'll implement on this issue, so I'm assigning it back to me.  I'll also go ahead and integrate his updated DRP overview diagram (currently on Confluence) into LDM-151 here.  ",1,3.3684256
DM-6262,"Cleanup and standardize DRP detection, association, and deblending diagrams","DM-6257 will produce rough, draft-level diagrams that will require cleanup and standardization.",1,3.6340914
DM-6263,Cleanup and standardize DRP object characterization diagrams,"DM-6258 will produce rough, draft-level diagrams that will require cleanup and standardization.",1,4.0552
DM-6264,Cleanup and standardize DRP afterburners and level-3 gathering diagrams,"DM-6259 will produce rough, draft-level diagrams that will require cleanup and standardization.",1,3.7160623
DM-6265,Audit DRP LDM-151 for correct handling of chromaticity,"Correctly handling wavelength-dependent photometric and PSF effects is one of the biggest qualitative differences between the current state-of-the-art and what we have in mind for LSST, and that makes it easy to get wrong.  We need to make sure all steps that produce high-quality fluxes or rely on high-quality PSFs have access to object colors and a reasonable approach to using them.  ",2,4.431002
DM-6266,Upgrade cfitsio and deal with long keyword handling,"To implement RFC-105, we need to figure out how we are handling long FITS header keywords, before we can upgrade to cfitsio 3.38 or newer. There may be other FITS-related idiosyncrasies in the stack that may be brought to light while upgrading, as 3.38 has changed how it handles some of the non-standard conventions.    See some of the notes in DM-4115 for problems encountered while attempting to upgrade to the 3.38 beta.",20,2.2179463
DM-6269,Attend HTCondor Week,Attend HTCondor Week with [~gdaues] to learn about condor and pegasus  http://research.cs.wisc.edu/htcondor/HTCondorWeek2016/index.html,20,1.9428287
DM-6270,Review of Workflow Systems,"Review different workflows and write a final comparison report. The plan is to look at up to 8 workflows. Current list of workflows:  - pegasus, HTCondor  - panda  - swift  - ...    Each review should take around 3 days. The goal is to review the workflows systems with:  - longevity, how long has the system been around, what is the funding?  - use cases, who is using it?  - scale, how large of a workflow has it used?  - code, is the code open, how is the developer community, does it have python bindings?  - GUI, does it have some easy way to monitor the workflow?  - can we generate workflows programmatically?  - what clusters are supported?    Ideally we should also try and get it up and running and maybe even generate a dummy workflow. Discussion could be how we can prototype DRP and use that as a use case.    Deliverable: Evaluation report  Staff: Rob Kooper, Hsin-Fang Chiang, Matias Carrasco Kind, Mikolaj Kowalik, Steve Pietrowicz  Effort: 25 days  Planned Start: 6/1/2016  Planned End: 6/30/2016",50,8.210213
DM-6271,Audit DRP LDM-151 for correct handling of crowded fields,"[~jbosch]'s background is in extragalactic science on high-latitude fields, and he frequently forgets to think about how algorithms will perform in crowded stellar fields.  When the first draft is complete, we should have someone experienced in that area read closely to check that he hasn't made any incorrect algorithmic assumptions as a result.",1,3.4819503
DM-6272,Reception and Placement,,7,3.5927663
DM-6273,Statement of Work ,,12,3.750963
DM-6274,Propose extension of SuperTask functionality for workflow package,"Should see what is needed to add to supertask so we can use it with workflows. After this is decided we should create a RFC for implementation.    Deliverable: RFC to extend SuperTask  Staff: Rob Kooper, Matias Carrasco Kind, Mikolaj Kowalik  Effort: 5 days  Planned Start: 6/1/2016  Planned End: 6/22/2016",10,2.9668717
DM-6275,Implementation of Supertask RFC,"This should implement the RFC written in DM-6274.  Note that this activity is independent of the work to complete the supertask and activator prototype in DM-6418.    Deliverable: Deliverables based on outcome of RFC  Staff: Matias Carrasco Kind, Mikolaj Kowalik  Effort: 15 days  Planned Start: 7/1/2016  Planned End: 7/31/2016",30,3.9731035
DM-6276,ConOps for Workflow/Middleware,"Create a conops for workflow, this will depend on some decisions made about L2 conops.    Deliverable: ConOps document for Workflow  Staff: Rob Kooper, Hsin-Fang Chiang, Matias Carrasco Kind, Steve Pietrowicz, Jason Alt, Margaret Johnson  Effort: 15 days  Planned Start: 7/1/2016  Planned End: 7/31/2016",30,7.1686373
DM-6277,Proof of Concept Implementation of Workflow System,"This should start the implementation of the workflow system. This will be a proof of concept only.    Deliverable: Proof of concept workflow implementation code  Staff: Hsin-Fang Chiang, Mikolaj Kowalik, Rob Kooper, Steve Pietrowicz  Effort: 20 days  Planned Start: 8/1/2016  Planned End: 8/31/2016",40,10.627152
DM-6278,Investigate proper precision for afw::image::Image pixel transforms,"The various pixel based transforms in {{afw/src/image/Image.cc}} were converted from using {{boost::lambda}} to C++11 lambda per DM-6091.    At many places the previous implementation contained implicit casts (through {{boost::ret}}) of intermediate results to {{PixelT}} (e.g. {{float}}).  In particular this affects opperations such as {{result = l + c*r}} where {{l}} is the left hand side image, {{r}} is the right hand side image and {{c}} a {{double}} constant.  When calculated at double precision (e.g. without the casts, which are not needed with C++11 lambdas) the result is slightly different and this causes {{tests/testProcessCcd.py}} to fail on {{self.assertAlmostEqual(psfIyy, 2.17386182921239, places=7)}} which is only equal up to the fifth place.    In order to not break existing behaviour I added explicit casts to {{PixelT}} for intermediate results. But this approach is questionable as the end result will be less accurate then possible. The aim of this ticket is to decide which approach is best:    1. Calculate at full precision and modify the test case.  2. Cast intermediate results to final precision (as it is done now).  3. Do something else?",1,2.4548254
DM-6279,Fix possible logic error in pex_policy dictionary,Investigate and fix the following warning in {{pex_policy}}.    {code}  src/Dictionary.cc:312:9: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses]      if (!getType() == Policy::POLICY) // should have checked this at a higher level          ^          ~~  src/Dictionary.cc:312:9: note: add parentheses after the '!' to evaluate the comparison first      if (!getType() == Policy::POLICY) // should have checked this at a higher level          ^           (                          )  src/Dictionary.cc:312:9: note: add parentheses around left hand side expression to silence this warning      if (!getType() == Policy::POLICY) // should have checked this at a higher level          ^          (         )  src/Dictionary.cc:312:20: warning: comparison of constant 'POLICY' (5) with expression of type 'bool' is always false [-Wtautological-constant-out-of-range-compare]      if (!getType() == Policy::POLICY) // should have checked this at a higher level  {code},1,-0.049528427
DM-6280,The labels in HMS formate are wrong in WebGrid,The labels in HMS format no longer show hh:mm:ss anymore.  The porting introduced the bug.  ,1,3.2727225
DM-6283,Fix mismatched-tags warnings in meas_modelfit,The following warnings are produced in {{meas_modelfit}}. Fix them.    {code}  include/lsst/meas/modelfit/UnitSystem.h:90:1: warning: 'LocalUnitTransform' defined as a struct here but previously declared as a class [-Wmismatched-tags]  struct LocalUnitTransform {  ^  include/lsst/meas/modelfit/Model.h:41:1: note: did you mean struct here?  class LocalUnitTransform;  ^~~~~  struct  {code},1,1.6417519
DM-6284,Remove swig special casing for obsolete boost features,In {{utils}} the file {{python/lsst/p_lsstSwig.i}} defines special cases for boost features that are removed as part of DM-5880. This ticket removes the special cases.,1,2.4024937
DM-6285,Chart API: external API and the API for histogram,need to support external API and the API for histogram    for now only addXYPlot and showPlot are implemented,4,3.392057
DM-6286,"Charts (XY plot, histogram) Container",Need to be able to view multiple charts simultaneously in the chart area    User would like to see multiple XYplots from the same data displayed at the same time. One example will be to display different color-color plots using all 4 bands data from WISE catalog.  It is also possible we want to display histogram data at the same time as color-color plots.,10,6.04782
DM-6287,Charts refactoring,"I'd like to do some cleanup, which would facilitate further development. This includes:  - moving chart related code to a separate package (now it is in visualize)  - converting components created with React.createClass to es6 classes  - reorganize store and controllers to have all charts related things under 'charts'. Now we have 'charts' for charts ui, xyplot for xyplot charts, histogram for histogram charts, and tblstats for table statistics.      Fixed bugs    * missing chart mount action, when a chart is removed and then recreated on the same table    Steps to reproduce: load a table (default scatter plot created), create histogram, delete scatter, create new scatter.       The last scatter did not produce mount action, and the plot was not tracking table changes, like filter.    * undefined shows as a label when no server call is necessary    Steps to reproduce: load table (default scatter created), clear options and choose the same columns , click apply.    ""undefined"" are shown as axis labels",4,7.336432
DM-6288,Chart options display,"Make chart options ""in-place"" popup, similar to table options for consistent look. It will also alleviate resizing, because the chart size won't need to change when options are open.",3,2.3268523
DM-6289,Chart options reset and clear,Need to support reset and clear for plot and histogram options.    Should be no-brainer after DM-6138 (update multiple fields at the same time),3,1.506344
DM-6290,Attend SBAG Meeting,"Meeting runs Tues 28 to Thurs 30 June; that means we'll likely lose Nate for the whole week, given travel.",8,1.9800401
DM-6291,Read materials related to SBAG prep and attend telecon,"Read up material to prepare for SBAG, and discuss readings with Mario, Lynne, and Zeljko.",4,2.1998801
DM-6293,Fix error in cmodel related to computing LinearTransforms,"When running cmodel in ci_hsc, the cmodel plugin throws the error:  {code}  processCcd.charImage.detectAndMeasure.measurement WARNING: Error in modelfit_CModel.measure on record 775961510756221246:     File ""src/geom/LinearTransform.cc"", line 66, in const lsst::afw::geom::LinearTransform lsst::afw::geom::LinearTransform::invert() const      Could not compute LinearTransform inverse {0}  lsst::afw::geom::SingularTransformException: 'Could not compute LinearTransform inverse'  {code}    This seems to be causing some aperture corrections to fail, as there are no sources to compute the corrections from. Investigate why this error is being thrown. If it is a bug, fix it, if the code is not handling situations it should then make the algorithm more robust.",4,3.682512
DM-6294,Add support for pybind11 to build system,Add pybind11 as third party package to the stack. Update sconsUtils to support building with pybind11. Use daf_base DateTime to demonstrate that this works.,8,3.4428606
DM-6295,Unit test for coadds in pipe tasks detects too many sources,"The unit test for pipe tasks creates a dozen stars, to use in coaddition testing. However the results of running the test show over a hundred sources found. Investigate why the extra sources are being detected, and fix to increase the robustness of the test. If this relates to other sections of the codebase (deblender) investigate if it is appropriate to make changes to those components to make them more robust instead of creating a simple hack in the unit test.",5,2.3602972
DM-6296,Wrap afw::geom with pybind11,"The generated wrappers will live parallel to the Swig wrappers. This ticket only covers the C++ wrappers themselves, not the Python layer on top (which will continue to use the old wrappers) all work will stay on a separate branch and will not be merged to master until DM-6168 is complete.",5,4.4467278
DM-6297,Wrap afw::detection with pybind11,"The generated wrappers will live parallel to the Swig wrappers. This ticket only covers the C++ wrappers themselves, not the Python layer on top (which will continue to use the old wrappers) all work will stay on a separate branch and will not be merged to master until DM-6168 is complete.",5,4.3995724
DM-6298,Wrap afw::math with pybind11,"The generated wrappers will live parallel to the Swig wrappers. This ticket only covers the C++ wrappers themselves, not the Python layer on top (which will continue to use the old wrappers) all work will stay on a separate branch and will not be merged to master until DM-6168 is complete.",5,4.8818917
DM-6300,Extend galaxy shear fitting results to cover ngmix,,10,3.7274463
DM-6301,Write example meas_base plugin in Python,"During X16, new functionality was exposed to Python plugins in meas_base. Write a complete pedagogical example. It should go beyond our current pure Python plugins to demonstrate use of:    * FlagHandler;  * SafeCentroidExtractor;  * Other relevant, undocumented functionality.    This should be added to the package level documentation for meas_base, so it appears in some extended version of https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/meas_base.html.",6,1.2356664
DM-6302,Wrap pex_exceptions with pybind11,"While wrapping these packages, pay particular attention to exception translation (see Jim's bullet point 3: https://jira.lsstcorp.org/browse/RFC-182?focusedCommentId=48644&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-48644).",4,3.89279
DM-6303,Wrap ndarray with pybind11,Note particularly Jim's second bullet point at https://jira.lsstcorp.org/browse/RFC-182?focusedCommentId=48644&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-48644.,12,5.0544357
DM-6304,Wrap afw dependencies in pybind11,"Everything that isn't base, utils, pex_exceptions (DM-6302), ndarray (DM-6303).",10,5.0422297
DM-6306,Executable test in utils needs to test an executable,In DM-4036 all the test binaries were removed as no longer being needed. This had the unfortunate side effect that the {{testExecutables.py}} test no longer tests anything. This ticket will be used for adding a test file.,1,0.6527494
DM-6307,input outlines to LDM-151 for AP,Write outlines into the LDM-151 document for the alert production pipelines.,4,0.9180852
DM-6308,Upload JSON from validate_drp to SQuaSH REST API on Jenkins,"This ticket covers work to build a Python package/script whose role is to take JSON output from validate_drp (DM-6086), shim it into the JSON schema currently expected by the SQuaSH REST API (http://sqr-009.lsst.io), and post the data to the API's {{/jobs}} endpoint.    This tool also adds additional metadata to the â€˜Jobâ€™ document, including the build ID and versions of packages as run by validate_drp (see DM-5943).",2,1.904789
DM-6309,Update LDM-151 with SDQA Skeleton and Outline,1. Update the LDM-151 draft with the SDQA Skeleton from the DMLT + SciPipelines working group discussions of May 16-20.  Implement as bullet points in a semi-coherent list. (/)    2. Clean up list. (/),1,3.344034
DM-6310,Transform SDQA bullets to prose,,1,2.658774
DM-6311,Create 1st-level block diagrams for SDQA,,2,2.4188328
DM-6312,Update Scons to v3.0,Scons v3 is the scons version that supports both Python 3 and Python 2.7. This ticket is for updating Scons and ensuring that the Python 2.7 stack still builds.    This work depends on the Scons developers delivering a new Scons by mid July. Whilst work is ongoing it may be necessary to help out with the port if we wish to meet our Python 3 target.,4,2.7552686
DM-6313,Create miniconda3 EUPS package,{{newinstall.sh}} currently installs miniconda via EUPS. To replicate that functionality in Python3 we need to create a {{miniconda3}} package. This package should be almost identical to {{miniconda2}}.    Requires that {{lsstsw}} first be updated to support python 3.,1,1.6301965
DM-6314,Port lsstsw to Python 3,Get {{lsstsw}} working with Python 3:  * Update the {{deploy}} script to allow a Python 3 python to be installed and modify the version checking code.  * Demonstrate that {{lsstsw}} {{rebuild}} will successfully build and install a third-party non-Scons package.,5,2.3528302
DM-6315,Write Python 3 porting guide,Porting the stack to Python 3 is not as simple as blindly running {{futurize}}. A guide has to be written explaining the issues and providing guidance on when to accept {{futurize}} suggestions and when to ignore them. This guide will be written as a Tech Note.,10,2.1494758
DM-6316,Update newinstall.sh to support Python 3,{{newinstall.sh}} currently insists on installing and checking for python 2.7. This needs to be changed to allow Python 3.    Requires {{sconsUtils}} works with Python 3 as the {{lsst}} EUPS package is installed as part of {{newinstall.sh}}.,1,1.9293559
DM-6317,Update developer guide to include Python 3,Update the developer guide to indicate that Python 3 must be supported and that code must run on Python 2.7 and 3.    This ticket will reference the tech note delivered as part of DM-6315. Writing extensive user documentation on the {{future}} package is beyond the scope of this ticket.,2,2.2219718
DM-6319,Port sconsUtils to Python 3,{{sconsUtils}} has to be modified to ensure it works with Python 3. Additionally SWIG calls must be changed to trigger Python 3 mode.,3,2.4515903
DM-6320,Port utils to Python 3,Ensure that the {{utils}} package will work with Python 3.,2,2.8181603
DM-6322,Port base package to Python 3,Ensure that {{base}} works with Python 3.,2,2.851835
DM-6323,Lead Python 3 migration at All Hands Meeting,* Prepare for all hands meeting.  * Present plan to developers.  * Advise developers doing migration.  * Contribute fixes as required.,8,3.234429
DM-6325,Replace BOOST_STATIC_ASSERT with static_assert,Replace BOOST_STATIC_ASSERT with static_assert from C++11.,1,0.7484916
DM-6326,reST roles for mock code references,"Add mock code reference roles so that authors can add semantics to their writing without attempting to make actual references to API documentation that does not _yet_ exist. Covers all roles in the Python domain, and supports tilde syntax for collapsing the namespace.",1,2.3020196
DM-6331,Shifting F16 milestones to S16,"Per [~jbecla]'s request, provide Kevin with a list of milestones which we will not address in F16. Reschedule them to S16 in JIRA.",1,6.961563
DM-6343,Update LDM-151 introduction to reflect new structure,"Some proposals made on DM-6247 to change the structure of LDM-151 (add Algorithmic Components section, move overview into production-specific sections, add notation section to introduction) were accepted at the live meeting on 6/27.  This issue rewrites the introduction accordingly.",1,1.7748879
DM-6345,Firefly Python API scope and decision,Python API to use Firefly visualization components and other functions.   This story is to come up with a good plan for the rest of the development work to related to Python API. ,2,5.766019
DM-6346,User installation and operation instructions for conda ,Create documentation for the Stack conda binaries created in DM-5415 as part of the Science Pipelines documentation,3,3.2701411
DM-6347,Add FlagDecorator to support FlagHandler in Python,"DM-4009 added the C++ and swig changes needed to allow the FlagHandler to be used from Python.  During review, Nate suggested that a decorator class could be used to improve the use of this code in Python.  This ticket will be to review Nate's decorator and confirm that it is the correct model for Python-only plugins.    We will also modify the unit test in DM-4009 and the EmPsfApprox plugin in DM-6123 to use the decorator.",2,0.96453243
DM-6348,Write Calibration Products Production section of LDM-151,Write photometric calibration pipeline section of LDM-151,20,4.6781116
DM-6349,Replace cameraGeom PAF files,"PAF files have long been deprecated, but continue to be used for describing the camera geometry.  We need to replace the PAF cameraGeom files used for CFHT-MegaCam, DECam, LSSTSim and SDSS, and the scripts used to convert these files to FITS files for reading by the Mappers.  They might be replaced by a configuration like YAML, or pure python.",10,2.4806247
DM-6350,Generate camera description at build time,"Camera geometry used to be defined using PAF (policy) files, which are now deprecated. As part of the transition to the refactored camera geometry scheme, scripts were introduced to convert from the PAF files to the new camera geometry configuration scheme which uses FITS files and a python file to describe the camera. These scripts are still part of the obs_* packages, and some people rely on them for making changes to the camera description. On the other hand, the generated FITS files and python file are also first-class members of the obs_* packages. This means that we have two sources of the same information, which is dangerous.    For obs_lsstSim, obs_decam, obs_cfht and obs_sdss, we want these scripts to be the primary source of information.  This means we should delete the generated files, and create them at build time.  We should also standardise the name of the script used to generate these.",3,3.0830748
DM-6351,Add skeleton words to LDM-151 for AP,We need to flesh out the algorithmic components and narrative sections to the point of having ~1 sentence per paragraph in the finished document.,10,0.85835093
DM-6352,Use the HTM based reference catalogs in tests,"In order to move A.net out of meas_astrom to make it a true dependency, we need to replace its use in tests.",4,3.9605827
DM-6356,Add linearity correction to obs_decam,Add linearity correction from DM-5462 to obs_decam using the standard linearity tables.  ,4,2.3685613
DM-6357,"Take part in LDM-151 Progress Meeting, 2016-06-03",,1,3.5910413
DM-6358,"Take part in LDM-151 Progress Meeting, 2016-06-03",,1,3.5910413
DM-6359,"Take part in LDM-151 Progress Meeting, 2016-06-03",,1,3.5910413
DM-6360,"Update ""Using Boost"" section in DM Developer Guide to prefer standard library by default","Implement RFC-185 by updating the ""Using Boost"" section in DM Developer Guide to prefer standard library by default.",1,1.6494639
DM-6361,Replan (June),,11,5.797785
DM-6362,Replan (July),,11,5.5642605
DM-6363,Replan (August),,11,5.327407
DM-6364,Design DAX containers,,6,7.5441813
DM-6365,L1 DB Prototype (June),Placeholder for L1 database prototyping in June 16 -- to be replaced with actual stories of same sp total,14,9.898618
DM-6368,Adjust version check of EUPS python package to allow v3,To enable Python 3 support of the stack the EUPS {{python}} stub package needs to allow Python 3.    ,1,2.8181908
DM-6369,Test DIA simulation script with Postgres,I will be useful to compare MySQL and Postgres performance for use in L1. After DM-6918 is complete (means works with MySQL) verify that it can also run against Postgres. ,5,2.4215128
DM-6370,L1 DB Prototype (August),Placeholder story for work in this epic in August -- replace with detailed stories at same sp load,14,9.786042
DM-6373,Improve skeleton for LDM-151 Algorithmic Components,For all subsections in  Algorithms Components owned by [~jbosch]:   - Provide enough bullet points to capture scope.   - Add bullet points for subtly difficult aspects of components.   - Add extra level subsubsubsection level for Measurement.   - Create matrix of measurement algorithms and contexts.  ,1,6.813521
DM-6375,New image visualization functions (F16),"TO support the pipeline QA and build the first web portal, there will be new functions need to be developed.  This epic is to collect those functions.",40,8.15235
DM-6376,Implement DAX containers,Implement containerized DAX services,4,6.926532
DM-6377,SPIE conference 2016,Activity related to attending the SPIE meeting in June 2016. Deliverable is a report on the conference.,15,3.227552
DM-6378,Persist output of simple DCR correction,DM-5695 will create transfer matrices stored as numpy arrays. This ticket extends that work to determine a useful format and write functionality to persist those arrays.,2,2.809579
DM-6379,Investigate CAOM,"Investigate observation model interfaces and storage, and applicability of CAOM",4,3.0043898
DM-6380,Attend SPIE conference,This ticket relates to attendance at the SPIE meeting in Edinburgh the last week of June.,10,1.9442515
DM-6381,ADQL support in dbserv,Work on understanding coordinate systems in ADQL and implement the ADQL->qserv rewriter,6,4.9802494
DM-6382,Generate template DCR images,DM-5695 will create transfer matrices that can be used to create template images of a field at arbitrary airmass. This ticket is to write the code to generate and persist those template images.,4,3.8484266
DM-6383,Use template DCR images for image differencing,"DM-6382 creates template images of a field at arbitrary airmasses, which can be used to match the template airmass to the science image precisely to mitigate Differential Chromatic Refraction in image differencing. This ticket is to determine the best method to supply the new templates to image differencing, which may be simply to create a new exposure and ingest/process the template as though it were a real observation.",2,2.2030838
DM-6384,Create and deploy Conda binaries for v12.0 release build,Deploy Mac OS X and CentOS 5 conda binaries for v12 to a conda repository (http://conda.lsst.codes/stack/current).,21,1.5753598
DM-6385,Create CLI tool to add mac users.,Create a CLI script to add and delete Mac OS X users. Somehow this is a many step process on Mac OS X.,1,1.8966012
DM-6387,Deploy Conda repository to S3,Deploy conda binaries to s3 using their static website feature. http://conda.lsst.codes/stack/current.,4,5.8791413
DM-6388,Create Ansible automation to run the conda build,Create an Ansible deploy to automate Conda binary builds. Target Mac OS X and CentOS5.,5,2.2037213
DM-6389,Create CentOS5 Conda binaries,Create CentOS5 conda binary builds using docker then push them to the S3 static website.,2,1.2491822
DM-6392,Text on variability characterization for LDM-151,Expand the variability characterization algorithmic section of LDM-151.,1,4.0304503
DM-6394,DM Replanning: ConOps Development,"Development of Concept of Operations documents for various DM services, including Data Backbone, AA system, L3 Hosting, and Batch Processing for the commissioning phase.    Deliverable: ConOps documents  Staff: Don Petravick, Margaret Johnson, Jason Alt, Steve Petrowicz, Hsin-Fang Chiang, Jagadeesh Yedetore, Jim Basney, Alex Withers, Robert Gruendl (roughly 0.5 effort each)  Effort: 33 days  Planned Start: 6/6/2016  Planned End: 8/31/2016",66,6.88398
DM-6395,Data Backbone conops iteration 1: create raw draft (internal),Write a raw draft of the concept of operations for data backbone services. In this iteration the document is developed in Google docs following the ConOps template.,3,6.290158
DM-6396,Data Backbone conops iteration 2: group review to produce first draft,"Review raw draft of concept of operations for the data backbone services to work through underdeveloped areas, clear up uncertainties, and make readable.",2,2.2512205
DM-6397,Data Backbone conops iteration 3: larger review to produce second draft,"Review first draft of data backbone services conops within Data Processing Architecture working group, bringing in relevant experts.    Input from review is incorporated into a second draft.",6,2.469198
DM-6398,Data Backbone conops formatting: convert second draft to reStructuredText,"When the data backbone services conops is in a solid state, convert the Google doc to reStructuredText following DM's documentation versioning process.",2,2.5138018
DM-6399,DM replanning: NCSA WBS broken down to Level 3 WBS elements,"Break down NCSA restructured WBS to level 3 (02C.07.xx.xx) sufficient for integration into PMCS.    Deliverable: Draft WBS for project-level change processes to accommodate.  Staff: Don Petravick, Margaret Johnson, Jagadeesh Yedetore, Santanu Chaudhuri (roughly 0.5 each)  Effort: 5 days  Planned Start: 6/1/2016  Planned End: 6/30/2016",10,4.80414
DM-6400,DM replanning: phased WBS elements for minimal data archiving of camera data and minimal transport via data backbone to NCSA,"Phased breakdown of work activities to construct minimal archiving of camera data and transport via data backbone to NCSA. Includes release of claim on camera buffer.    Deliverable: Phased WBS for minimal data archiving of camera data and minimal transport via data backbone to NCSA.  Staff: Don Petravick, Margaret Johnson, James Parsons, Steve Petrowicz, Jagadeesh Yedetore, Felipe Menanteau  Effort: 20 days  Planned Start: 7/1/2016  Planned End: 7/31/2016",40,4.641388
DM-6401,DM replanning: instantiating Project Reporting Group and planning & reporting process,"Instantiating NCSA's Project Reporting Group and planning and reporting processes.    Deliverable: Project reporting normalized to new methods.  Staff: Don Petravick, Margaret Johnson, Santanu Chaudhuri, Jagadeesh Yedetore  Effort: 10 days  Planned Start: 6/6/2016  Planned End: 6/30/2016",20,4.699493
DM-6403,DM replanning: participation in PM working group,"Participation in Project Management working group for DM replanning.    Deliverable: Deliverables to PM working group.  Staff: Santanu Chaudhuri, Don Petravick, Margaret Johnson  Effort: 3 days  Planned Start: 6/1/2016  Planned End: 6/30/2016",6,2.9498942
DM-6404,Operations Planning in LOPT and TOWG,"Participation in LOPT and TOWG for LSST operations planning to get to ConOps.    Deliverable: Deliverables to get to ConOps  Staff: Don Petravick, Margaret Johnson  Effort: 12 days  Planned Start: 6/6/2016  Planned End: 8/31/2016",24,5.5320344
DM-6405,Verification Planning with Systems Engineering,"Extend concepts of operations to include adequate verification. Will involve coordination with LSST Systems Engineering team.    Deliverable: verification plan descriptions in ConOps documents  Staff: Don Petravick, Margaret Johnson, Jason Alt, Paul Wefel, Steve Petrowicz, Jagadeesh Yedetore  Effort: 27 days  Planned Start: 6/6/2016  Planned End: 8/31/2016",54,14.383669
DM-6406,Install and configure GNU/Linux on my office desktop.,,4,1.8191864
DM-6407,Main prototype for all L1 entities (F16 part 1),Main program prototypes for all entities in the L1 Prompt Processing system. This epic continues work started in x16 and covers work in the first part of the F16 cycle.    Deliverable: Major component hierarchy and all 'has a' objects list.  Staff: Jim Parsons + 2 summer students (at 50% each)  Effort: 15 days  Planned Start: 6/1/2016  Planned End: 7/31/2016,30,7.2466626
DM-6408,L1 Startup Scaffolding,Scaffolding to remotely start and stop all L1 Prompt Processing system entities.    Deliverable: Initial scripts starting and stopping all entities remotely  Staff: Jim Parsons + 2 students (50% each)  Effort: 8 days  Planned Start: 7/1/2016  Planned End: 7/31/2016,16,5.1521897
DM-6409,L1 System Status Message Dictionary,Message formats and contents between all L1 Prompt Processing System entities. This epic continues work from x16.    Deliverable: Enumeration of message formats and contents as needed.  Staff: Jim Parsons + 2 students (50% each)  Effort: 10 days  Planned Start: 6/1/2016  Planned End: 6/30/2016,20,6.5297503
DM-6410,Learn about design principles and usage of data processing tasks.,"As we are working on designing a new workflow framework I should read available documentation and look through the existing code base regarding data processing tasks to learn more how they are written, work, and interact among themselves.",10,3.1579652
DM-6411,Message interaction between all L1 entities (F16),"Basic messaging and interactions, including data dictionary and message patterns.    Deliverable: All communication, data, and reporting paths specified and implemented  Staff: Jim Parsons + 2 students (50% each)  Effort: 15 days  Planned Start: 6/1/2016  Planned End: 8/31/2016",30,7.0385065
DM-6412,Basic Framework for L1 System Health and Status,"Basic framework for L1 prompt processing and archiving system health and status display, including status event recorder.    Deliverable: First draft of health checks via message; plan for remote diagnostics  Staff: Jim Parsons + 2 students (at 50% each)  Effort: 10 days  Planned Start: 7/1/2016  Planned End: 8/31/2016",20,7.8794293
DM-6414,ConOps/Planning Document for the OCS-DM interface,Detailed concept and technical implementation plan for DM interface with OCS.    Deliverable: ConOps document for OCS  Staff: Jim Parsons  Effort: 7 days  Planned Start: 8/1/2016  Planned End: 8/31/2016,14,6.2942944
DM-6415,ConOps/Planning Document for the Camera-DM interface,Detailed concept and technical implementation plan for DM interface with the main Camera.    Deliverable: ConOps document for Camera  Staff: Jim Parsons  Effort: 7 days  Planned Start: 8/1/2016  Planned End: 8/31/2016,14,6.4851823
DM-6416,ConOps/Planning Document for Base Archiving API,Detailed concept and technical implementation plan for Base Archiving API.    Deliverable: ConOps document for Base Archiving API  Staff: Jim Parsons  Effort: 5 days  Planned Start: 8/1/2016  Planned End: 8/31/2016,10,5.999616
DM-6417,Specification for Comfort Dashboard and Alarms,"Detailed specifications for comfort dashboard and alarms, including interactions with human operations, and some technology prototyping.    Deliverable: Detailed specifications  Staff: Jagadeesh Yedetore, Santanu Chaudhuri, TBH  Effort: 21 days  Planned Start: 6/13/2016  Planned End: 8/31/2016",42,6.0074844
DM-6418,Final version of Supertask and Activator prototype implementation,"Final version of Supertask and Activator prototype implementation. This is not the final version of SuperTask, just what was initially designed.     Deliverable: Final prototype  Staff: Matias Carrasco-Kind, Mikolaj Kowalik  Effort: 6 days  Planned Start: 6/6/2016  Planned End: 7/15/2016",12,7.243383
DM-6419,Propose and discuss workflow selection,"Propose and discuss workflow selection.    Deliverable: RFC for workflow selection  Staff: Hsin-Fang Chiang, Mikolaj Kowalik, Rob Kooper, Steve Pietrowicz  Effort: 5 days  Planned Start: 7/1/2016  Planned End: 7/15/2016",10,1.7888815
DM-6420,"Investigate Shifter, HTCondor, preemption, and file cleanup",Evaluate use of containers to configure HTCondor slots for DRP tasks. Investigating Shifter on Blue Waters.    Deliverable: investigation report  Staff: Greg Daues  Effort: 10 days  Planned Start: 6/1/2016  Planned End: 8/31/2016,20,3.6261446
DM-6421,Evaluate use of dynamic slot mechanism in HTCondor for DRP tasks,Evaluate use of dynamic slot mechanism in HTCondor for DRP tasks.    Deliverable: Evaluation report  Staff: Steve Pietrowicz  Effort: 5 days  Planned Start: 6/1/2016  Planned End: 6/30/2016,10,4.187515
DM-6422,Python 3 migration work,"Migrate existing packages in the LSST stack to support Python 3 compatibility. Some work will occur during the All-Hands meeting.    Deliverable: Migration of existing packages for Python 3 compatibility  Staff: Steve Petrowicz, Jim Parsons, Matias Carrasco-Kind, Mikolaj Kowalik, Hsin-Fang Chiang  Effort: 1 days  Planned Start: 8/1/2016  Planned End: 8/31/2016",2,3.4659796
DM-6423,Data Backbone: explore overheads and costs of staging model,Explore overheads and costs of staging model from Data Backbone into data caches.    Deliverable: assessment and characterization of staging component of orchestration  Staff: Steve Pietrowicz  Effort: 15 days  Planned Start: 8/1/2016  Planned End: 8/31/2016,30,5.189687
DM-6425,Analyze existing implementation of Supertask,Look through the code base of current prototype of Supertask and Activator to understand better limits of existing design of data processing task and how they are being addressed.,6,6.1256742
DM-6426,Understand how EUPS works,Read Developer's Guide tutorial and official documentation of EUPS to understand how it works to manage Stack's packages easily.,2,2.4203439
DM-6427,Data Backbone: produce abstract API to ingest data into L1 archive ,Implement an abstract API to ingest data into the L1 archive in the Data Backbone.    Deliverable: abstract API in github  Staff: Steve Pietrowicz  Effort: 4 days  Planned Start: 6/1/2016  Planned End: 6/30/2016,8,4.898283
DM-6428,Data Backbone: initial analysis of OpenStack and Ceph object store APIs,Initial analysis of OpenStack and Ceph object store APIs in Data Backbone.    Deliverable: analysis report  Staff: Steve Pietrowicz  Effort: 10 days  Planned Start: 6/1/2016  Planned End: 6/30/2016,20,7.0652485
DM-6429,Data Backbone: initial analysis of DDN WOS object store API,Initial analysis of DDN WOS object store API in Data Backbone.    Deliverable: analysis report  Staff: Steve Pietrowicz  Effort: 10 days  Planned Start: 7/1/2016  Planned End: 7/31/2016,20,6.7838507
DM-6430,Object Store and WAN Data Interchange Evaluation,"Evaluate data interchange over the WAN with object store technology.    Deliverable: evaluation report  Staff: Jason Alt, TBD SET hire  Effort: 25 days  Planned Start: 6/6/2016  Planned End: 8/31/2016",50,7.8207173
DM-6431,Commission the evaluation framework on one machine at NCSA,Commission the evaluation framework on one machine at NCSA.,10,3.800852
DM-6432,Evaluate at additional sites and/or by simulation using WAN emulation techniques,Additional sites and/or simulation using WAN emulation techniques.,30,8.379255
DM-6433,Produce evaluation report,WAN data interchange evaluation report.,5,2.9004753
DM-6434,Cost Model Updates for FY17,Semi-annual updates of costing forecast in sizing model.    Deliverable: RFC for proposed cost updates  Staff: Jason Alt  Effort: 10 days  Planned Start: 6/6/2016  Planned End: 6/30/2016,20,8.8248625
DM-6435,Service Management for F16 (part 1),"Provide service management for LSST development resources at NCSA, including Nebula openstack cluster, lsst-dev, and relevant FY16 procurements. Interface with functional groups to provide support for DM services.    Deliverable: services  Staff: Greg Daues  Effort: 6 days  Planned Start: 6/1/2016  Planned End: 8/31/2016",12,8.09551
DM-6436,Deploy FY16 Integration Environment,"Deploy infrastructure for FY16 SUI/Qserv integration environment (a.k.a., prototype DAC).    Deliverable: secure SUI/Qserv integration environment  Staff: 3 NCSA ICI engineers (networking, storage, systems)  Effort: 65 days  Planned Start: 6/1/2016  Planned End: 6/30/2016",100,60.125114
DM-6437,Convert GWT projection and Coorindate Conversion routine to JavaScript,convert Booth's projection code and Judy Bennet's coordinate conversion routines to pure javascript  ,8,6.848065
DM-6438,Test the new JS convertion and projection routines against the java versions,"Now that the gwt algorithmic code has been converted it needs to be validated. Set up the test for both the projections routines and the coordinate conversion routines.    h3. Task Details  * Unit test should be run on the Java and JavaScript side  * A unit test should exist for all 10 projections. More might be necessary since there are variation within a projection type.  * We need to bring Booth in for details of each projection and each variation.  * Booth has example file somewhere.  * Xiuqin ran coordinate conversion test in to past.  She (and maybe Booth) have the best understand of what that test should be.   * The same input file should be used for the Java and JavaScript side.  * The same output (if possible) should be produced.      h3. Status so far    *Projections*    * GNOMONIC - somewhat tested  * ORTHOGRAPHIC -somewhat tested  * AITOFF - somewhat tested  * SFL - somewhat tested  * PLATE - somewhat tested  * LINEAR  * ARC  * CAR  * NCP  * CEA      *Coordinate conversion.*    It appears to work when run in Firefly, however the code is not fully covered.    h3. Switching between GWT and pure JavaScript    To switch between GWT and JS edit {{VisUtil.js}} and change the following line:  {{export const USE_GWT= false;}}    true uses the old code, false used the new code.    h3. Entry Points and Directories      * Coordinate Conversion:  _Dir_: firefly/src/firefly/js/astro/conv, _Entry Point:_ VisUtil.js, convert(), line 104, also see line 26  * Projection: _Dir_: firefly/src/firefly/js/visualize/projection, _Entry Point:_ WebPlot.js, makeWebPlot(), line 124  ",12,2.4537292
DM-6439,Remove GWT from build,After the code is tested remove the GWT from the build. Should check with [~roby] to make sure the boolean to enable GWT has been removed from VisUtil.js and WebPlot.js,4,1.6837624
DM-6440,May 2016 LAAIM work,Gave input on IAM design for FY16 Integration Environment.  Discussed IAM replication requirements with stakeholders.  Attended local NCSA LSST coordination meeting.,4,3.1684413
DM-6441,Create Ansible automation to run the conda build,Complete Ansible implementation started in DM-6388.,4,2.2037213
DM-6443,Measure photometric and astrometric precision for DECam COSMOS dataset,Measure the photometric and astrometric precision for the DECam COSMOS dataset and determine the sources of extra systematic scatter.,26,6.212059
DM-6444,"For the 3_build-git-image.sh, pass -j$(nproc) to scons to speed up the build process",,2,3.2761934
DM-6445,Verification CoDR preparation,Just capturing FE's SPs  towards this. ,6,7.6916766
DM-6446,Remove boost dependencies where possible,"In X16/DM-5580, we removed Boost from a number of packages. However, we may not have rigorously updated their dependency lists to indicate where Boost is no longer required. Please do so.",1,1.0058532
DM-6447,Revise and improve DMTN-020,"An initial version of DMTN-020, describing project management practices, was produce in DM-6140. Revise and update that based on feedback from the DM Project Manager, DM Project Controls Specialist, DM technical managers, and others.",10,6.2162514
DM-6448,Deploy FY16 Storage Expansion (part 2),"Deploy infrastructure for FY16 storage expansion. This epic covers follow-on work to DM-3830.    Deliverable: storage expansion  Staff: 5 NCSA ICI engineers (networking, storage, systems)  Effort: 45 days  Planned Start: 6/1/2016  Planned End: 7/31/2016  ",90,48.670776
DM-6449,Deploy FY16 Nebula Expansion (part 2),"Deploy infrastructure for FY16 Nebula expansion. This epic covers follow-on work to DM-3832.    Deliverable: expanded services  Staff: 3 NCSA ICI engineers (networking, storage, systems)  Effort: 10 days  Planned Start: 6/1/2016  Planned End: 7/31/2016",20,19.385235
DM-6450,Deploy FY16 Cluster Services (part 2),"Deploy infrastructure for FY16 cluster services. This epic covers follow-on work to DM-5624.    Deliverable: cluster services deployed  Staff: 3 NCSA ICI engineers (networking, storage, systems)  Effort: 10 days  Planned Start: 6/1/2016  Planned End: 6/30/2016  ",20,16.29269
DM-6451,Deploy FY16 Verification Cluster (part 2),"Deploy infrastructure for FY16 Verification Cluster. This epic covers follow-on work to DM-5626.    Deliverable: verification cluster  Staff: 5 NCSA ICI engineers (networking, storage, systems)  Effort: 65 days  Planned Start: 6/1/2016  Planned End: 6/30/2016  ",100,22.22118
DM-6452,L1 System Mock 1: Butler component,Implement a mock program that receives the Level 1 processing system data stream to simulate Butler integration.    Deliverable: mock program  Staff: Felipe Menanteau  Effort: 5 days  Planned Start: 7/1/2016  Planned End: 7/31/2016,10,9.352214
DM-6453,L1 System Mock 2: Archive component,Integrate mock API to ingest data into Archive that organize data spatially on tape.    Deliverable: mock API  Staff: Felipe Menanteau  Effort: 5 days  Planned Start: 8/1/2016  Planned End: 8/31/2016,10,8.471378
DM-6454,"Investigate the feasibilty of hosting an extracted, transformed and loaded database at archive site instead of a full EFD","Investigate the feasibilty of hosting an extracted, transformed and loaded (ETL) database at archive site instead of a full EFD. Gather sufficient details to support change request to eliminate full EFD at archive site. Address evident concerns relating to the increased data volume in the reformatted EFD and better integration into operational context, including the data backbone.     Deliverable: sufficient details to support a change request  Staff: Steve Peckins  Effort: 16 days  Planned Start: 7/1/2016  Planned End: 8/31/2016    ",32,3.5954406
DM-6455,Investigation of workflow and interface tools in the OpenStack environment,"Investigation of workflow and interface tools in the OpenStack environment. This is learning to support the eventual toolkits anticipated in the SUI for production deployment at the DAC at NCSA.    Deliverable: investigation report  Staff: Matias Carrasco-Kind, 2 students (at 50% each)  Effort: 20 days  Planned Start: 6/15/2016  Planned End: 8/15/2016",40,6.0893726
DM-6456,create description of features in storage APIs,"The APIs for the storage brokers we're looking into are similar, but don't have a 1-1 correspondence.  Write up the features offered by the APIs, and see where there is overlap.",4,5.7021484
DM-6457,Design and RFC for Repository Refactor,Drive the RFC for Repo Refactor to completion (this includes a lot of design work),20,6.140508
DM-6458,Expand skeleton in LDM-151,We need to flesh out the skeleton text to contain full descriptions of the algorithms and pipelines we expect the baseline design to use.,20,3.5344286
DM-6459,"productize ""Repository Refactor""","After RFC-184 is closed: implement, unit tests, review, document, submit.    When this story closes, I think RFC-184 status is supposed to be changed from Adopted to Implemented.",20,4.2255206
DM-6460,Ramp-up adminstrative capability of qserv for deployment of SUI prototype system,"New staff will be on-boarded who has no prior experience with qserv. The goal is to ramp up to provide administration for the deployment of the prototype DAC, and to foster development of documentation within the qserv project that facilitates administration and usability of the product as a component in the LSST systems.    Deliverable: administration of qserv for SUI prototype system  Staff: Steve Peckins  Effort: 15 days  Planned Start: 6/1/2016  Planned End: 8/31/2016",30,6.8355837
DM-6461,App logging framework migration work,"App logging framework migration work. Enhance the lsst::log package, prepare and do a RFC, migrate codes to use lsst::log, deprecate pex_logging.    Deliverable: framework migration  Staff: Hsin-Fang Chiang  Effort: 20 days  Planned Start: 7/1/2016  Planned End: 8/31/2016",40,3.1320677
DM-6462,"Emergent middleware work (F16, part 1)","Reserve of effort to handle MINOR middleware-related work that emerges during the F16 cycle, June-August.    Deliverable: TBD middleware fixes  Staff: Steve Pietrowicz, Hsin-Fang Chiang, Mikolaj Kowalik, Matias Carrasco-Kind, Rob Kooper  Effort: 10 days  Planned Start: 6/6/2016  Planned End: 8/31/2016",20,7.4958844
DM-6463,Please provide how-to-reproduce instructions for LSST/HSC comparison epics,"For all the stories describing comparisons between HSC and LSST results (notably DM-5301 and DM-5827), please provide instructions describing the steps to reproduce the comparison. In particular, include:    * A list of any tweaks that had to be applied to the code;  * Non-default configuration options;  * Exactly which comparisons were made.",2,2.7276974
DM-6464,Compare CModel results from LSST and HSC,"Demonstrate that the HSC and LSST stacks produce consistent results for CModel measurement. Account for (and fix, where relevant) differences.",4,2.272097
DM-6465,Compare Kron results from LSST and HSC,"Demonstrate that the HSC and LSST stacks produce consistent results for Kron measurement. Account for (and fix, if relevant) any differences.",4,1.8627187
DM-6466,Compare meas_mosaic-ed HSC and LSST coadds,"The previous comparison of coadds on HSC and LSST was performed without an operable LSST-based meas_mosaic. When one becomes available, demonstrate that mosaicking is consistent between HSC and LSST; describe, account for, and (where possible) correct differences.",5,2.5272186
DM-6467,Account for noise replacement differences between LSST and HSC,"In DM-5827, [~rearmstr] wrote:  {quote}  In most of these plots you can see some scatter at relatively bright magnitudes... These are likely getting different pixel values when we replace objects with noise which is causing these changes.  {quote}  Check that this is the case, and, if so, explain why the noise replacement is different.",5,1.8816016
DM-6470,convert jenkins-ebs-snapshot job to use credentials for aws keys,"At present, this job is being templated by puppet to inject the keys in plain text which are they converted by jenkins to stored secrets if/when the job is edited and resaved via the jenkins UI.  This means that the credentials may be leaked.",1,0.97316307
DM-6471,Conda eups packages don't work if eups is already configured,"When [~tjenness] attempted to use the Conda repository he ran into a problem installing and using the packages because he already had an active EUPS_DIR and EUPS_PATH.    When the eups package is installed and linked, it should warn users when these environment variables are set.    I'm open to another solution but would prefer it doesn't change the eups package behavior. Changing behavior goes against the best practices for Conda and more generally packaging.",1,1.3302435
DM-6473,Possible image related issues in firefly viewer,"Image Meta Data tab  * images cannot be remove, but in expanded mode, it can.  * selecting image no longer highlight table.  the reverse works fine.  * visualize/saga/ImageMetaDataWatcher.js:272 returns -1.  * when a non-meta table is selected, images are shown, but not the toolbar.  * after table is removed, images are still there.    image external api does not mix well with firefly viewer.  * firefly viewer uses 'triViewImagesâ€™ viewer_id while api has no viewer_id.  as a result, images loaded by api will be lost once table or other searched data are returned.    catalog overlay are drawn outside of the images.    more issues:    - It's possible to select distance tool and then area selection. First drag would define area selection, all the following line. A click would be defining a 0 length line, even if point selection is enabled.  ",8,4.8672357
DM-6474,Restore star selector registry,"Restore the registry for star selectors that was lost in DM-5532, now that tasks in registries can be used as subtasks.    Also use the registry where appropriate.",2,2.3715558
DM-6475,Install conda psutil instead of LSST's version,[~tjenness] requests that conda-lsst uses Conda's psutil. Currently we use our own version.,1,1.39414
DM-6476,Report and work around conda repository change,This needs to be worked around by either using a different version of conda-build or addressing the changes to the conda recipe structure. I also want to comment and/or create an issue on conda-build so they know that such changes are affecting users.    See:    https://github.com/conda/conda-build/issues/1003  https://github.com/conda/conda-build/pull/1004    https://github.com/conda/conda-build/commit/b4ec0e0659d8f376042d4fc391616bf235996cf5    [Mario fixed it|https://github.com/mjuric/conda-lsst/commit/6a552b6f9cada2530681cfdc4a9f67add261ff99] but that fix will be broken as soon as conda-build #1004 is merged.,1,1.242144
DM-6487,Form validation regression issues,"Recent changes in 'dev' made some of the components stop working.  We need to click through firefly viewer to identify the problems and fix it.  Below are a few that I've spotted.    Data Sets menu:  Form fail validation when they should not.  filters and upload file should be nullable.    Catalogs Classic menu:  form fail validation without any visual indications.  valid parameter is false when passed into validUpdate in CompleteButton.    xyPlot(Scatter Plot) options:  Beside X and Y, everything else should be optional(nullable).  Even after entering a valid value into all of the fields, 'OK' still fail validation similar to above where 'valid' parameter is false when passed into CompleteButton.    There may be more, please do a quick search to make sure all usage of CompleteButton is good.   ",4,4.402929
DM-6490,Investigate calibration zeropoint offset between HSC vs. LSST processCcd.py runs,"As reported in DM-4730, while the scatter between single frame processing measurements of the same dataset on the HSC vs. LSST stacks is quite good (rms = 0.009 mag between Gaussian fluxes, for example, in the figure shown on that ticket), there is a clear offset (0.0166 mag in the figure shown) in the zeropoint between the two stacks (it is systematic, i.e. no trend with magnitude).  The cause may well be due to slight differences in the reference stars selected for calibration.  We also speculated about differences in slot definitions used in the calibrations steps (e.g. for aperture corrections, psfex, etc...), so I have rerun visit 1322 through both stacks having forced all apertures used in calibration to be the same, namely a circular aperture of 12 pixels measured using the sinc algorithm (as opposed to ""naive"").  I have attached the *processCcd.py* config files for the two runs so my settings can be reproduced.    Also of note, I am using a {{meas_algorithms}} branch on the HSC stack with the following commit:    {code}  commit 173ad0b32ed4f4ab074f1a942d2d3f758e189917  Author: Lauren MacArthur <lauren@astro.princeton.edu>  Date:   Wed Jan 13 16:35:59 2016 -0500        Hack to allow flux.aperture to be used in apCorr            Since it does not seem possible to access the nth element of a      schema element that is an array in the context of setting a config      override, this allows for flux.aperture to be set as      calibrate.measureApCorr.reference and it sets it to index 4 (which      corresponds to a radius of 12 pixels) in the __init__.  This was      selected to match the current LSST default.    diff --git a/python/lsst/meas/algorithms/measureApCorr.py b/python/lsst/meas/algorithms/measureApCorr.py  index 9f6c599..f1fa99d 100644  --- a/python/lsst/meas/algorithms/measureApCorr.py  +++ b/python/lsst/meas/algorithms/measureApCorr.py  @@ -81,6 +81,9 @@ class MeasureApCorrTask(lsst.pipe.base.Task):       def __init__(self, schema, **kwds):           lsst.pipe.base.Task.__init__(self, **kwds)           self.reference = KeyTuple(self.config.reference, schema)  +        if self.config.reference == 'flux.aperture':  +            print ""NOTE: setting aperture correction flux to flux.aperture[4] ==> radius = 12 pixels""  +            self.reference.flux = self.reference.flux[4]           self.toCorrect = {}  {code}    I attach some of the figures comparing the PSF fluxes from these runs which compare the output of the two stacks having matched the two src catalogs.  There are two sets: 1) having adjusted the flux for each source to the zeropoint calculated in the calibration and stored as *FLUXMAG0* 2) having adjusted the flux for all sources to a common zeropoint (zp=33.0, chosen to roughly match the calibrated zp).  Note that my figures do include aperture corrections (in DM-5301, many of the plots show fluxes pre-aperture correction).  I have also included plots that directly compare the aperture corrections applied (difference in mag units).  Finally, I also include plots comparing the 12 pixel circular aperture mags (i.e. to which no apCorr is added).    Clearly, the zeropoint determined in the calibration of the two stacks differs between the two stacks and, in particular, there seem to be some very problematic CCDs where the differences are particularly significant (~0.05 mag, and not always in the same direction).  Please investigate the source of this discrepancy.",8,1.7346518
DM-6491,Investigate offset in baseline zeropoint between LSST vs. HSC stack reductions for some HSC visits,"DM-6490 reports on an offset between the calibration zeropoints between HSC vs. LSST *processCcd.py* runs.  Here we report another, additional, offset seen in certain HSC visits.  It is not seen in the figures shown in DM-6490 for visit 1322.  However, here attach the same figures for visit 19696, run with identical setups/configs for both stacks as in DM-6490, where we see an additional offset in the ""common ZP"" figures (i.e. all fluxes have been scaled the same zp=33.0 for comparison).    A best guess at present is that the calibration frames are different between the HSC and LSST stacks for the timeframe of this visit; e.g. were the inputs ingested exactly the same for both sets?  Did the bug in regards to flagging on the flats noted in DM-5124:  {quote}  I found a difference in the codes doing the statistics: the HSC code uses a hard-coded mask ignore list of DETECTED only, while the LSST code uses a configurable mask ignore list that defaults to DETECTED,BAD (and the default isn't overridden). This produces a large difference on CCDs with bad amps (e.g., ccd=9).  There's a smaller difference on ccd=49 because the number of BAD pixels is smaller. Also note that the scaling of one CCD (like ccd=9) can affect others because we force the normalisations to correspond to that which we get from solving the system of M exposures of N CCDs.  {quote}  have a greater impact on these calibs?    Please investigate the cause of this offset.",8,2.0246837
DM-6492,Review LTS-210,,2,2.6638703
DM-6494,Better error messages from the camera mapper when a template cannot be formatted,"The CameraMapper produces a very unhelpful traceback if it cannot format a template string with the provided data ID dict. For example:  {code}  Traceback (most recent call last):    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_tasks/12.0.rc1-3-gb785bf9/bin/processCcd.py"", line 25, in <module>      ProcessCcdTask.parseAndRun()    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_base/12.0.rc1-1-g832266b/python/lsst/pipe/base/cmdLineTask.py"", line 450, in parseAndRun      parsedCmd = argumentParser.parse_args(config=config, args=args, log=log, override=cls.applyOverrides)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_base/12.0.rc1-1-g832266b/python/lsst/pipe/base/argumentParser.py"", line 479, in parse_args      self._processDataIds(namespace)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_base/12.0.rc1-1-g832266b/python/lsst/pipe/base/argumentParser.py"", line 577, in _processDataIds      dataIdContainer.makeDataRefList(namespace)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_base/12.0.rc1-1-g832266b/python/lsst/pipe/base/argumentParser.py"", line 126, in makeDataRefList      dataRef=dr)]    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/pipe_base/12.0.rc1-1-g832266b/python/lsst/pipe/base/argumentParser.py"", line 935, in dataExists      return butler.datasetExists(datasetType = datasetType, dataId = dataRef.dataId)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_persistence/12.0.rc1-1-gc553c11+4/python/lsst/daf/persistence/butler.py"", line 288, in datasetExists      locations = self.repository.map(datasetType, dataId)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_persistence/12.0.rc1-1-gc553c11+4/python/lsst/daf/persistence/repository.py"", line 392, in map      return self.doParents(Repository.doMap, *args, **kwargs)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_persistence/12.0.rc1-1-gc553c11+4/python/lsst/daf/persistence/repository.py"", line 325, in doParents      res = func(parent, *args, **kwargs)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_persistence/12.0.rc1-1-gc553c11+4/python/lsst/daf/persistence/repository.py"", line 405, in doMap      loc = self._mapper.map(*args, **kwargs)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_persistence/12.0.rc1-1-gc553c11+4/python/lsst/daf/persistence/mapper.py"", line 169, in map      return func(self.validate(dataId), write)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_butlerUtils/12.0.rc1+6/python/lsst/daf/butlerUtils/cameraMapper.py"", line 284, in mapClosure      return mapping.map(mapper, dataId, write)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_butlerUtils/12.0.rc1+6/python/lsst/daf/butlerUtils/mapping.py"", line 123, in map      path = mapper._mapActualToPath(self.template, actualId)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_butlerUtils/12.0.rc1+6/python/lsst/daf/butlerUtils/cameraMapper.py"", line 732, in _mapActualToPath      return template % self._transformId(actualId)  TypeError: %d format: a number is required, not NoneType  {code}    It is unclear what string was being formatted with what data, making the problem difficult to diagnose and correct.    I suggest changing line 732 of CameraMapper.py from:  {code}  return template % self._transformId(actualId)  {code}  to something like the following:  {code}  try:      transformedId = self._transformId(actualId)      return template % transformedId  except Exception as e:      raise RuntimeError(""Failed to format %r with data %r: %s"" % (template, transformedId, e))  {code}    Here are the last few lines of the same traceback after applying this change:  {code}      path = mapper._mapActualToPath(self.template, actualId)    File ""/Users/rowen/UW/LSST/lsstsw/stack/DarwinX86/daf_butlerUtils/12.0.rc1+6/python/lsst/daf/butlerUtils/cameraMapper.py"", line 735, in _mapActualToPath      raise RuntimeError(""Failed to format %r with data %r: %s"" % (template, transformedId, e))  RuntimeError: Failed to format '%(date)s/%(filter)s/decam%(visit)07d.fits.fz[%(hdu)d]' with data {'date': '2013-02-10', 'ccdnum': 10, 'hdu': None, 'visit': 176837, 'filter': 'z'}: %d format: a number is required, not NoneType  {code}    A bit wordy, but it is much easier to figure out what went wrong.    I have stumbled across this problem twice in the last few weeks, so I consider this change fairly important. The first time it was caused by a defective format string in a paf file. This time I'm not yet sure what is causing it, but at least I have something to go on.",1,0.73833853
DM-6497,Assist IN2P3 engineer in loading DC2013 data sample,"Bogdan Vulpescu, IN2P3 engineer, tried to load DC2013 data sample. Fabrice help was required to install Qserv in multi-nodes and understand data-loading system.    Some issues have been found and will be reported in future tickets:    - a script to publish loaded data (i.e. insert db name in qservw_worker.Dbs) would be useful  - mysql client might break proxy if option are not provided correctly (a bug report will be available soon)",3,3.2793932
DM-6498,Assist IN2P3 student in using Openstack and following LSST coding standards,"[~oachbal] has written a code to automate Qserv cluster boot on Openstack cloud. Soma support was required to understand and solve cloud-init and openstack issues, Qserv container deployment and LSST coding standards.",6,3.836596
DM-6500,convert irsaviewer to react.js,"Convert irsaviewer to use the new firefly library built on react/flux.    also made these changes:  remove irsa footer from fireflyviewer  filter by selected rows  auto-correct tableâ€™s filter input.  multiple columns sort via sortByCols  fix menu item not showing selected  ife automatically builds firefly.    To test, make sure you pull ife repos as well.  same branch name on ife.",10,3.1778655
DM-6501,Regrid needed to for WebGrid,"When compute the points for the grid lines, there is no guarantee that the number of points will all be the same.  However, the points can be regrided to ensure all the lines have the same number of points.",6,3.3307586
DM-6502,setup test framework,"Need to decide what to check so we have a consistent testing, requirement is opensource  - language  - license  - maturity  - funding  - ease of install  -- dependencies  - OS requirements  - ease to create a workflow  - ability to execute on clusters/laptop  - test with simple LSST workflow  - willingness to meet and answer our questions  -- open bug reporting site  -- speed at which bugs are resolved  -- size of community, external collaborators  - how big a graph can it support?  - is shared filesystem required for data, or can it take care of data transfer  - does it support MPI other parallel code?  - smart wrt to data available on node (optional)  ",2,2.5844743
DM-6503,pegasus,Review Pegasus Workflow Management System (https://pegasus.isi.edu) against criteria defined in the epic.,6,3.1855757
DM-6504,Swift,Review [Swift|http://swift-lang.org/main/index.php] scripting language against criteria defined in the epic.,6,3.639313
DM-6505,final report,,4,2.7077968
DM-6506,panda,,6,3.1923091
DM-6510,Verification Plan Systems Engineering Status Review,"This follows on from  [DM-5315] and covers collating comments from DMLT, submitting the status report and document to Systems Engineering and dealing with the comments.     ",4,11.298551
DM-6513,"Remove unsused ""version.h"" file and associated code","This code seems obsolete and unused:    {code:bash}  qserv@clrinfopc04:~/src/qserv (tickets/DM-5967)$ grep -r ""version.h"" *  admin/tools/docker/git/src/qserv/site_scons/genversion.py:# genversion.py : declare a builder for global version headers.  admin/tools/docker/git/src/qserv/site_scons/genversion.py:    """"""Construct a version header from git-describe output and store  admin/tools/docker/git/src/qserv/core/modules/SConscript:versionFile = env.Command(['global/version.h'], None, genversion.buildVersionHeader)  core/modules/SConscript:versionFile = env.Command(['global/version.h'], None, genversion.buildVersionHeader)  {code}",3,1.5360036
DM-6514,Minor fixes to linearization,"DM-5462 added linearization to {{IsrTask}} but had a few loose ends which this ticket aims to correct:  - I intended to enable linearization by default, but somehow lost that change.  - I intended to update obs_test to use null linearization, but I forgot and the previous item meant I didn't catch the omission  - It turns out that the butler data proxy object will not work with functors (attempting to call the retrieved item results in an error, rather than resolving the proxy). This is easily worked around by using immediate=True when retrieving linearizers. This didn't show up until DM-6356 because obs_decam is the only camera that uses linearization lookup tables, and obs_subaru avoids the problem by not returning a proxy.  ",1,5.8186
DM-6516,Convert footprint support,Convert the footprint support from the GWT code,20,4.6469655
DM-6518,Fix scheduler delays caused by mlock call in memman.,"Locking tables in memory with mmap and mlock greatly increases scan query speeds but makes the worker scheduler unresponsive to interactive queries. This also tends to have only one scheduler (fast, slow, medium) running at a given time.",8,1.758934
DM-6519,Temp local background broken,The temp local background feature has been broken and needs to be fixed.,1,1.1193002
DM-6520,Prepare an RFC about logging migration,"Summarize RFC-29, evaluate technical details, prepare working examples, re-raise RFC-29 or file a new RFC before the migration.  Some implementation may be done before the new RFC.  ",10,3.169006
DM-6521,Enhance lsst.log by having a Log object and Python interface ,"Based on branch u/ktlim/getLogger in {{log}} and requests from DM-3532, implement a lsst::log Python interface through Log objects, and allow controllability of logger names and levels in Python.  ",7,2.5245533
DM-6524,Capture ProjMgmt WG Long Term Planning conclusions in DMTN-020,The ProjMgmt WG is going to agree on a strategy for long term planning. Make sure it's captured in DMTN-020.,3,4.8697414
DM-6527,Statement of Work ,,10,3.750963
DM-6528,Networking Configuration,,5,5.983064
DM-6529,Investigate single frame processing astrometry failures/poor solutions on some HSC chip/visits.,"The astrometric solution of some visit/ccd combinations for HSC data are failing or finding very poor solutions.  This typically occurs for the outermost (highly fringed) ccds (e.g. 100..103, 95).  I provide some sample output below.    {code:title=LSST bad fit: visit=19696 ccd=100}  processCcd.calibrate.astrometry.refObjLoader: Loaded 71 reference objects  processCcd.calibrate.astrometry.matcher: filterStars purged 0 reference stars, leaving 71 stars  processCcd.calibrate.astrometry.matcher: Purged 4436 unusable sources, leaving 288 usable sources  processCcd.calibrate.astrometry.matcher: Matched 6 sources  processCcd.calibrate.astrometry.matcher WARNING: Number of matches is smaller than request  processCcd.calibrate.astrometry: Matched and fit WCS in 1 iterations; found 6 matches with scatter = 0.000 +- 0.000 arcsec  {code}    {code:title=HSC fit: visit=19696 ccd=100}  2016-06-10T17:13:54: processCcd.calibrate.astrometry: Found 80 catalog sources  2016-06-10T17:13:54: processCcd.calibrate.astrometry: Matching to 119/148 good input sources  2016-06-10T17:13:55: processCcd.calibrate.astrometry: Matched 20 sources  2016-06-10T17:13:55: processCcd.calibrate.astrometry WARNING: Number of matches is smaller than request  2016-06-10T17:13:55: processCcd.calibrate.astrometry: 20 astrometric matches for 100, 0_31  2016-06-10T17:13:55: processCcd.calibrate.astrometry: Refitting WCS  2016-06-10T17:13:55: processCcd.calibrate.astrometry: Astrometric scatter: 0.038076 arcsec (with non-linear terms, 20 matches, 0 rejected)  {code}    {code:title=LSST failed fit: visit=19696 ccd=103}  processCcd.calibrate.astrometry.refObjLoader: Loaded 68 reference objects  processCcd.calibrate.astrometry.matcher: filterStars purged 0 reference stars, leaving 68 stars  processCcd.calibrate.astrometry.matcher: Purged 2206 unusable sources, leaving 225 usable sources  processCcd.calibrate.astrometry.matcher: Matched 4 sources  processCcd.calibrate.astrometry.matcher WARNING: Number of matches is smaller than request  processCcd FATAL: Failed on dataId={'taiObs': '2015-01-21', 'pointing': 1116, 'visit': 19696, 'dateObs': '2015-01-21', 'filter': 'HSC-I', 'field': 'SSP_UDEEP_COSMOS', 'ccd': 103, 'expTime': 300.0}:     File ""src/sip/CreateWcsWithSip.cc"", line 142, in lsst::meas::astrom::sip::CreateWcsWithSip<MatchT>::CreateWcsWithSip(const std::vector<_RealType>&, const lsst::afw::image::Wcs&, int, const lsst::afw::geom::Box2I&, int) [with MatchT = lsst::afw::table::Match<lsst::afw::table::SimpleRecord, lsst::afw::table::SourceRecord>]      Number of matches less than requested sip order {0}  lsst::pex::exceptions::LengthError: 'Number of matches less than requested sip order'  {code}    {code:title=HSC fit: visit=19696 ccd=103}  2016-06-10T17:20:11: processCcd.calibrate.astrometry: Found 84 catalog sources  2016-06-10T17:20:11: processCcd.calibrate.astrometry: Matching to 137/162 good input sources  2016-06-10T17:20:11: processCcd.calibrate.astrometry: Matched 19 sources  2016-06-10T17:20:11: processCcd.calibrate.astrometry WARNING: Number of matches is smaller than request  2016-06-10T17:20:11: processCcd.calibrate.astrometry: 19 astrometric matches for 103, 1_31  2016-06-10T17:20:11: processCcd.calibrate.astrometry: Refitting WCS  2016-06-10T17:20:11: processCcd.calibrate.astrometry: Astrometric scatter: 0.086131 arcsec (with non-linear terms, 18 matches, 1 rejected)  {code}    Other failed visit/ccd combos:  visit=19684 ccd=101  visit=30488 ccd=95: RuntimeError: Unable to match sources    This may simply be due to some threshold in the configs that is rejecting more stars on the LSST side, but this is not confirmed.  Please investigate the cause of these failures.",6,3.5212648
DM-6533,LDM-151 adjustments,"Adding text to LDM-151 where appropriate, working around the structure defined by Jim et al.",2,5.0001817
DM-6538,Write DMTN describing Lupton diffim decorrelation,"Write a technote describing the analysis and implementation of the Lupton(ZOGY) difference image decorrelation correction.    A new technote has been set up, it will be: http://dmtn-021.lsst.io",12,1.9737617
DM-6540,Propose track to improve container infrastructure,"Qserv uses Docker for deployment, this ticket will add track on how to improve container deployment and management.",10,6.17233
DM-6541,lsst-dev shared stack should provide release builds,"The shared stack on {{lsst-dev}} (etc) currently only provides tagged weekly builds of the LSST stack. Releases, RCs, etc are not included. Please update the build script so that they are.    NB simply including these builds is easy enough by changing the {{VERSION_GLOB}} regular expression in {{shared_stack.py}}. However, the {{current}} version is selected by a lexicographic sort of available versions. That works well enough for weekly builds ({{w_2016_XX}} is less than {{w_2016_XX+1}}), but fails with other tags. Better use a sort based on the date the tag was created on the HTTP server instead, perhaps.",1,1.4656777
DM-6542,Prevent external viewer from popup blockers.,"Currently, when external viewer launched, it is blocked by pop-up blockers. Need to change polling logic to a pushed solution so the 'launch' action can happen immediately. ",3,2.9029684
DM-6544,Release Note integration for 12_0 Stack Release,Transcribe v12_0 release notes prepared by development teams on Confluence into the Pipelines documentation sphinx project.    Pipelines documentation is published with LSST the Docs to https://pipelines.lsst.io.,3,2.3672702
DM-6545,Setup mononode test environment for initial learning about installations,How to load data and perform queries.  Investigate DAX interface to qserv.,4,1.2415826
DM-6546,Add queryId to messages at start and end of user queries.,"The queryId, ""QI=xxx:"", needs to be added to log messages that are useful for analysis. of primary interest are messages that indicate that a query has begun or finished, such as ""Discarded UserQuerySelect"".",1,2.0615673
DM-6547,Capture proposed epic review procedure in DMTN-020,See notes at https://confluence.lsstcorp.org/display/DM/ProjMgmt+Meeting+2016-06-14,1,3.5120778
DM-6548,Capture release policy in DMTN-020,"Capture the policy for releases (all work to be done 2 weeks before end of cycle, release at the cycle changeover) in DMTN-020.",1,3.0849347
DM-6552,Attend SBAG prep meeting at UW,[~nlust] will travel to UW for preparatory discussions in advance of this month's SBAG meeting.,8,3.8328233
DM-6554,"Take part in LDM-151 Progress Meeting, 2016-06-13",,1,3.1244884
DM-6555,"Take part in LDM-151 Progress Meeting, 2016-06-13",,1,3.1244884
DM-6556,"Take part in LDM-151 Progress Meeting, 2016-06-13",,1,3.1244884
DM-6557,"Take part in LDM-151 Progress Meeting, 2016-06-20",,1,3.3413925
DM-6558,"Take part in LDM-151 Progress Meeting, 2016-06-20",,1,3.3413925
DM-6559,"Take part in LDM-151 Progress Meeting, 2016-06-20",,1,3.3413925
DM-6561,Fix order of flags in Kron photometry,The flags are not added to the flag handler in the correct order for Kron photometry.,1,2.4138873
DM-6563,Clean-up rerun documentation,"Following DM-4443, there are a few ambiguities in the new {{--rerun}} documentation. Fix them.",1,1.2599492
DM-6566,Make updateSourceCoords and updateRefCentroids more visible,Implement RFC-197 to make updateSourceCoords and updateRefCentroids more visible,1,1.9745483
DM-6568,"Further prep for SBAG meeting, attend video telecon with Heidi et al.",Read back ground materials on LSST moving object simulations. This will be used to prepare for both the SBAG meeting and to come up with questions that need clarification in the preparatory telecons.,5,3.234176
DM-6569,Remove the extra init method from the SourceDetectionTask,"SourceDetectionTask defines both {{init(self, schema=None, **kwds)}} and {{\_\_init\_\_(self, schema=None, **kwds)}}. The first exists purely because of a Doxygen bug that makes {{\copydoc \_\_init\_\_}} fail. However,   {code}  copydoc \_\_init\_\_  {code}  works. Remove the non-dunder init method and update the documentation with  {code}  \copydoc \_\_init\_\_  {code}.",1,0.7218454
DM-6575,Refactor Known Issues and Metrics pages in Pipelines Docs,Make Known Issues and Metric Report both top-level pages. Link to installation issues from installation page.    See https://pipelines.lsst.io/v/DM-6575/index.html,1,3.4140456
DM-6577,Convert jointcalTask unittest into a validation measure,"Now that jointcal has some basic unittests that check whether the relative and absolute astrometry are less than some value, we should convert those tests into validation measures a la [validate_drp|https://github.com/lsst/validate_drp]. This would help us track whether we are actually improving things as we tweak the algorithm and the mappings that we fit.",4,3.6182084
DM-6578,Initial tests running HTCondor jobs utilizing Shifter,"We start with initial tests of Shifter, with the first goal to  submit PBS jobs on the Blue Waters test system utilizing Shifter that start HTCondor master/startd daemons on compute nodes.  These daemons will communicate to a remote HTCondor central manager (e.g., running on the Nebula OpenStack) and glide-in to join a working pool.  The setup will then be tested with simple payload jobs (these  submitted from a Nebula instance running the schedd)  that verify access to the LSST stack within the UDI (User Defined Image).",4,3.2711685
DM-6580,Understand and ensure variance plane compliance with diffim decorrelation,"Understand how the variance plane should be adjusted in the decorrelation (ZOGY) correction, and ensure it is being done correctly.",8,2.5720174
DM-6581,Decrease warning messages in dipoleFitTask,The dipoleFitTask was spitting out too many warnings. Change many of those to debug statements and remove the `lmfit` UserWarnings.,1,1.4959483
DM-6582,Design a metadata system for LSST code and documentation repositories (technote),"This ticket involves the research and design of a metadata system for describing LSST code and documentation repositories. Such metadata would be leveraged by DocHub and LSST the Docs (see [SQR-011|https://sqr-011.lsst.io]) and would reside as a YAML/JSON file in a resourceâ€™s GitHub repository.    [JSON-LD|http://json-ld.org] is of particular interest. Iâ€™m also consulting with GitHub, ADS, Zenodo, and CfA Library on making a sustainable system.    *Note: this story should be moved to a DocHub epic.*",3,4.3418403
DM-6588,Adapt qa analysis script for LSST vs. HSC coadd processing comparison,The analysis script was adapted for single visit processing comparisons in DM-4393 and DM-4730.  Do the same here for coadd processing comparisons.,4,3.9459221
DM-6589,Fill out Software Primitives section of LDM-151,,2,4.193242
DM-6591,Implement exception translators in upstream pybind11,Pybind11 does not currently support translation of custom exceptions. This ticket tracks work done on upstream pybind11 (internal fork https://github.com/lsst-dm/pybind11-1) to implement this functionality. It should support functionality equivalent to (but not necessarily with the same API) as Boost Python exception translators (http://www.boost.org/doc/libs/1_61_0/libs/python/doc/html/reference/high_level_components/boost_python_exception_translato.html).,4,2.869023
DM-6593,firefly api related issues due to irsa integration.,"* firefly_loader.js mistakenly uses relative path to load dependencies when it should resolve it via location of the loading script.  * TablePanel should render html content as html by default.  * paging bar style does not show correctly in irsa html  * row height does not resize to the icon size, the old api did. and the default row selectable is set to false in the old api.  * the help button needs to be added on top of the table panel.  * the expand button does not function as expected (open a full table panel).",6,3.1254406
DM-6596,Write command-line driver tutorial for LSST@Europe2 meeting,"This will be done as DMTN-023 so the results are preserved for posterity.    This may be somewhat redundant with the work Mandeep Gill is doing in translating HSC docs, but I need it now; we can merge later.",1,1.3181318
DM-6598,Prepare presentation for SPIE,Write the presentation for the SPIE conference. Date of presentation: 26th June.,2,4.855695
DM-6600,Clean up naming of multiband tasks and scripts,"Several of the multiband processing tasks and files in pipe_tasks and pipe_drivers have inconsistent names:   - Some task names do not agree with the script names.   - Words like ""Coadd"" and ""Merged"" are not consistently used.     Actually making these changes is trivial, but the work also requires creating and shepherding an RFC.",1,2.0423176
DM-6601,Port change to EXP-ID handling,"From [HSC-1409|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1409]:  {quote}  Due to an operational reason (to meet the requirement of Subaru FITS dictionary), the definition of EXP-ID is soon to be changed in the data acquisition side.  In the new definition, EXP-ID is set to 'HSCE%08d' where the letter 'E' is fixed as requested in the dictionary, and the number part corresponds to exactly the same number as our familiar 'visit'.  obs_subaru:ingest.py needs to be updated to include this rule.  The data taken with this change so far are:  HSCA07441200--HSCA07441757  HSCA90925200--HSCA90929557  {quote}    The change made as part of HSC-1409 introduces a new code path for the updated data, while old data continue to be supported with the old code path.",1,2.5303578
DM-6603,Reporting improvements,read and critique Jacek's  LPM document and the more manual oriented work from John Swinbank.  Phone con with Kevin w.r.t. reporting channel for equipment expenses in Jira (as opposed to the now clear separate distinct financial channel).  Worked out checklist and principals for revised WBS. ,6,4.270208
DM-6607,Install packstack to test OpenStack Object Storage API,,2,3.9254954
DM-6608,Finalize v12 Pipelines release documentation,Add the release announcement and finalize other documentation details in pipelines.lsst.io for the v12 release.,1,2.2850134
DM-6609,Review LDM-135 (LSST Database Design),,4,6.723897
DM-6610,Further refine alert generation pipelines sections,"There is much more information in the document, but the pipelines sections need to be refined.  We also need to give the software primitives a go over.",20,5.4980783
DM-6611,Update X16/W16 release notes for qserv and dax services,,2,5.648914
DM-6612,Make HSC processing without bright object catalogs easier,"obs_subaru enables bright object masks by default, as that's desirable for HSC production runs.      However, when HSC data is processed without bright object masks available (as will happen in most GO observations and development use), multiBandDriver.py will fail because the BRIGHT_OBJECT mask plane is not present but the base_PixelFlags algorithm is configured to make use of it. This is confusing, and it also requires the definition of a configuration file to fix the problem because base_PixelFlags cannot be configured directly on the command-line.    Some possibilities for fixing this:   - Add the BRIGHT_OBJECT mask plane in AssembleCoadd if doMaskBrightObjects is True but the external catalog is not found.  This will make the PixelFlags operation a silent no-op.   - Allow configuration options to allow PixelFlags algorithm to silently skip some flags if the appropriate masks are not available.    I am sure there are other options as well.  ",2,2.7681117
DM-6614,Include Kron parameters in algorithm metadata,"The Kron code doesn't set the algorithm metadata.  E.g.  {code}  algMetadata.set(""ext_photometryKron_KronFlux_nRadiusForFlux"",                  config.plugins[""ext_photometryKron_KronFlux""].nRadiusForFlux)  {code}  ",1,1.3107592
DM-6616,"update ""newinstall.sh"" nebula images & docker containers - v12_0",,1,1.7456436
DM-6620,Cannot instantiate LoadAstrometryNetObjectsTask without Config object,"One should be able to create a LoadAstrometryNetObjectsTask without passing a Config object, if one only wants the default configuration. Currently it raises TypeError:    {code}  Traceback (most recent call last):    File ""testJointcal.py"", line 79, in setUp      refLoader = LoadAstrometryNetObjectsTask()  TypeError: __init__() takes at least 2 arguments (1 given)  {code}    If the config object really is a kwarg, it should default None and create a default config, so that one doesn't have to do, e.g.:    {code}  LoadAstrometryNetObjectsTask(LoadAstrometryNetObjectsConfig())  {code}",1,2.9655697
DM-6621,cleanup non-survey-generic python in jointcal,"jointcal.py current does things like:    {code}  for dataRef in dataRefs:      if dataRef.dataId[""visit""] == int(visit) and dataRef.dataId[""ccd""] == int(ccd):          ...  {code}    This is not survey generic, and is probably not the best way to identify data blocks anyway. This, and other non-generic things in jointcal.py should be cleaned up so they work across surveys.",4,1.5315967
DM-6622,make jointcal integration/validation test for hsc,"We need an integration/validation test for jointcal on hsc data, to show that jointcal can run safely on hsc data processed through the stack.",10,2.3998451
DM-6623,make jointcal integration/validation test for cfht,"We need an integration/validation test for jointcal on cfht data, to show that jointcal can run safely on cfht data processed through the stack.",10,2.285527
DM-6624,make jointcal integration/validation test for DECam,"We need an integration/validation test for jointcal on DECam data, to show that jointcal can run safely on DECam data processed through the stack.",10,2.5019596
DM-6625,make jointcal integration/validation test for lsstSim,"We need an integration/validation test for jointcal on lsstSim data, to show that jointcal can run safely on lsstSim data processed through the stack.",10,2.0113287
DM-6627,Fix base_* stuff in CcdImage.cc,"CcdImage.cc currently has hard-coded a bunch of {{getSchema().find(""base_blah"").key}} things. These should either be replaced with ""slot_*"", config.blahName, or dealt with at a higher level (e.g. not loading all those values directly inside of ccdImage::LoadCatalog).    Once this is done, we should delete the comments at the top of the file.",1,1.0981342
DM-6628,Reimplement diffim decorrelation as task,Reimplement the image decorrelation as a subtask rather than a direct call to a function.,6,2.1953614
DM-6629,validate_drp: design and implement an API for metric measurements and serializations,"{{validate_drp}} computes metrics and generates JSON that, through the [post-qa|https://github.com/lsst/post-qa] tool, is submitted to the SQuaSH REST API for persistence and display in a web app.    A previous ticket, DM-6086, we bolted on a JSON serialization scheme compatible with SQuaSH. However, this approach was not well integrated with {{validate_drp}}. We want a framework/API where serialization is handled consistently and integrally with metric computations. This includes the semantic serialization of computational parameters and reduced datasets.    This API can be applied beyond {{validate_drp}} as a means for metrics and integration tests to be submitted to SQuaSH as well.",22,4.3190513
DM-6630,Support ingesting reference catalogs from FITS files,Support a means of ingesting index reference catalogs from FITS tables (e.g. SDSS catalogs).,2,3.0467181
DM-6631,Single-frame processing tasks are no longer usable without a Butler,"Adding a butler argument to the constructor signatures for {{CharacterizeImageTask}}, {{CalibrateTask}}, and {{ProcessCcdTask}} makes these tasks difficult to use without a butler.    The fix is to make the butler argument optional (with a default of None), while adding another argument that allows a fully-constructed reference object loader to be provided directly instead.    This is closely related to DM-6597, which has the opposite problem: pipe_drivers' {{SingleFrameDriverTask}} doesn't take a butler argument, but it needs to in order to provide one to {{ProcessCcdTask}}.    I have a fix for this just about ready, but I'd like to add some unit tests that verify we can run all of these tasks both from the command-line and directly before calling it complete.",3,4.7313495
DM-6632,Make match and flag propagation more reusable,"We have two bits of code for doing spatial matches and propagating flags:   - {{PropagateVistFlagsTask}}: propagates flags from individual visit catalogs to coadd catalogs, and depends on a butler to do so (reasonably; it includes the smarts to load the appropriate catalogs, so it has to do I/O).   - {{CalibrateTask.copyIcSourceFields}}: propagates fields from icSrc to src, but is only usable as part of {{CalibrateTask}}.    Both of these should delegate at least some of their work to new class (possibly a Task) that manages the Schemas, SchemaMappers, and cross-matching necessary to do this work.  This new class should be reusable without a butler and without constructing any higher-level tasks.",4,2.524872
DM-6633,"HSC ISR configuration file is applied to ProcessCcdTask, not IsrTask","{{obs_subaru/config/hsc/isr.py}} has its config options specified relative to {{ProcessCcdTask}}'s config hierarchy, not {{IsrTask}}'s.  This allows the ISR task to be retargeted in this file, but it will prevent {{IsrTask}} from being run as a {{CmdLineTask}} directly.    ISR Task retargeting should be moved to {{config/processCcd.py}}, allowing the {{config/isr.py}} level to be moved to the appropriate level.",1,1.5120419
DM-6634,Add JIRA-wrangling howto to DMTN-020,Expand https://dmtn-020.lsst.io/v/DM-6447/#jira-maintenance to describe best practices for T/CAMs working with JIRA. Include:    * Appropriate labels;  * Teams;  * ... other things?,1,3.7167609
DM-6638,LTD Keeper: Auto slug for edition paths deals with underscores,"Had a bug where {{utils.auto_slugify_edition}} did not replace underscores with a dash, and therefore failed {{utils.validate_path_slug}}. This created a silent breaked where a branch like {{u/rowen/r12_patch1}} did not get an edition created for it.    This ticket adds this replacement code and adds a test for such a case.",1,0.18323644
DM-6640,IsrTask is not a valid CmdLineTask,"IsrTask is a command-line task, but its run method does not take a dataRef (it instead has a {{runDataRef}} method.  This is inconsistent with other {{CmdLineTasks}} and more importantly breaks {{parseAndRun}}.    I'm committing a small workaround on DM-6631 to get {{parseAndRun}} working, but the ultimately method names should be made consistent across CmdLineTasks.  That will require an API change and hence an RFC.",1,0.94845104
DM-6642,Make list of elements for consideration for planning packages,Create a detailed checklist for developing the planning packages for the replan and WBS restructuring.,2,1.5428691
DM-6643,RADICAL-Pilot,Review [RADICAL-Pilot|http://radicalpilot.readthedocs.io/en/latest/index.html] against criteria defined in the epic.,6,4.8496666
DM-6644,Makeflow,Review Makeflow against criteria defined in the epic.   http://ccl.cse.nd.edu/software/makeflow/,6,3.800591
DM-6645,pinball,Review [pinball|https://github.com/pinterest/pinball] workflow management system.,6,2.4441848
DM-6646,CloudSlang,Review CloudSlang against criteria defined in the epic.   http://cloudslang-docs.readthedocs.io/en/v0.9.60/index.html,6,3.3253675
DM-6647,Adapt qa analysis script to apply corrections measured by meas_mosaic,DM-2674 involves getting HSC's {{meas_mosaic}} working with the LSST stack.  This issue consists of adapting the analysis.py script of DM-4393 & DM-4730 to (optionally) apply the astrometric and photometric solutions derived running {{meas_mosaic}} to the individual visits before comparison.  This is useful in general and is specifically useful in comparing the {{meas_mosaic}} results between the HSC and LSST stacks.,2,2.8656251
DM-6650,Management level review of two products of the Management process working group,"Reviewed https://github.com/lsst/LDM-PMT/blob/integration/index.rst and https://dmtn-020.lsst.io/v/DM-6447/    Made extensive markup of LDM-PMT,  delivered to Mario Juric.  Assessed DM-6447,  which show promise of an actual workable manual, though not complete.",1,4.3381424
DM-6651,Move new reference loader so meas_astrom can use it and perform some cleanup,"The new reference object loader code lives in pipe_tasks, which means it cannot be directly used by code in meas_astrom. This will hamper separating astrometry.net out of meas_astrom, because unit tests need reference catalogs and meas_astrom cannot depend on pipe_tasks.    Also, I'd like to take a cleanup pass on the module names, so the new code is easier to find, and improve the unit tests.",2,1.7272571
DM-6652,Remove database hack,"DM-5988 introduced a hack in reading the raw files: we use a database to cache metadata from the shutter files and update the camera files at read time.  The camera files have now been ""sanitised"" (updated with the appropriate metadata), and it's time to remove the hack.    [~mfisherlevine] writes:  {quote}  Data is on lsst-dev in:    /nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/1m3    Raw calibs are in:    /nfs/lsst2/photocalData/data/monocam/sanitised9/1m3/calibs    Regarding what I want: everything to be the same, but with a normal ingest, i.e. no splicing, just taking everything that is needed from one set of files. Some points to note:    * should be able to ingest all the raws and calibs files, and register their OBJECT types to allow processing with these as ids (inc. pipe_drivers scripts)  * pipe_drivers master calib scripts should still run (and their outputs still be ingestable)  * processCcd should run  {quote}",2,1.3112601
DM-6653,implement the active target,"When a dialog such as catalog search is displayed, it should be able to pick up the active target or the coordinates from a highlighted row in a table. Please, implement the mechanism that will automatically pick up those coordinates and pre-fill the search form for you.",6,3.4986854
DM-6656,ffApi image related issues found by irsa integration,"*-for external image viewer, the default RangeValues causes problem, i.e. other defaults not set-. (FIXED)  *-global default does not always apply to external image viewer-(FIXED DM-7016)  The Gator implementation related to coverage map   (1) default symbol size, shape, color setting is different from that of original map   (2) cannot specify the shape, size, and color through API;   (3) cannot specify the shape, size, and color of a search center through API;   (4) -does not display any image and source when the table has only one ra,dec values, for example:  one table with one position value or one table with many records but has the same ra,dec values.- MOVED to [DM-7001]   (5) -the sources on coverage map are not clickable. However, on table and plot are clickable and work fine.- (FIXED)  ",6,5.371083
DM-6657,ffApi XYplot related issues found by irsa integration,"* default  symbol size, shape,and color setting is different from that of original version.  * no XY Plot Options pop-out windows  *  the plot displays non-ascii characters on the panel (for example: Ã‚ FitÃ‚ Ã‚ )  * miss Filter Dialog on the plot panel comparing with the original version.  *  does not accept default column names for the plot.",6,5.7928534
DM-6660,CR finder does not care about XY0 of input image,"Port of [HSC-1391|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1391]:  {quote}  The current version of CR finder does not care about XY0 of the input image and when I try to run CR finder on warped (difference) image, PSF cannot be properly extracted.  {quote}  and:  {quote}  I have noticed that the center of warped image is a gap between CCDs and PSF estimation there will fail. So get PSF without specifying the position is good enough. PSF class will select the best position.  {quote}",1,1.1235591
DM-6661,"ConfigDictField says ""Inequality in keys for..."" even if I give 2 same configurations","From [HSC-1401|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1401]:  {quote}  config.py:  {code:python}  from lsst.meas.photocal.colorterms import ColortermGroupConfig    for key in ['i', 'i2', 'y', 'r', 'N1', 'N2', 'N3', 'z']:      root.calibrate.photocal.colorterms.library[key] = ColortermGroupConfig.fromValues({}){code}    This comamnd line  {code:bash}  rm -fr output ; for i in {1..2} ; do processCcd.py ./HSC --output output -C config.py  ; done  {code}  raises following error  {noformat}  2016-06-01T02:43:45: processCcd FATAL: Comparing configuration: Inequality in keys for calibrate.photocal.colorterms.library: ['z', 'i', 'i2', 'r', 'y', 'N1', 'N2', 'N3'] != ['N3', 'i', 'i2', 'r', 'y', 'N1', 'N2', 'z']  2016-06-01T02:43:45: processCcd FATAL: Failed in task initialization: Config does match existing config on disk for this task; tasks configurations must be consistent within the same output repo (override with --clobber-config)  {noformat}  {quote}",1,1.0652562
DM-6663,Study iPlant as a potential candidate for workspace implementation,,2,5.325665
DM-6664,Investigate why afw.table.IdFactory doesn't allow reserved=0,"Setting reserved=0 when constructing a source ID factory (as would be logical when there is no exposure ID to reserve bits for) strangely doesn't work; it seems to be necessary to reserve at least one bit.  This may be a signedness problem (we use signed 64-bit integers for IDs to appease FITS, which is unfortunate), but we should be careful just reducing the number of available bits, as this could break code that expect to read IDs already written to disk.    Note that any change to this code in afw.table may require changes to code in daf.butlerUtils.ExposureIdInfo as well.",2,2.2254121
DM-6665,set up unit test for projection in Java,"While working on DM-6438 (set up unit test for projection in JavaScript), we realized we should have a parallel unit test system set up for Java code, to keep the two systems in sync. ",6,3.798832
DM-6667,Data Backbone conops iteration 4: submit to TCT,"Submit the document for TCT change control. Process is TBD.     If it is not accepted by TCT, further work is not in the scope of this epic, and would need to be planned in the EV system.",1,4.388047
DM-6668,Data Backbone conops: develop engineering considerations for BOE for work package,"Based on the data backbone services conops, develop a list of engineering considerations for making a BOE for the data backbone planning package.",3,4.2374654
DM-6669,Authentication & Authorization conops iteration 1: create raw draft (internal),Write a raw draft of the concept of operations for authentication and authorization services. In this iteration the document is developed in Google docs following the ConOps template.,5,5.738663
DM-6670,Authentication & Authorization conops iteration 2: group review to produce first draft,"Review raw draft of concept of operations for the AA services to work through underdeveloped areas, clear up uncertainties, and make readable.",2,1.7653396
DM-6671,Authentication & Authorization conops iteration 3: larger review to produce second draft,"Review first draft of AA services conops within Data Processing Architecture working group, bringing in relevant experts.    Input from review is incorporated into a second draft.  ",6,1.8985285
DM-6672,Authentication & Authorization conops formatting: convert second draft to reStructuredText,"When the AA services conops is in a solid state, convert the Google doc to reStructuredText following DM's documentation versioning process.",2,2.6827497
DM-6673,Authentication & Authorization conops iteration 4: submit to Systems Engineering,"Submit the document for TCT change control. Process is TBD.    If it is not accepted by TCT, further work is not in the scope of this epic, and would need to be planned in the EV system.",1,7.194956
DM-6674,Authentication & Authorization conops: develop engineering considerations for BOE for work package,"Based on the AA services conops, develop a list of engineering considerations for making a BOE for the AA planning package.  ",3,4.13746
DM-6675,Level 3 Hosting conops iteration 1: create raw draft (internal),Write a raw draft of the concept of operations for Level 3 Hosting services. In this iteration the document is developed in Google docs following the ConOps template.,4,5.488115
DM-6676,Level 3 Hosting conops iteration 2: group review to produce first draft,"Review raw draft of concept of operations for the L3 Hosting services to work through underdeveloped areas, clear up uncertainties, and make readable.",2,1.4031736
DM-6677,Level 3 Hosting conops iteration 3: larger review to produce second draft,"Review first draft of Level 3 Hosting services conops within Data Processing Architecture working group, bringing in relevant experts.    Input from review is incorporated into a second draft.  ",6,1.5459894
DM-6678,Level 3 Hosting conops formatting: convert second draft to reStructuredText,"When the L3 Hosting services conops is in a solid state, convert the Google doc to reStructuredText following DM's documentation versioning process.",2,2.3356097
DM-6679,Level 3 Hosting conops iteration 4: submit to TCT,"Submit the document for TCT change control. Process is TBD.    If it is not accepted by TCT, further work is not in the scope of this epic, and would need to be planned in the EV system.",1,3.1163561
DM-6680,Level 3 Hosting conops: develop engineering considerations for BOE for work package,"Based on the L3 Hosting services conops, develop a list of engineering considerations for making a BOE for the L3 Hosting planning package.",3,3.843318
DM-6681,Batch Processing for commissioning conops iteration 1: create raw draft (internal),Write a raw draft of the concept of operations for batch processing services for the commissioning phase. In this iteration the document is developed in Google docs following the ConOps template.,4,6.0545487
DM-6682,Batch Processing for commissioning conops iteration 2: group review to produce first draft,"Review raw draft of concept of operations for the batch processing for commissioning services to work through underdeveloped areas, clear up uncertainties, and make readable.",2,2.2551532
DM-6683,Batch Processing for commissioning conops formatting: convert first draft to reStructuredText in a technical note,"When the batch production for commissioning services conops is in a solid state, convert the Google doc to a DM technical note in reStructuredText.",1,2.365403
DM-6684,Batch Processing for commissioning conops: develop engineering considerations for BOE for work package,"Based on the batch services for commissioning services conops, develop a list of engineering considerations for making a BOE for the batch services planning package.",3,4.327968
DM-6685,"Planning package for Management, Engineering and Integration with engineering judgement BOE based on RACI diagram","Following list of elements for consideration (DM-6642), estimate planning packages for Management, Engineering and Integration WBS element.    BOE is derived from RACI document, which list roles and responsibilities of line management, reporting group, steering group, and area technical leads.",1,6.2256837
DM-6686,Planning package for L1 Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Level 1 Services WBS element.    BOE is derived from detailed plan for prompt processing and archiving services created in February and engineering judgement based on conops documents.",1,5.128503
DM-6687,Planning package for Batch Production Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Batch Production Services WBS element.    BOE is derived from engineering judgement based on conops documents.  ",1,5.6016383
DM-6688,Planning package for Data Backbone Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Data Backbone Services WBS element.    BOE is derived from engineering judgement based on conops documents.  ",1,5.84085
DM-6689,Planning package for Data Access Hosting Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Data Access Hosting Services WBS element.    BOE is derived from engineering judgement based on conops documents.",1,5.753114
DM-6690,Planning package for Common Workflow/Middleware with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Common Workflow/Middleware WBS element.    BOE is derived from engineering judgement based on conops documents.",1,4.9511547
DM-6691,Planning package for Misc. Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Miscellaneous Services WBS element. An example is the Authentication and Authorization services.    BOE is derived from engineering judgement based on conops documents.",1,3.8359609
DM-6692,Planning package for Development Support Services with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Development Support Services WBS element.    BOE is derived from engineering judgement.",1,5.856836
DM-6693,Planning package for ITC and Fabric Provisioning and Operation with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for ITC Fabric Provisioning and Operation WBS element.    BOE is derived from engineering judgement.  ",1,5.9248734
DM-6694,Planning package for Service Management with engineering judgement BOE,"Following list of elements for consideration (DM-6642), estimate planning packages for Service Management WBS element.    BOE is derived from engineering judgement based on ITIL methodology.",1,5.432318
DM-6695,Submit change request,Submit formal change request to restructure NCSA WBS in PMCS.,1,1.887445
DM-6696,Revise Level 1 ConOps    ,Revise the Level 1 conops to incorporate the minimal required functionality of Level 1 Services: minimal data archiving of camera data and minimal transport via data backbone to NCSA.,4,5.303938
DM-6697,Build draft design,Produce functional design breakdown from the revised conops (DM-6696).,16,3.333069
DM-6698,Articulate the design in format needed for planning,Articulate the design created in (DM-6697) into the format needed for planning.,12,5.3966417
DM-6699,Produce revised WBS,"Based on articulated design, revise WBS to incorporate phase.",10,5.472228
DM-6700,Discuss elements of RFC,Discuss elements of RFC (technical details and scope).,6,1.5989418
DM-6701,Produce RFC,Write up and submit RFC.,2,2.4113395
DM-6702,Respond to RFC comments and update RFC as needed,Respond to RFC comments and update RFC as needed.,2,2.470479
DM-6705,Select workflow based on conops and review of workflow systems,"Based on use cases/requirements gathered in DM-6270 and evaluation reports completed in DM-6276, select workflow system.",2,6.5885296
DM-6706,Discuss elements of RFC,"Discuss elements of workflow RFC (technical details, scope, requirements).",4,1.5989418
DM-6707,Produce RFC,Write up and submit RFC.,2,2.4113395
DM-6708,Respond to RFC comments and update RFC as needed,Respond to RFC comments and update RFC as needed.,2,2.470479
DM-6709,Pull down and install OCS SAL code in prep for ConOps development,"At the Camera Workshop in Mid-June, OCS Team members suggested that DM pull down their Service Abstraction Layer software and gain familiarity with it. The User manual is being studied before compiling the software and running it with DM software as a means of simulating planned Telescope & Site processes and how DM will interact with them.  Most of the work for this epic will be conducted in August. This story captures our prep work.",4,3.2714484
DM-6710,Monitoring plan for Startup procedure,Identify startup processes to be monitored for health and to provide notification for startup failure.,1,3.3320038
DM-6711,L1 entity prototypes,This story addresses the need to separate the processes that connect to the DAQ and retrieve the image data from the processes that forward the image data to NCSA. Requirements for this component and the component that formats the image data into a file which includes associated metadata were discussed at length during the Camera Workshop this month. Prototypes for these component processes are underway.,16,7.0441613
DM-6712,Message Dictionary additions,"Message types for system bookkeeping acknowledgements as well as report messages were added to the existing dictionary and the means for acting upon these message types are being added to component prototype code.  In addition, needed changes were made to the existing dictionary so all reporting entities write more complete details to their report message queues.",4,1.7816715
DM-6713,Amendments to message interaction,Proper acknowledgements began being added to the messaging system this month.,6,4.3220487
DM-6714,Camera Workshop attendance,Work on preliminary specific additions to the camera interaction ConOps took place this month during attendance at the Camera Workshop,6,3.3628938
DM-6715,Use Shifter+HTCondor  in processing Stripe82 ref data at modest scale,"To test out processing at modest scales (~ 100 -- 1000 cores)  utilizing Shifter+HTCondor on machines like BW, organize processing (processCcd of obs_sdss) of stripe82 data similar to that used in the lsst_dm_stack_demo (run=4192 field=300).",6,4.512507
DM-6723,Add tests for order of flags to all measurment plugins,"In the meas_base framework, we independently define an enumeration of available flags [(e.g.)|https://github.com/lsst/meas_extensions_photometryKron/blob/cba01575dab0cd609c7e2a3f3d08632b94f97f58/include/lsst/meas/extensions/photometryKron.h#L82] and a set of table fields for storing flags [(e.g.)|https://github.com/lsst/meas_extensions_photometryKron/blob/cba01575dab0cd609c7e2a3f3d08632b94f97f58/src/KronPhotometry.cc#L422]. We implicitly assume that these are declared in the same order, but do not, in general, enforce this.    In DM-6561, these were found *not* to be in the same order in meas_extensions_photometryKron. Setting a flag based on a bad result would therefore set the wrong flag in the output table.    In the DM-6561 solution, we introduced a test for this which is specific to the photometryKron codebase. However, the basic structure of the test would be easily extended to cover all meas_base plugins to ensure this error can never occur. Do so.",3,2.1500669
DM-6725,"Message refinement , in light of development #1",,12,3.5910537
DM-6726,Default chart and other optimizations,"These are the changes to support defalt chart and single chart type (as for IRSA release)  - Remove chart selection from chart area  - Use dropdown for chart selection (can be omitted if single chart type is used)  - Populate current values in chart options  - Support Clear and Reset in chart options  - For tables, connected to charts, if no default parameters are specified, default chart is an XY plot with CATALOG_COORD_COLS (used to produce an overlay) for catalogs or two first numeric columns for other tables.  - Label, matching column expression, and unit, matching table model, are default parameters for both app and api now.  ",6,4.311414
DM-6727,Message refinement #2,,12,3.5097425
DM-6728,Camera workshop attendance,"Attend camera workshop, Meeting did not fully address the need.  Travel to SLAC.",8,2.7161763
DM-6729,Summarize meeting results into Concepts of Operation,,2,5.4309816
DM-6730,ConOps for Comfort Console and System Monitor,"This is the first definition of the Concept of Operation of the Comfort Console and System Monitor piece of the DM system. This application will play a key role in fault detection and correction as well as monitor actively the state (and sub-state) of all the components in the DM system. Based on the role of the operator, he / she will be able to dig down into the faults and take corrective action. An action dashboard will provide a hierarchical view of the state of the system and its components at any point in time.",20,7.743709
DM-6731,Definitions of Alarms and Actions,This is a task to define all the failure cases and alarms that they should generate. It will also define the action that will be taken in the event of an alarm / fault and who will be taking the action.,30,4.7921658
DM-6732,"Process reference data on ""lsstdev pool"" for reference",,2,2.2695143
DM-6733,Reference processing on NERSC Cori Shifter implementation,,4,7.8689513
DM-6736,Write test jobs and submit files,,2,2.0212967
DM-6737,Investigate HTCondor configuration wrt dropping of nodes in backfill scenario,,4,2.5414014
DM-6738,Run test jobs and evaluate,,2,2.31436
DM-6740,Write final report,,2,2.1380558
DM-6741,Make SuperTask data-aware,,10,4.199874
DM-6742,Add workflow features,,10,3.2859223
DM-6743,Select existing tasks for prototyping conversion to workflow supertask,,1,4.86272
DM-6744,Convert selected tasks,Convert a {{CmdLineTask}} into {{SuperTask}},10,3.3274982
DM-6745,Finish gathering input from DM representatives,,3,2.4838212
DM-6746,Compile input,,2,3.2241476
DM-6747,Review conops template,,1,0.9956514
DM-6748,Iteration 1: Write raw draft based on input gathered from DM representatives,,6,2.5240555
DM-6749,Iteration 2: group review to produce first draft,,6,1.5124866
DM-6750,Iteration 3: larger review to produce second draft,,8,1.815956
DM-6751,Iteration 4: final draft and convert to reStructuredText to produce tech note,,4,1.121978
DM-6752,Service Management for F16 June,Dividing F16 Service Management  ~ monthly.,4,5.1210003
DM-6753,Service Management for F16 July, Dividing F16 Service Management  ~ monthly.  ,4,5.2780223
DM-6754,Service Management for F16 August, Dividing F16 Service Management  ~ monthly.,4,6.0091686
DM-6755,Write test programs to exercise Swift API with OpenStack ,,2,4.2139816
DM-6756,Write test programs to exercise Swift API with Ceph,,2,4.740747
DM-6757,Benchmark Swift command line tool for objects less than 5GB,,4,2.3065522
DM-6758,Benchmark Swift command line tool for objects greater than 5GB,,4,2.4527273
DM-6759,Benchmark Swift custom tool for objects less than 5GB,,4,2.3834023
DM-6760,Benchmark Swift custom tool for objects greater than 5GB,,4,2.5275533
DM-6761,Analyze results and write report,,4,2.4449775
DM-6762,Find and read documentation for OpenStack Swift API,,1,3.6197934
DM-6763,Find and read documentation for Ceph API,,1,3.0680013
DM-6764,Write abstract API,,4,4.191855
DM-6765,Research existing API,,2,9.173146
DM-6766,Find and read documentation for DDN WOS API,,1,3.662121
DM-6768,Create description of features in storage APIs,,2,4.9184976
DM-6769,Write test programs to exercise Swift API with DDN WOS,,2,3.9299355
DM-6770,Benchmark Swift command line tool for objects less than 5GB,,2,2.3065522
DM-6771,Benchmark Swift command line tool for objects greater than 5GB,,2,2.4527273
DM-6772,Benchmark Swift custom tool for objects less than 5GB,,2,2.3834023
DM-6773,Benchmark Swift custom tool for objects greater than 5GB,,2,2.5275533
DM-6774,Analyze results and write report ,,3,3.2795372
DM-6775,Write test programs to exercise object stores,,6,3.0601552
DM-6776,Benchmark Swift command line tool for objects less than 5GB,,2,2.3065522
DM-6777,Benchmark Swift command line tool for objects greater than 5GB ,,2,3.3411653
DM-6778,Benchmark Swift custom tool for objects less than 5GB,,2,2.3834023
DM-6779,Benchmark Swift custom tool for objects greater than 5GB ,,2,3.8984866
DM-6780,Write report ,,6,2.8081827
DM-6781,remove SizeMagnitudeStarSelector,"The sizeMagnitudeStarSelector is still in meas_algorithms, but it is unused and likely no longer works. We should either remove it, or update it to be fully supported.    The same holds true for any other C++-based star selectors we still have lying around.",1,2.390871
DM-6783,Add support for deriving from Python exception types to pybind11,DM-6302 adds support for custom exception translators to pybind11. However exceptions mapped do not inherit from Python {{BaseException}} or higher. This prevents exceptions from being raised and caught with {{except Exception as e}} in Python. This behaviour also occurs with Boost Python and Swig (we hack around it with a pure Python wrapper).    This ticket aims to solve the problem by adding support for inheritance from Python exception types to pybind11.,4,2.0319235
DM-6784,Port meas_extensions_convolved from HSC,HSC has a new measurement extension: meas_extensions_convolved.  This performs aperture photometry with the PSF degraded to nominated seeings (similar to how galaxy photometry is commonly done these days).    Relevant HSC tickets are [HSC-1395|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1395] and [HSC-1408|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1408].,5,1.2675647
DM-6785,Port parent/child measurement from HSC,"The deblender sometimes gets into trouble with cluster galaxies, and the deblended fluxes aren't accurate.  In that case it helps to have measurements on the image without any deblending having been performed.  This is a feature used in HSC's mid-2016 production run afterburner, ticket [HSC-1400|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1400].  This feature should be ported for use in LSST.",5,2.7831569
DM-6788,Document meas_extensions_ngmix,"meas_extensions_ngmix has no useful documentation, not even a {{doc}} directory. Add some.    This should include at least an overview of the package contents, a description of its capabilities, and instructions on enabling it within the meas_base framework. The package should have a README.",2,1.3348773
DM-6789,Provisioning,,15,5.5475097
DM-6790,Product Acceptance,,15,4.772389
DM-6791,Disaster Recovery Implementation,,20,12.19994
DM-6792,Documentation,,5,2.992436
DM-6793,Capability Validation,,5,7.8991957
DM-6794,Security Vetting,,5,4.347973
DM-6795,Acceptance by Stakeholders,,10,2.737503
DM-6796,Capability Design,,10,9.654732
DM-6797,Gathering product pricing,,10,8.003584
DM-6798,Updating LDM-143,,5,2.4216394
DM-6799,Acceptance into baseline,,5,2.6372766
DM-6800,Design,,10,5.6365256
DM-6801,Implementation,,10,7.152642
DM-6802,Capability Design,,15,9.654732
DM-6803,Procurement,,10,5.3200245
DM-6804,Reception and Placement,,10,3.5927663
DM-6805,Networking Configuration,,10,5.983064
DM-6806,Provisioning,,25,5.5475097
DM-6807,Disaster Recovery Implementation,,10,12.19994
DM-6808,Documentation,,10,2.992436
DM-6809,Capability Validation,,20,7.8991957
DM-6810,Security Vetting,,10,4.347973
DM-6811,Acceptance by Stakeholders,,10,2.737503
DM-6812,Qserv container crashes on Openstack using up to date CentOS/docker setup,"  {code:bash}  [qserv@lsst-fabricejammes-qserv-0 ~]$ docker run -it --net=host -e ""QSERV_MASTER=lsst-fabricejammes-qserv-0"" qserv/qserv:dev_master bash    qserv@lsst-fabricejammes-qserv-0:/qserv$ /qserv/run/bin/qserv-start.sh   INFO: Qserv execution directory : /qserv/run  Starting MySQL  [FAIL.] Manager of pid-file quit without updating file. ... failed!  [FAILing xrootd.[....] : Manager of pid-file quit without updating file. ... failed!   failed!  See startup logfiles : /qserv/run/var/log/xrootd-console.log, /qserv/run/var/log/worker/xrootd.log  [FAILing cmsd.[....] : Manager of pid-file quit without updating file. ... failed!   failed!  See startup logfiles : /qserv/run/var/log/xrootd-console.log, /qserv/run/var/log/worker/cmsd.log  [ ok ing mysql-proxy..  [FAILing qserv-watcher failed!  See startup logfile : /qserv/run/var/log/qserv-watcher.log  [ ok ing qserv-wmgr.    # Here error log can be different sometimes...  qserv@lsst-fabricejammes-qserv-0:/qserv$ cat /qserv/run/var/log/mysqld.log  ...  2016-06-27 23:50:00 140703880873792 [Note] InnoDB: Waiting for purge to start  2016-06-27 23:50:00 140703880873792 [Note] InnoDB: 5.6.27 started; log sequence number 1661735  2016-06-27 23:50:00 140703880873792 [Note] Plugin 'FEEDBACK' is disabled.  2016-06-27 23:50:00 140703105521408 [Note] InnoDB: Dumping buffer pool(s) not yet started  2016-06-27 23:50:00 140703880873792 [Note] Server socket created on IP: '::'.  2016-06-27 23:50:00 140703880873792 [Note] /qserv/stack/Linux64/mariadb/10.1.11.lsst2/bin/mysqld: ready for connections.  Version: '10.1.11-MariaDB'  socket: '/qserv/run/var/lib/mysql/mysql.sock'  port: 13306  Source distribution  2016-06-27 23:50:04 140703665879808 [Note] /qserv/stack/Linux64/mariadb/10.1.11.lsst2/bin/mysqld: Normal shutdown    2016-06-27 23:50:04 140703665879808 [Note] Event Scheduler: Purging the queue. 0 events  2016-06-27 23:50:04 140703088736000 [Note] InnoDB: FTS optimize thread exiting.  2016-06-27 23:50:04 140703665879808 [Note] InnoDB: Starting shutdown...  2016-06-27 23:50:06 140703665879808 [Note] InnoDB: Shutdown completed; log sequence number 4432991  2016-06-27 23:50:06 140703665879808 [Note] /qserv/stack/Linux64/mariadb/10.1.11.lsst2/bin/mysqld: Shutdown complete    160627 23:50:06 mysqld_safe mysqld from pid file /qserv/run/var/run/mysqld/mysqld.pid ended  160629 19:36:11 mysqld_safe Starting mysqld daemon with databases from /qserv/data/mysql  2016-06-29 19:36:11 139694065747776 [Note] /qserv/stack/Linux64/mariadb/10.1.11.lsst2/bin/mysqld (mysqld 10.1.11-MariaDB) starting as process 143 ...  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Using mutexes to ref count buffer pool pages  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: The InnoDB memory heap is disabled  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Memory barrier is not used  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Compressed tables use zlib 1.2.8  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Using SSE crc32 instructions  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Initializing buffer pool, size = 128.0M  2016-06-29 19:36:12 139694065747776 [Note] InnoDB: Completed initialization of buffer pool  2016-06-29 19:36:12 139694065747776 [ERROR] InnoDB: ./ibdata1 can't be opened in read-write mode  2016-06-29 19:36:12 139694065747776 [ERROR] InnoDB: The system tablespace must be writable!  2016-06-29 19:36:12 139694065747776 [ERROR] Plugin 'InnoDB' init function returned error.  2016-06-29 19:36:12 139694065747776 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.  2016-06-29 19:36:12 139694065747776 [Note] Plugin 'FEEDBACK' is disabled.  2016-06-29 19:36:12 139694065747776 [ERROR] Unknown/unsupported storage engine: InnoDB  2016-06-29 19:36:12 139694065747776 [ERROR] Aborting  {code}",10,1.6430749
DM-6813,Track statistics about user queries and tasks running on chunks,,9,1.486247
DM-6814,Move queries to different scheduler if too slow,,8,0.9636816
DM-6815,Update LSST full-stack processing configuration to match best practice from HSC,"In preparation for running an end-to-end comparison of large scale processing with the HSC and LSST stacks, we need to update the configuration to reflect currently understood best practice.    In general, we expect the default HSC configuration to be better understood and ""battle-tested"" given that it has been used for science-grade data releases.    Audit the default configuration of the full LSST stack (from ProcessCcdTask through multiband coadd processing). Where LSST defaults differ from HSC, update the LSST configuration to match the HSC equivalent unless there's a clear reason why LSST's default should be different. When it's not appropriate to update the LSST configuration, add an override to obs_subaru.    In some cases, the LSST and HSC stacks have diverged so that a direct transfer of configuration options isn't possible. Where an equivalent can be found, take advantage of it. Otherwise, stick with existing LSST defaults.",10,1.4359341
DM-6816,"Process HSC ""RC"" dataset through the LSST stack","Process the ""RC"" dataset used to verify HSC data releases through the LSST stack using the configuration specified by DM-6815.",4,2.9206057
DM-6817,Compare HSC and LSST processing of RC dataset,"Using the script enhanced in DM-6588, compare HSC and LSST (DM-6816) processing of the RC dataset.",8,4.2364025
DM-6818,Quality check LSST processing of RC dataset,Perform a quality analysis on the LSST processing of the RC dataset (DM-6816) in the same way as would be performed before an HSC data release.,5,4.1271195
DM-6819,Resolve CModel issues with aperture corrections,While working on DM-4202 it became apparent that the aperture corrections calculated and applied by CModel were too large. This ticket is intended to trace down where the failure is occurring and correct it.,4,2.9044795
DM-6820,Develop resource loaded plan for executing DRP sections of LDM-151,,20,3.9552233
DM-6821,Deliver DRP slide deck for LSST Director's Review,Required by 2016-07-12.,10,4.0589375
DM-6822,Add meas_extensions_ngmix to lsst_distrib,Primarily so it can enjoy the benefits of regular CI runs.,2,0.87007713
DM-6824,Use meas.algorithms.astrometrySourceSelector in measOptimisticB,"Now that there is a working astrometrySourceSelector (just merged in meas_algorithms from DM-5933), we should get matchOptimisticB working with it. This would entail replacing matchOptimisticB.SourceInfo with AstrometrySourceSelectorTask and tweaking the latter to do whatever matchOptimisticB needs, and removing SourceInfo.",2,2.9800012
DM-6828,Deliver sections for  Operations Use Case Report,"For each diagram covering a key use case, provide a narrative interpretation of the key concepts being conveyed, including significant operational implications from the concepts being presented.    Fill in the table for the assigned use case areas.    Key use cases/concepts include: L1 production, L2 production, ITC incident response, ITC problem management.",6,4.972876
DM-6829,Deliver sections for Concept of Operations,"Contribute to Concept of Operations sections about Chilean, NCSA, and CC-IN2P3 facilities. Describing the ""nuts and bolts"" basics and summarize each facility's role in the LSST operational system.",3,7.5895143
DM-6830,Investigate effects of turning on the Brighter-Fatter correction for single-frame processing of HSC data,"In the process of comparing HSC vs. LSST stack single-frame processing runs, we have been running with the Brighter-Fatter correction (BFC) turned off.  The reason for this to begin with was that is was not yet available on the LSST stack when we started these comparisons.  We also want to isolate as many features as possible in order to confidently assess their individual effects  The functionality was ported on DM-4837 with a default of *doBrighterFatter=False*.  This issue is to continue the single-visit run comparisons (see e.g. DM-5301, DM-6490, DM-6491) with BFC turned on on both stacks.    In particular, we are finding that slight differences in the reference stars selected for a given CCD can result in significantly different psf models.  Also, it was noted in DM-4960 that LSST seems to select reference stars to a brighter cutoff than HSC.  If a given field has a larger fraction of bright stars considered in the psf modeling, it is conceivable that it will be more significantly influenced by the BF effect, thus causing the large CCD-to-CCD variations seen in, e.g. DM-6490 (https://jira.lsstcorp.org/secure/attachment/28213/compareVisit-v1322-diff_base_PsfFlux-skyZp.png).",6,4.3120384
DM-6831,Wrap base with pybind11,Split off from DM-6302.,2,6.3352613
DM-6832,Wrap utils with pybind11,Split off from DM-6302.,2,5.6254253
DM-6833,add 'placeholder' attribute to the input element,An attribute called placholder is available in html element <input> to give a hint to the user of what can be entered. The placeholder text must not contain carriage returns or line-feeds.      Add it as proptype to <inputfield> component.,1,2.981893
DM-6834,Write report on SPIE conference,Write a report on my visit to the SPIE conference in Edinburgh.,3,1.9314712
DM-6835,Learning about Openstack,Sahand progress on learning about Openstack,4,3.974194
DM-6836,Create a python interface to access OpenStack,Sahand progress on getting the interface to access the Openstack interface using Nova Client,3,3.302652
DM-6837,Data Backbone Conops  iteration 1 prep:  Create a list of service endpoints,"Create a for list of service endpoints, with service considerations, and deliver to the Development file tree. Del with new ambiguities from the camera meeting at SLAC by listing the ""summit data services""  for both main camera and spectrograph as service endpoints,  since this may increase the functionality required, and it seems prudent to flow any of these requirement into further processes, since they seem likely.",2,3.0961044
DM-6838,Learning about Spark,Sahand progress on getting familiar with Spark and use of the interface to  create a small Spark cluster in OpenStack,4,2.930077
DM-6839,Learning about Docker,Sahand progress on learning Docker containers and potential automatic deploy in OpenStack,3,3.3241198
DM-6840,Set up and install Spark,Sahand progress on getting Spark installed ,2,1.4728879
DM-6841,Learning about Kubernetes,Sahand progress on learning about automatic deploy and scalability of Docker containers using Kubernetes ,2,4.476187
DM-6842,Deal with emergent related requests  affecting operations planning in June,"There emergent request for comment emerged in June.     1) The interim project manager,  directed that the project begin an investigation into Amazon Wen Service due to contacts he developed at a Data base orient workshop he sponsors.  Formulating  a response required a review of the service offered by AWS, and inquiring about the validity of pursing an evaluation of just one vendor in a marketplace that has many vendors, and a deciding that an appropriate amount of work was to send additional NCSA staff to an AWS workshop to gain a similar appreciation of AWS as was gained at the database meeting at SLAC.  (Authority of interim project manager to insist on immediate action was also sorted out)    2) Request to understand computing capabilities at alternate site from the Deputy director.  Support for for alternate site capabilities are documented in the  the emerging L2 Batch concept of operations a copy of which was shared (though draft status noted)     3) Processed a summary of the Camera meeting which occurred at SLAC. Did not find  conclusions that related to a concept of operations.    IN particular we could not understand it there was a call for computing and a summit data service to support disconnected operations,  or if this was a mere optimization in the system to relocate the acquisition and forwarding infrstructure to the summit, with no other changes.",4,2.3350694
DM-6843,Learning about Swift and HDFS,Sahand progress on storage objects to be used in OpenStack,4,5.0233874
DM-6844,Learning about Openstack and Jupyter,Di progress on learning these web technologies,5,4.0585794
DM-6845,Installing JS9 in Openstack server,,2,2.3573823
DM-6846,Learning about SocketIO and HTML REST API,Di progress on Communication technologies for the web,4,6.061649
DM-6847,Integrating Jupyter and JS9 for FITS visualization,Di progress in getting JS9 to work in Jupyter notebook,6,6.3439307
DM-6848,Write wrapper API for JS9 and Jupyter,Di progress in writing a wrapper to interact between JS9 within Jupyter,5,2.7694678
DM-6849,Understand the installation and administrative processes,"Review and gain administrative insight using the processes encoded in test scripts and other relevant features based on investigations in the prototype installations. For example, we may observe steps in test scripts to gain understanding of capabilities behind the scripts.    Provide comments on documentation where deemed helpful.",9,4.656076
DM-6850,Liaison with deployment effort,Interact with qserv developers supporting deployment and NCSA's service provisioning environment. Learn and investigate aspects of qserv administration present in test deployment but not previously covered.,10,4.201466
DM-6851,Setup multinode test environment for initial learning about installations ,Setup up one master node and one worker node.,3,2.3254025
DM-6852,Update Activator to reflect recent changes in CmdLineTask,,4,0.7164184
DM-6853,Discussion regarding  'quanta' definition in SuperTask,,2,0.81871605
DM-6854,Finalize documentation and current issues of prototype,"After updating some latest changes, need to update documentation to explain the extend of this supertask and activator initial implementation.",4,4.9403
DM-6855,TBD related emergent work in July,,5,2.6546156
DM-6856,TBD related emergent work in August,,5,3.1797702
DM-6857,Document that the catalog returned from star selectors is a view,"Star selectors return a catalog whose records are shallow copies of the input catalog records. Document the shallow copy aspect. This is important for two reasons:  - The user should know  - Implementers must be told this, because if the records are deep copies then the code that sets a flag for stars will not set a flag in the input catalog, which loses most of the point of setting that flag.",1,1.7471868
DM-6858,Mapper tests require modification when new datasets are added,"[~price] [recommends|https://community.lsst.org/t/centrally-defined-butler-datasets/841] a new way to define datasets common to all cameras in daf_butlerUtils, but modifying these yaml files require explicit lists of datasets to be modified in tests/cameraMapper.py.    If these tests are still useful, they need to depend on a minimal set of dataset definitions instead of the real ones.",1,2.3256214
DM-6859,Participation according to direction from interim project management,"Given directions from interim project management, participation consisted of direct conversations with Kevin and Jacek plus background work talking to staff related to assembling a plan.",5,7.2014427
DM-6860,Refine simple 1D DCR correction,"DM-5695 created a functional implementation of a simple DCR correction algorithm. While it appears to successfully create template images with airmass and DCR matched to science images, it is computationally inefficient and appears to introduce new artifacts to the template image. This ticket is to enhance the simple algorithm in several ways:  * Convert to sparse matrices where possible  * use variance weighting of the images  * propagate masked pixels correctly  * Refine the algorithm to mitigate the new artifacts",6,3.3607843
DM-6861,Understand how to render conops documents in Sphinx,Learn how to render conops documents in reStructuredText. Prototype conops template and for delivery into Technical Control Team Sphinx engineering environment.,1,1.0127956
DM-6862,Raw draft of System Monitor and Comfort Display,Produce raw draft of conops for review by steering committee. Includes operational components and connectivity for the system monitoring services that will monitor devices from the summit to NCSA.,3,6.6607795
DM-6863,Add verification feature to L1 conops,,7,2.5494196
DM-6864,Add verification test to L1 plan,,7,2.5608754
DM-6865,Add verification test to L1 design,,7,3.558197
DM-6866,Add verification feature to Data Backbone conops,,10,3.4288516
DM-6867,Add verification feature to L2 conops,,7,2.5885985
DM-6868,Add verification feature to Authentication & Authorization conops,,10,2.953056
DM-6869,Liaison with Systems Engineering,,6,10.425324
DM-6870,Appreciate amount of effort needed to run preliminary planning exercise,Run planning process with local staff to appreciate amount of effort needed.,5,3.5452874
DM-6871,Review evaluation criteria with CC-IN2P3,Review evaluation criteria with Fabio during his visit from CC-IN2P3 to NCSA.   https://drive.google.com/open?id=1Xhj6kaFEnNhCyRPskB6BCXYxgfs_9-cl3BRX9wCh1sE,1,2.9090304
DM-6872,Create evaluation plan from evaluation criteria,Turn criteria into tabular comparison chart and respect test implementation constraints.,4,1.8707082
DM-6873,Estimate amount of effort needed to run detailed planning exercise,"Run through process of detailing activities down to story size requested by the LSST EVM system.     Do detailed estimation of conops development and a sample of technical areas, and extrapolated based on number of epics, size of staff, and complexity of mission. Total = 100 hours for 3 months of activities for current staff size.",2,3.812542
DM-6874,Design framework for integrating procurement activities with invoices,Respond to request to relate equipment charges to acquisition strategy document procurement activities.,1,4.403206
DM-6875,Design framework for reporting and steering meetings,"Run the process with staff to assess and supervise technical status, the appropriateness of work compared to architectural vision, consistency with NCSA general acumen, and status vs. plan.",6,3.1493883
DM-6876,TBD processes coordinated with impending hire,"Design and implement critical processes defined in the RACI document, coordinated with impending hire.",6,4.2787
DM-6879,Address concerns with source side (Dave Mills),"Work with Dave Mills and others to understand architecture and use of ""source"" EFD. The goal is to understand the amount of volume of data that would be in reformatted EFD that otherwise would not have been, should we proceed with the proposed change.",8,4.13104
DM-6880,Address concerns with target side (SLAC),"Understand permissions and protections that would be in the reformatted EFD that otherwise would not have been, should we proceed with the proposed change.",8,3.8820302
DM-6881,Address internal concerns,Understand whether the file annex should be kept in the same cluster as EFD as opposed to general files in the data backbone.,6,2.0350187
DM-6882,Incorporate into ConOps and any draft design notes,"Incorporate concerns, solutions and agreements into ConOps and any draft design notes.",6,1.9618565
DM-6883,Address additional emergent concerns ,Address TBD additional emergent concerns ,2,2.8709383
DM-6884,Rework MemMan to be inline with the qserv worker Scheduler.,Split the memory mapping function from the memory locking function to allow the scheduler to initiate locking without blocking. Add additional memory tracking improvements in line with current thinking. Reduce lock contention. Add logging.,4,2.8662086
DM-6886,forcedPhotCoadd.py fails on CFHT data due to a CModel bug,"Hello,    forcedPhotCoadd fails while running on CFHT data due to a CModel bug. Here is an example on the error message that we get:    {code}  python: src/CModel.cc:1368: void lsst::meas::modelfit::CModelAlgorithm::measure(lsst::afw::table::SourceRecord&, const lsst::afw::image::Exposure<float>&, const lsst::afw::table::SourceRecord&) const: Assertion `measRecord.getFootprint()->getArea()' failed.  Aborted  {code}    Adding the following lines in cmodel.py (in CModelForcedPlugin.measure, before the call to self.algorithm.measure) allows to go around the problem for the time being, which seems to arise for null value of the number of pixel in a given footprint:    {code}  if not measRecord.getFootprint().getArea():      raise ValueError(""measRecord.getFootprint().getArea(): 0. No pixel in this footprint."")  {code}",1,2.1879742
DM-6890,deploy jenkins python env support,,1,2.5474515
DM-6892,Access to system with LSST stack,Secure access to machine(s) with the LSST stack. This includes installation on local desktop/laptop.,2,3.1091814
DM-6893,Controlled Test of LMSimpleShape using high SNR objects,"Some issues came up during DM-6300 which indicated that a more controlled set of tests would be required than the random Great3Sims tests to understand the behavior of NGMIX LMSimpleShape.      LMSimpleShape appears to fail computing moments on low SNR objects.  It also shows pretty wide variation in shear bias which did not show up with CModel.    The needed tests with would include controlled profiles (Gauss, Dev, and Exp), controlled SNR, and controlled q, theta, and flux.  This should separate out the causes of failure and shear variation which we have seen.",6,4.019543
DM-6894,Ensure DipoleFitTask uses correct PSF(s) in case when Decorrelation is turned on,"Diffim A&L decorrelation (DM-6241) modifies the diffim PSF, but leaves the ""pre-subtraction"" images used by DipoleFitTask as they were. Ensure that the correct PSFs are being used for dipole fitting when decorrelation is turned on (and actually, in all cases).",8,2.342587
DM-6897,Get data stream from socket into a fits file,Get data stream (module?) from Jim into a fits file than can be loaded subsequently to the butler.,2,1.875783
DM-6898,Load known image data format into the Butler,Use some type of known data (image) to load and test into the buttler. Data types might include DECam MEF images of single-plain image files from simulations.,2,4.7377167
DM-6899,Assemble data stream from socket to lsst-stack pipeline,Connect all of the parts together.,4,4.609967
DM-6900,ci_hsc failure: insufficient PSF sources classified as stars,"Since [ci_hsc#396|https://ci.lsst.codes/job/ci_hsc/396/], the regular ci_hsc build has been failing with:  {code}  [2016-07-05T23:59:53.929169Z]  FATAL: At least 95% of sources used to build the PSF are classified as stars (49 > 50): FAIL  [2016-07-05T23:59:53.929201Z] Traceback (most recent call last):  [2016-07-05T23:59:53.929238Z]   File ""/home/build0/lsstsw/build/ci_hsc/bin/validate.py"", line 3, in <module>  [2016-07-05T23:59:53.929249Z]     main()  [2016-07-05T23:59:53.929317Z]   File ""/home/build0/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 53, in main  [2016-07-05T23:59:53.929334Z]     validator.run(dataId)  [2016-07-05T23:59:53.929375Z]   File ""/home/build0/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 163, in run  [2016-07-05T23:59:53.929394Z]     self.validateSources(dataId)  [2016-07-05T23:59:53.929436Z]   File ""/home/build0/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 201, in validateSources  [2016-07-05T23:59:53.929451Z]     0.95*psfStars.sum()  [2016-07-05T23:59:53.929510Z]   File ""/home/build0/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 91, in assertGreater  [2016-07-05T23:59:53.929547Z]     self.assertTrue(description + "" (%d > %d)"" % (num1, num2), num1 > num2)  [2016-07-05T23:59:53.929587Z]   File ""/home/build0/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 82, in assertTrue  [2016-07-05T23:59:53.929614Z]     raise AssertionError(""Failed test: %s"" % description)  [2016-07-05T23:59:53.929660Z] AssertionError: Failed test: At least 95% of sources used to build the PSF are classified as stars (49 > 50)  {code}  This error appears to be related to DM-5877: when I reverted to versions of pipe_tasks, meas_base, meas_algorithms, ip_diffim, meas_extensions_photometryKron and obs_subaru predating that ticket landing, the error vanishes.    I note that [~nlust] reports that he does not see these failures on his (OS X) system, but I can reproduce them on Linux: we should investigate if that's just a coincidence, or if there is per-platform variation here.",1,0.46728706
DM-6902,VO search doesn't trigger coverage image nor overlay,"While migrating the VO search panel, i found the follwing problem: once the table gets back, no image coverage or overlay is rendered.  One problem from IRSA simple cone search result is that the VO table doesn't contain the right UCDs expected. The second problem when the VO table does contain the proper UCDs is that the META_INFO is not set.   The edu.caltech.ipac.firefly.server.query.SearchManager#jsonTablePartRequest doesn't set the attributes from the DataGroup object into the TableMeta data as it is done previously in OPS by edu.caltech.ipac.firefly.server.query.SearchManager#getRawDataSet    Please, add the META_INFO object missing to the table and set the proper CATALOG_OVERLAY_TYPE, and CATALOG_COORD_COLS needed so the Coverage image and overlay can be rendered.",4,3.7925334
DM-6903,Add an option to label ccd serial number on the showVisitSkyMap.py plot ,(actual assignee: Samuel Piehl)     Sometimes it is useful to know where the CCDs are on the plot. Add an option to label the CCD numbers. ,1,2.085451
DM-6904,Create DCR visualization tools,Several visualization tools will be very helpful to fully understand the effect of DCR correction algorithms and their failure modes.   * A function that generates difference images with the sources used for calibration and/or psf fitting marked.  * A visualization that indicates the spectral type of each source in an image. This could be a mask overlay where the color corresponds to the spectral type.  * A visualization of the coarse spectral resolution model built for DCR correction,5,5.879047
DM-6905,Locate the test dataset for PDAC,Locate and evaluate a dataset of SDSS Stripe82 which is going to be used for testing the prototype DAC.,2,2.351844
DM-6907,XYPlot density plot with log scale - bin size is not reflected correctly,"XYPlot with the large number of points does not display correctly when log scale is selected. When log scale is selected, binning on the server should be using the logs, so that the bins are the same size on the log scale. ",4,1.3949565
DM-6908,Filter editor on a chart toolbar,Need to add filter editor to the chart toolbar. Filter editor should be without selectable rows.,4,2.535687
DM-6909,Filtering from expanded mode cancels expanded mode,"When a table is filtered from the expanded mode, the layout is changed back to unexpanded.    It looks like the issue is more general: table actions trigger layout changes, which are not always right. For example, TABLE_REMOVE action while in a dropdown makes the  dropdown to get closed. I've traced it to FireflyLayoutManager.js:layoutManager generator function.    Test sequence in firefly:   - When a table is loaded, open ""Charts"" dropdown, select Col link for X, then select Col link for Y. (At this point the previous table is removed).  - TABLE_REMOVE action on the second click triggers dropdown to go away.   ",2,3.153241
DM-6914,git-lfs.lsst.codes certificate is expired,"Per reports on hipchat, the tls certifcate on git-lfs.lsst.codes was not upgraded to the new *.lsst.codes cert.    {code:java}  John Swinbank  9:52 AM  @josh @jmatt I'm seeing the following, which I think might be the same as @srp's error above. Any ideas?  Get https://git-lfs.lsst.codes/objects/24874b686b9479a823987dc2bd2700cad5b73e74a43108fb61b91d7f79f0cd99: x509: certificate has expired or is not yet valid  Followed by git lfs failing.  (I assumed it was user error on my part at first, but if so it's coincidence that Steve's git lfs fails at the same time.)  {code}    ",1,-0.023288736
DM-6915,"jointcalRunner passing tract to jointcal, which had tract removed from run()","When cleaning up jointcal for testing, I removed tract from jointcal.run(), but did not remove it from the return list of JointcalRunner.getTargetList(). Tract isn't actually used anywhere in jointcal.run(), so we should be able to just remove it from getTargetList's return.    Keeping those two in sync may be a bit tricky without a unittest that compares them.",4,2.529595
DM-6916,Documenteer seeds Git revision date and branch name if not present in metadata.yaml,"If {{last_revised}} and {{version}} are not present in metadata.yaml, then the Git commit date and branch name should be used while building metadata instead.    Also updates lsst-technote-bootstrap to take advantage of automated metadata for new projects.",1,1.1901424
DM-6917,Write User Guide for new validate_drp metric/measurement API,"DM-6629 provided a new API for consistently specifying metrics, their specification, and reporting results of measurements.    This API can, and should, be used beyond validate_drp for any code that wants to submit metadata to SQUASH. This ticket will provide user documentation on the API base classes to help other developers write new metrics and measurements.",4,3.8789833
DM-6918,Implement script to simulate AP workflow,"To understand better the load on L1 database I need a more or less adequate set of queries running against the databases. AP-generated queries should be a good start so a simple script that simulates what AP does will be very helpful. Sure I don't need any actual image processing or alert production, only the parts which read/write data to the database on per-visit basis.",10,4.6156955
DM-6919,"Please rename ""afterburners""","In DM-4887 we introduced a new measurement post-processing system which we called ""afterburners"".    The term ""afterburner"" is overloaded and applied in multiple contexts. To save confusion, please rename this system to something less ambiguous. Best if we can do this soon, before this usage spreads.",1,2.3965614
DM-6922,Upgrade to new stack install procedure for containers,"LSST stack install has evolved: https://pipelines.lsst.io/install/newinstall.html#  Release container creation script needs to be update.  Latest Docker version will be tested, as [~bvan] reported cmd line options have changed.",2,4.0215216
DM-6923,Apply distortion when searching for astrometric reference objects,"While investigating DM-6529 I found that LSST generally finds fewer reference objects than HSC when doing astrometry.  For the CCDs on the edge of the focal plane the number of stars was typically very low causing frequent failures.  I found that in the HSC code, there is a distortion being applied that shifts the exposure bounding box when getting objects from the reference catalog.  This distortion is not being applied in the LSST code.",1,3.2167287
DM-6924,Resurrect obs_file,obs_file needs to be resurrected.  This is partially due to the reorganization of processCcd.  My take is to try to make the ingest script read the files and ingest them keyed on the filename.  Then the dataId will be just the filename.  Hopefully we can then mock all the other info needed for processing in a general way.  Calibration (astrometric and photometric will be off by default).  ,8,1.7954661
DM-6925,star selector and PSF determiner are selecting stars that are not valid point sources,"When turning on CModel a more robust extendedness classifier relieved that many of the stars being used as PSF candidates were being classified as extended as shown in the attached plot. This plot was generated from the output of ci_hsc. Work should be done to determine why these stars are mistakenly being selected and fix the bad behavior. Additionally the [temporary work around in ci_hsc|https://github.com/lsst/ci_hsc/commit/6daf43ca41b6d192b6e1dbedb60cde0bec90b615], where the success criteria for validate sources in validate.py should be reverted from 85% to 95%.",4,3.4039116
DM-6928,HSC backport: Include PSF moments in the output tables,"This is effectively a port of [HSC-110|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-110] though, due to the considerable differences in bookkeeping for the SdssShape code, this will be more of a reimplementation.  ",4,2.2977638
DM-6933,access policy for PDAC,This is a Prototype DAC (PDAC) and the access to it is limited. We need to draft a access policy. ,1,2.268755
DM-6934,Startup Scaffolding Machine Requirements - Base,"Plan Base machine needs for Startup, including those processes that must run together on the same physical host (such as databases resident in memory needed by other processes).",2,4.6013393
DM-6935,Plan Base site machine startup pattern,"List all dependencies for specific processes that must be previously up an running. Establish the settings for 'time zero' on the startup timeline, such as purging queues, clearing specific data stores, arranging file system for startup, etc.",2,3.7047565
DM-6936,Prep for and attend Kubernetes meeting,"Kubernetes is a machine provisioning application that has potential to assist LSST Startup scaffolding such as Just In Time personality assignment, persisting config settings, etc.",1,2.3929982
DM-6937,Download and install Kubernetes,Implement a Kubernetes instance running on the Nebula cluster and begin configuration for testing Base site Startup behavior.,4,4.1239915
DM-6938,Evaluation of Kubernetes for Startup Scaffolding,"After Kubernetes is running as a simulated base site start up and provisioning tool, begin evaluation with fault injection such as the need for hot swap machine failover, sudden changes to Network topology and name server entries, etc.",3,5.765014
DM-6939,Set up proposed start up tools and procedure for NCSA L1 components,"If Kubernetes is the answer for startup provisioning which it is hoped to be, apply it to NCSA L1 machine startup requirements.",2,3.7146266
DM-6940,Final Startup Scaffolding document,"This is expected to be a document specifying the final Startup scaffolding disposition. If specification is not final, it will assess which requirements for this epic were not reached.",2,1.1866238
DM-6941,First round of updates to DRP LDM-151 sections from reviews,"Will address comments from [~swinbank], [~rhl], and probably [~ktl].",4,1.5285066
DM-6942,Explore and experiment the process of creating a Jupyter widget,Study the Jupyter notebook and understand the concept of Jupyter widget. Try to make a simple Jupyter widget that works with Firefly visualization.,4,5.5248637
DM-6944,Integrate multiple-backgrounds concept into LDM-151,It's recently become apparent that we need to at least consider using different background estimation techniques for different kinds of measurements.  This is will require some thought to work into our current processing plans.,4,4.3066363
DM-6945,Add text to algorithmic components sections in LDM-151,"While [~swinbank] has commented that the outlines are probably good enough for planning work (and I thnk that's broadly true), the lack of text in the algorithmic components section did occasionally lead to some misunderstandings in [~rhl]'s first review pass, so I think I should flesh that out with text sooner rather than later.    In this issue, I'll stick to sections that no one else has added text for, but eventually I'll also need to work with [~krughoff] and perhaps others to ensure that section has a consistent level of detail and focus.",8,2.9693224
DM-6949,Firefly has problem to render in other browsers than Chrome,"Couple of problem using Firefly in  Safari:  * the components appears blank,    in Firefox:   * image and xyplot are not aligned (Gator).    The alignment can be reproduced in my Chrome and Safari.  Search parameters: ALLWISE source catalog, m81 100arcsec.   ",1,3.7486165
DM-6952,Table problems,"Table component has couple of problems:    #  Scrambled table values after column selection and saving the table, then reset mess up the table. Saving the table and reset makes the table comes back.  #  table display no longer redefines column names in the table based on the column label, e.g. ""Field Size"" instead of ""s_fov"".  #  Downloaded file is not a valid IPAC table.  #  Filtering table does not change image overlay or plot until table is saved. At that point, the filtering works, but the plot symbol changes (happens when result is decimated, datapoints > 5000?)  #  In Edit Table Options, it's unclear what the reset button resets to.  ",6,3.6027293
DM-6953,Image problems are grouped in this ticket,"Image viewer has a couple of issues:    * There is no panner for the image (is it missing from the API or is it a bug in calling it?)  * No readout value from thumbnail image  * -Image does not have toolbar or layers control (Gator) - probably API options to be used or missing?- -> move to DM-7001  * -Markers don't show up in PNG download- -> moved to DM-6980  * The top bar readout doesn't include units for the pixel flux  * Clicking on the expand icon deletes the image (in API only)  * Clicking on the expand icon diabled the expand mode of table and xy plot (in API only)   * Image button ask you for a position and displays that, wiping out whatever image brought you to IRSA Viewer in the first place. It should give another tile of the same field, drawn from the selected data set. (IRSAVIewer only)  * Need mode to draw grid without labels  * RangeValues messing up image display        {noformat}  old:  var external= firefly.getExternalViewer();  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚external.setDefaultParams({â€‚â€‚ ""TitleOptions"" : ""FILE_NAME"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""ColorTable""â€‚â€‚ : ""1"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""TitleFilenameModePfx"" : ""cutout"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""PostTitle""â€‚â€‚â€‚â€‚:â€‚â€‚""\locstr\"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""OverlayPosition""â€‚â€‚â€‚â€‚:â€‚â€‚""\lon\;\lat\;EQ_J2000"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""RangeValues""â€‚â€‚: firefly.serializeRangeValues(""Sigma"",-2,8,""Linear"")  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚}) ;    new:  xtViewer.setDefaultParams({â€‚â€‚""TitleOptions"" : ""FILE_NAME"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""ColorTable""â€‚â€‚ : ""1"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""TitleFilenameModePfx"" : ""cutout"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""PostTitle""â€‚â€‚â€‚â€‚:â€‚â€‚""\locstr\"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚""OverlayPosition""â€‚â€‚â€‚â€‚:â€‚â€‚""\lon\;\lat\;EQ_J2000"",  â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚}) ;   The ""RangeValues"" were taken out for now   ""RangeValues""â€‚â€‚: firefly.util.image.serializeSimpleRangeValues(""Sigma"",-2,8,""Linear"")  {noformat}  ",14,1.4658118
DM-6954,XY plot problems found,"implement the items listed here:  * min/max options are now gone after migration, need to be added.  * Use the expression for X, Y column as the default label, otherwise the read out could be confusing.  * label changes for decimation: X-Bins and Y-Bins:  Number of X-Bins, Number of Y-Bins * shrink the size (to 1/5?)  of the blue dots for data representation.  I do like the circle when the point is highlighted.  * The units on the plot are indicated with a comma, e.g. â€œdec, degâ€, should be ""dec (deg)"" as before   Need to confirm again ([~ejoliet])  * -Making a change to the plot (e.g. ra = ra * -1), then clicking on the gears to close makes the shading legend disappear. It also â€œquantizesâ€ the plot- (not any more) * What happens now is the plot appears without legend after a search. Then making a change to the plot (e.g. ra = ra * -1 or filtering the table), then applying makes the legend appears/disappears. Expanding the table and collapsing it, make the legend disappears. *- Step to reproduce: Catalog search on 2MASS around m16 with 10' radius. * Greyscale introduced, where different colors represent different numbers of points. After filtering, the points change color to blue.  (This is because the it is not decimated any more) * -Clicking on plot gears makes plot unusably small.- (Not applicable any more since gear now brings up the options in popup) ",6,1.9458605
DM-6955,Message Dictionary Adjustment.,"Audit format of existing messaging and adjust according to 'wants' not task 'needs'...that is, msg body format that exists now is sufficient to fulfill tasks, but destination components must receive a broader description of overall system state. This will allow all components to log a more comprehensive snapshot of current state and is needed for troubleshooting. These additions to the message dictionary will be configurable like a logging priority levels function, and additions to message payload can be turned off for typical nightly operation.",4,2.6593797
DM-6956,'ACK' (Acknowledgement) message formats,"Enumerate ACK messages for all primary message types. Prototype both blocking and non-blocking acknowledgement aggregator that works via timeout, behavioral change, etc. This is related to DM-6411",4,3.020254
DM-6957,Adding ACK messages to existing code framework,New entries in message dictionary must be added and tested with the existing messaging code base.,4,3.1120358
DM-6958,Documentation for new message types,Add new ACK message types to existing Dictionary documentation.,2,2.4679909
DM-6959,Messages as objects,"Consider creating a dictionary of code objects to represent messages. Currently message bodys are built on the fly - evaluate pros and cons of switching to a message factory pattern. Message types are not a very extensive list, but switching to object implementation could increase maintainability of code.",2,2.9074938
DM-6960,Overlay health check code,Implement and overlay health check mechanism on existing messaging control code. Prototype and gather timing information to determine optimal frequency of checks and the location in the exposure cycle when these checks should occur.,8,3.0314753
DM-6961,Fault Injection in the form of unsuccessful health checks for components,Build testing mechanism to inject faults into into health framework and stub code to address health check failures,4,5.131081
DM-6962,Create policy for health check failure,"Document policy regarding action to take when various components are found to be unhealthy. This can vary depending when 1 component type (Forwarder) is offline versus 21 Forwarders offline. In addition, plans must be formulated for addressing the point in the exposure cycle when the health failure occurs.",4,1.7483119
DM-6963,Implement health failure policy,Formalize the prototypical implementation of health checks and associated policy into 'what to do' actions,4,3.683473
DM-6964,Make a proposal for API support for representation of relationships between table columns,"End users and the SUIT need to be able to determine a variety of relationships between columns in the tabular data products produced by LSST.  The particular example motivating this ticket is the need to answer the question ""where in the table is the uncertainty data for column 'x'?"".    The answer could be:  * ""there isn't any""  * ""a symmetric Gaussian uncertainty is in column 'sigma_x'""  * ""asymmetric Gaussian uncertainties are in columns 'sigmaplus_x' and 'sigmaminus_x'""  * ""'x' is correlated with 'y' and the covariance matrix is in 'covar_xx', 'covar_xy', and 'covar_yy'""     Ideally we would find a way for these relationships to be defined when the Apps code generates its afw.table outputs, discoverable through an API usable in the afw.table context, exportable to the database, and made available to end users and the SUIT.  It should be usable whether the data are delivered to end users as reconstituted afw.table objects or as tables in common Python formats (at least Astropy tables).    It should assist the SUIT in determining how to (automatically, though optionally) display uncertainty data when the primary data are requested.    This ticket expresses the idea that a solution that consists purely of a documented convention about prefixes to the string names of columns is inadequate.  We would like to avoid having to write code implementing that convention in, potentially, hundreds of places, and we would like to avoid requiring that end users know these conventions in order to see proper displays with error bars.  ",3,1.883977
DM-6966,Flesh out software primitives,Jim has put together a fairly complete software primitives section.  This task is to read it over from the perspective of Alert Production and expand/refine where necessary.,4,9.408884
DM-6967,Level 2 conops formatting: convert draft to reStructedText,,1,1.8229305
DM-6968,create a shared stack on NFS for use with  the current local condor pool,"It is well known that building, setting up a stack, and interactive devel work with those operations on NFS has performance issues.  Hence the official shared stack on lsstdev uses /ssd .    However,  a shared stack on NFS is useful and adequate for one important  use case --   users need a stack that can be used for small productions on the local condor pool currently available  on lsstdev.   For this use case multiple ""source""/""setups"" on a node/against the file system  can be avoidable by using a script to directly declare the environment.  run_orca /ctrl_orca supports this feature.       While GPFS is coming soon, there is expected to be a transition period of 2-3 months and so the NFS file system and a stack on it can serve users for an interim period.   If building a shared stack on NFS is not a heavy labor, we think it is worth the effort for this interim period, and as such make this request for a shared stack on NFS. ",1,1.3521078
DM-6969,Fixes to LoadIndexedReferenceObjects,Bug fixes for using the new {{LoadIndexedReferenceObjectTask}} and its associated components.,2,2.6751542
DM-6970,Add tests for bindings of Eigen::Array and ndarray::EigenView,"[~pschella] has discovered that we don't have test coverage for converting less-common Eigen types to Python.  This is not urgent, but it should be fixed.",1,3.3119066
DM-6971,Qserv 2016_07 release,- Update release notes  - Publish docs and bump version numbers,1,1.6181949
DM-6972,Fix Qserv install doc and scripts for new newinstall.sh,Update qserv install docs per new info at https://pipelines.lsst.io/install/newinstall.html,1,0.22124103
DM-6973,"Fix metadata date problem in LDM-{463,152,135}",These docs are currently borken in CI -- just need to have the dates reformatted in their metadata.yaml,1,2.6697567
DM-6974,Type of IngestIndexedReferenceTask_config wrong in obs_ paf files,"In DM-6651 I moved the new HTM indexed reference catalog code from pipe_tasks to meas_algorithms, but didn't do a complete job. The type of IngestIndexedReferenceTask_config in obs_ paf files still must be updated.",1,1.3565702
DM-6975,Document release milestone changes in DMTN-020,Please add a note to DMTN-020 describing the changes to release milestones discussed at the [DMLT meeting of 2016-07-18|https://confluence.lsstcorp.org/display/DM/DM+Leadership+Team+Meeting+2016-07-18].,1,2.7875605
DM-6976,watch for Highcharts update ,"There is an issue in the density plot for displaying the legends. Highcharts does not support the setting of the symbol size in the legends. So when the symbol size is too small or too large, the legends are not displayed.     We don't want to do too much workaround currently. This ticket is to watch for the Highcharts update. ",1,3.135998
DM-6977,verification and test of the Bayesian histogram calculation on server side,We need to set up some unit tests of the Bayesian histogram calculation.     First we need to do some verification of our algorithm with scientists.  I think we can find some known data sets and the results with help from scientists.   The unit tests should include several different distribution of input data. ,10,4.391349
DM-6978,Update qserv for changes in Log interface,DM-6521 improved Log class interface by replacing some static methods with non-static. Qserv is currently using couple of static methods which were retained in Log class for the duration of this migration. Once updated log package is released update qserv code to use new non-static methods and remove static methods from Log class after that.,2,3.8384216
DM-6980,Markers don't show up in PNG download,Markers don't show up in PNG download,4,1.5591073
DM-6982,Fix oversampling settings in psfex,"The current settings in psfex will only turn on oversampling only if the seeing is < 0.5"", even if you have configured it do oversampling. This needs to be changed so that everything is determined by the config parameters.    We have also seen on HSC data that oversampling in general does not work well in psfex.  We need to change the current configuration which does 2x oversampling to just use the native pixel scale.",1,1.4798805
DM-6983,ci_hsc failure: AttributeError: 'Butler' object has no attribute 'repository',"Following [~npease]'s [recent changes to the Butler|https://community.lsst.org/t/im-checking-in-butler-changes-related-to-rfc-184/959], ci_hsc is failing as follows:    {code}  [2016-07-20T07:57:31.954576Z] Traceback (most recent call last):  [2016-07-20T07:57:31.954643Z]   File ""/home/jenkins-slave/workspace/stack-os-matrix/compiler/gcc/label/centos-7/python/py2/lsstsw/build/ci_hsc/bin/validate.py"", line 3, in <module>  [2016-07-20T07:57:31.954664Z]     main()  [2016-07-20T07:57:31.954732Z]   File ""/home/jenkins-slave/workspace/stack-os-matrix/compiler/gcc/label/centos-7/python/py2/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 53, in main  [2016-07-20T07:57:31.954756Z]     validator.run(dataId)  [2016-07-20T07:57:31.954825Z]   File ""/home/jenkins-slave/workspace/stack-os-matrix/compiler/gcc/label/centos-7/python/py2/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 155, in run  [2016-07-20T07:57:31.954851Z]     self.validateDataset(dataId, ds)  [2016-07-20T07:57:31.954923Z]   File ""/home/jenkins-slave/workspace/stack-os-matrix/compiler/gcc/label/centos-7/python/py2/lsstsw/build/ci_hsc/python/lsst/ci/hsc/validate.py"", line 117, in validateDataset  [2016-07-20T07:57:31.954956Z]     mappers = self.butler.repository.mappers()  [2016-07-20T07:57:31.954991Z] AttributeError: 'Butler' object has no attribute 'repository'  [2016-07-20T07:57:32.023212Z] scons: *** [.scons/ingestValidation-903342-100] Error 1  {code}    See e.g. https://ci.lsst.codes/job/stack-os-matrix/13274/compiler=gcc,label=centos-7,python=py2/console.    Please fix it. ",1,1.1127692
DM-6984,Suggest logging migration in daf_persistence and daf_butlerUtils,Use lsst::log instead of pex::logging in daf_persistence and daf_butlerUtils,2,2.7316546
DM-6985,Suggest logging migration in afw,Suggest a changeset with lsst::log instead of pex::logging in afw,5,2.5672338
DM-6986,Suggest logging migration in pipe_tasks and meas packages,Suggest changesets using lsst::log instead of pex::logging,5,1.0471343
DM-6987,Write up a description of Composite Datasets based on input from KT,"Write a description of composite datasets as I understand them based on the email KT sent on May 20 (attached), and on conversation I had with KT and Fritz on July 20.",2,2.6596873
DM-6988,Review Composite Dataset description document with stakeholders,"Review the composite dataset description document with [~jbosch] and [~Parejkoj], and any others who may be interested (e.g. post on community or do an RFD)",2,3.384642
DM-6989,ctrl_events/tests/EventAppenderTest.py fails Jenkins run-rebuild,"ctrl_events/tests/EventAppenderTest.py started failing on Jenkins ""run-rebuild"" last night:   https://ci.lsst.codes/job/run-rebuild/354//console    All test cases in EventAppenderTest.py did run and pass, but it failed with a Segmentation fault in the end.     Jenkins ""run-rebuild"" uses a stack on NFS on lsst-dev (/nfs/home/lsstsw).  The same test passes on regular Jenkins (stack-os-matrix).      ",3,1.4487919
DM-6990,Improve testing in SQuaSH prototype,This ticket captures some testing practices from https://ep2013.europython.eu/media/conference/slides/obey-the-testing-goat-rigorous-tdd-for-web-development-with-django-and-selenium.pdf  that we intend to use in the SQuaSH prototype.     - Use selenium to test user interactions  (functional tests)  - Use unittest module for unit tests   - Include some documentation about testing in sqr-009 ,5,6.065877
DM-6991,Add a script to summarize what visits are in what patches,"(Actual assignee: Samuel Piehl)     Have a script to show what visits are in what tracts/patches. This is especially useful for running coadd making and processing (e.g. makeCoaddTempExp, assembleCoadd) with runOrca and HTCondor, as the dataId of the jobs need to be specified. So this script's output will be in the format of a runOrca input file.     ",5,1.2186846
DM-6992,Extend SQuaSH dashboard to work with multiple datasets,"Currently SQuaSH dashboard works only with a fixed dataset. We want to ingest measurements of metrics computed by validate_drp for multiple test data e.g CFHT, DECam and HSC. In order to handle multiple datasets, we need a new model in SQuaSH  and extended the job API to ingest the measurements for different datasets. The user must be able to selected in the interface the dataset to be displayed.",3,3.602726
DM-6996,produce a draft document of SUIT requirements,"After combing through the current SUIT requirements, we feel that we need to re-organize and re-write the SUIT requirements to be in-line with SUIT vision document.    This story will be producing the first draft of the rewrite. ",20,3.769797
DM-6998,Problems with MemoryTest ordering,"{{MemoryTestCase}} (or a derivative thereof) must be run as the last of all tests in a module in order to properly catch leaks.    [Our documentation|https://developer.lsst.io/coding/python_testing.html#memory-and-file-descriptor-leak-testing] implies, and [SQR-012 states|https://sqr-012.lsst.io/#memory-test], that this can be achieved by listing it as the last test case in the file.    This works for py.test, but not when using plain old unittest: the latter does not, so far as I can see, guarantee any sort of ordering as a matter of principle, and, in practice, it sorts things lexicographically (it uses whatever order it gets from running {{dir()}} on the test module, and I don't *think* that's guaranteed to be anything in particular).    For example, consider [{{testAstrometrySourceSelector.py}}|https://github.com/lsst/meas_algorithms/blob/master/tests/testAstrometrySourceSelector.py]. I made the following change to introduce a memory leak:    {code}  --- a/tests/testAstrometrySourceSelector.py  +++ b/tests/testAstrometrySourceSelector.py  @@ -70,8 +70,9 @@ class TestAstrometrySourceSelector(lsst.utils.tests.TestCase):           self.sourceSelector = sourceSelector.sourceSelectorRegistry['astrometry']()         def tearDown(self):  -        del self.src  -        del self.sourceSelector  +        pass  +        #del self.src  +        #del self.sourceSelector         def testSelectSources_good(self):           for i in range(5):  {code}    Py.test catches it:  {code}  $ py.test-2.7 testAstrometrySourceSelector.py  [...]  testAstrometrySourceSelector.py .........F  [...]  {code}    But simply running the test suite does not:  {code}  $ python testAstrometrySourceSelector.py  ..........  ----------------------------------------------------------------------  Ran 10 tests in 0.105s  {code}    Rename the test case:  {code}  @@ -144,7 +145,7 @@ def setup_module(module):       lsst.utils.tests.init()      -class MyMemoryTestCase(lsst.utils.tests.MemoryTestCase):  +class xMyMemoryTestCase(lsst.utils.tests.MemoryTestCase):       pass     if __name__ == ""__main__"":  {code}    And boom:  {code}  $ python testAstrometrySourceSelector.py  .........  54 Objects leaked:  {code}    Based on a very quick check, I think [sconsUtils runs tests by simply invoking {{python}}|https://github.com/lsst/sconsUtils/blob/f9763768d999cefa4c26b9f3418c28394dfb38df/python/lsst/sconsUtils/tests.py#L133], and I'm pretty sure that this is hard-wired into the muscle memory of many developers. In these cases, memory tests written following current guidelines won't be being properly executed.    ",3,2.7064188
DM-6999,Use lsst::log in pipe_base and pipe_tasks,"Per RFC-203, switch from using pex.logging to lsst.log in pipe_base and pipe_tasks (stage 2)",8,1.4886935
DM-7000,Remove pex_logging dependency on pipe_tasks,,3,1.0196676
DM-7001,Gator / Image Vis issue,"Issues with coverage:     * Toolbar icon not showing up  * If only one point that is no coverage image (or one table with many records but has the same ra,dec values)  * CANâ€™T REPEAT: In expanded mode, magnifier fails when image fills the visible space entirely (seems to affect 'Coverage' image only)  * Missing feature: before migration, in expanded mode, the toolbar had an 'added image' button which was bringing an image search panel to add images to the current view. => _move to:_ DM-7068  * CANâ€™T REPEAT: if marker/footprint overlay is clicked, that doesn't activate the image viewer and doesn't update the layer dialog either.  * in laptop screen size, the toolbar is not fully visible, scrolling from left to right only move the background but not the expanded panel.  * CANâ€T REPEAT:in expand mode and zoom 'fill the visible space' clicked, the magnifier image doesn't show anything from the coverage image, can be reproduced in http://localhost:8080/firefly/demo/ffapi-highlevel-test.html (BTW, it happens in finderchart in OPS on any image in expanded mode ( ? ) )  * Readout is sometimes off the screen  * Expanded then return to normal: zoom is not adjusted correctly    If we find a way to repeat the items marked 'CAN'T REPEAT' they should go into another ticket.  Maybe in DM-7068 if it is still opened.  ",4,4.591723
DM-7003,Match across filters -- Make color-color diagram,Add the capability to match across filters.    1. Create color-color diagrams  2. Analyze performance metrics as a function of color.,4,2.7875454
DM-7004,Add ellipticity measurement to validate_drp,"Calculate the ellipticity, and the residual ellipticity (moments - PSF).    Add to calculated SRD statistics.    This will involve thinking about things on an image-by-image basis, which is the natural and largely SRD-specified way for considering ellipticity.",4,2.0736365
DM-7005,Show the list of packages that changed from build to build linked to the git url of the latest commit,Motivated from the deviation seen from build 156 to 157 in  https://squash.lsst.codes/AM1 (caused by a commit in meas_algorithms package) we can show the list of packages that changed in the current build with respect to the previous build by comparing the git commit shas and return a list of tuples with the package name and git url.,2,0.6609265
DM-7006,Update squash to use bokeh 0.12.1,"Bokeh 0.12 was just released and some issues are being fixed, before updating the bokeh version used in SQUASH we propose to wait for 0.12.1 release.  ",1,2.2770944
DM-7007,Investigate coverage of S13 databases found so far,Look at databases located at *NCSA* so far to assess if they cover the full survey. The databases to be evaluated are mentioned in [DM-6905].    According to [S13 Testing Plan|https://dev.lsstcorp.org/trac/wiki/Summer2013/ConfigAndStackTestingPlans/Instructions] the S13 DRP dataset was split into two regions with an overalp used for cross-site verification:  * *NCSA*: -40< R.A. < +10  * *IN2P3*: +5 < R.A. < +55    Hence a goal of this task is to identify which previously located candidate databases and files correspond to either or both of these ranges.,4,4.1158824
DM-7008,Check boost.python building with Python 3,We may want to disable boost.python in the build. There are hints that there are problems with python3.5.,1,2.1048055
DM-7009,std::string construction from NULL pointer in ctrl_events,"I was browsing through ctrl_events package and found couple of instances in the headers where std::string instance is constructed from NULL pointer:  https://github.com/lsst/ctrl_events/blob/master/include/lsst/ctrl/events/Receiver.h#L87  https://github.com/lsst/ctrl_events/blob/master/include/lsst/ctrl/events/Transmitter.h#L81    I suspect that this code is never executed and those methods are overridden in subclasses because that construct will very likely crash when executed (std::string does not support construction from zero pointer, it will try to read from that pointer). Even if it's not executed it's better to change to return empty string or, if those two classes are never instantiated, make them abstract and make the methods pure virtual.  ",1,1.4279062
DM-7010,Builds should be optimised by default,"By default, our builds are not optimised ({{-O0}}), which requires everyone who doesn't want to wait until the heat death of the universe to set {{SCONSFLAGS=""opt=3""}}, but other packages that are built with scons may not recognise this.  This default is also contrary to the standard practise for open-source software, which is that by default builds are optimised.  I will change the default optimisation level to {{opt=3}} from the current {{opt=0}}.  I will also add support for {{-Og}}.    This change was approved in RFC-202.",1,1.4647487
DM-7011,Run DECam data through proccessCcd.py and imageDifference.py,,2,1.2960459
DM-7012,assign initial responsibilities in LDM-151,Assign first thoughts responsibilities to all software primitives and algorithmic components.  This is my take.  John will have his own take.,2,2.8192677
DM-7014,Memory cache leak in firefly server,The visualization system is not update the memory accounting for the caching system.,2,2.330498
DM-7015,Analyze segmentation fault in EventAppenderTest,Analyze the bug described in DM-6462,4,5.690349
DM-7016,Big image not showing working message when the load,"This is a problem with uploads, large image loads, and Atlas.   When a big image is loading the user does  not get feedback.  The problem is the the UI is not creating the ImageViewer soon enough.",2,1.9288071
DM-7017,Firefly JavaScript API documentation to support Camera team,Convert API documentation and code examples to get Camera team started with the converted Firefly FITS viewer. ,6,4.5198293
DM-7018,Firefly distribution build,"We need to support regular Firefly distribution builds (with bundled tomcat server),  similar to the builds we did in lsst firefly repository before the conversion.    This is to get Camera team started with new API.",2,5.625407
DM-7019,Setup standalone Firefly build using IPAC github,Modify the existing Firefly-Standalone build in Jenkins to use IPAC's github.  Make sure github auto-releases still works.,3,2.5137818
DM-7021,Update pex_exceptions to support Python 3,{{pex_exceptions}} needs to be updated to support Python 3.,1,2.0654523
DM-7022,Package an experimental Firefly widget,The aim is to package an experimental Jupyter widget with limited functionality so that it can be installed like other Jupyter widgets. Only a small set of Python and Javascript code will need to be packaged -- the widget will connect to a Firefly server. The [Jupyter widget cookiecutter|https://github.com/jupyter/widget-cookiecutter] provides a template.  ,4,7.1978216
DM-7024,Add more features to JS9 Wrapper ,"Di progress on adding extra features to JS9, including load and saving regions in the local notebook server, same with files. ",4,3.264159
DM-7025,Investigate the option to use websockets used by jupyter to explore bi-directional communication ,Di progress on understanding the possibility of using websocket locally to communicate with JS9 instances on local server. In this case we wouldn't need an external server and communication can be bi-directional. Now is only in one direction (mostly) when running Js9 locally ,3,2.640917
DM-7026,Setup up a cluster with kubernetes,Sahand progress on installing and deploying a cluster automatically with Kubernetes. After this is completed we will use a user case example of running in cluster managed by Kubernetes/Spark,6,2.420809
DM-7028,Port daf_base to Python 3,Changes necessary to get daf_base to work with Python 3.,1,2.4604745
DM-7029,Image Bugs noticed in the API testing,"- Image is coming with one draw layer. (I can delete this draw layer and nothing changes on the image)    - When draw layer is deleted, and no more layers are present, the layers dialog should be closed. (It stays with nothing to display, you have to click x to close it.)    - After selecting an area in one viewer, I select an area in another viewer, then move the mouse to the first one:      147 ImageViewerLayout.jsx:314 Uncaught TypeError: Cannot read property 'x' of null at ImageViewerLayout.jsx:314   Nothing works after that. I have to reload.    - Selection appears with an offset, if the page, which contains the viewer is scrolled. (Load the attached script, press 'Start selection tracking' click to select a point, then scroll page a bit down, then click to select another point - it shows down from where it should be.)    - I have 2 image viewers in separate divs. Selected line in one, then selected line in the other. The line from the first one disappeared, but its label is still there. (See attached image.)    - Selection is working differently from distance. To select in another plot, I need to press selection again. I don't need to press ruler again to select new distance in another plot.    - It's possible to select distance tool and then area selection. First drag would define area selection, all the following line. A click would be defining a 0 length line, even if point selection is enabled. _move to_ DM-6473    - The payload.attValue of CHANGE_PLOT_ATTRIBUTE action is using WorldPt for area and point selections (when payload.attKey is 'SELECTION' or 'ACTIVE_POINT'), but ImagePt for line selection (when payload.attKey is 'ACTIVE_DISTANCE') How can I make them all use image coordinates?        ",6,3.8144984
DM-7030,Update xrootd from upstream,,4,1.5207121
DM-7031,Assign initial responsibilities in LDM-151,Assign first thoughts on responsibilities to all software primitives and algorithmic components. This is my take. Simon will have his own take.,2,2.6163104
DM-7032,Estimate resource requirements for Software Primitives,Meet with Jim & Simon. Discuss the Software Primitives section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate.,3,7.807597
DM-7033,Estimate resource requirements for Software Primitives,Meet with Simon & John. Discuss the Software Primitives section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate.,3,7.807597
DM-7034,Estimate resource requirements for Algorithmic Components,Meet with Jim & Simon. Discuss the Algorithmic Components section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate,3,8.516052
DM-7035,Estimate resource requirements for Algorithmic Components,Meet with Simon & John. Discuss the Algorithmic Components section of LDM-151: clarify any ambiguities and perform an initial resource loading estimate,3,8.516052
DM-7036,Port pex_policy to Python 3,Changes needed to make pex_policy work on Python 3,1,2.1041033
DM-7037,Check endianness in ndarray/numpy conversions,"As reported on [community.lsst.org|https://community.lsst.org/t/how-to-run-the-dm-stack-on-simulated-fits-images/892/9], our {{ImageF(array)}} constructor will accept arrays with non-native endianness and interpret them as native.  This probably means the array converters in ndarray aren't including byte order when checking whether a passed array's dtype matches the expected C++ type.  ",2,2.196586
DM-7038,Setup JSDoc generation for the API portion of Firefly,"We need generate and publish JSDoc for Firefly JavaScript API, both high and low level.",4,5.7731037
DM-7039,Familiarization with Footprint redesign,"Familiarize yourself with the RFC-37 driven Footprint redesign. Start thinking about ideas for how you could implement it and what the transition plan from the current Footprints might be.    A great outcome would be to propose a set of stories which would tackle the new Footprint development effort.    A good outcome would not be to have the stories ready to go, but to be well prepared for a discussion with [~jbosch] & [~swinbank] where we'll come up with some stories as a group.",5,5.493218
DM-7040,Stars selected by starSelector change when number of cores varies,"Sogo Mineo writes in [HSC-1414|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1414]:  {quote}  See the following lines:    meas_algorithms/HSC-4.0.0/python/lsst/meas/algorithms/objectSizeStarSelector.py:466  in ObjectSizeStarSelector.selectStars():  {code}      if psfCandidate.getWidth() == 0:          psfCandidate.setBorderWidth(self._borderWidth)          psfCandidate.setWidth(self._kernelSize + 2*self._borderWidth)          psfCandidate.setHeight(self._kernelSize + 2*self._borderWidth)  {code}    In reduceFrames, these lines set the width of psfCandidate to be 21  for the first time the execution reaches there.    When the first CCD image has been processed, the worker process  continues to process another CCD image, and the execution reaches  here again.  This time, psfCandidate.getWidth() is 41, because  psfexPsfDeterminer has set it to be 41, and the value has been  retained because the width is a static member.  And so, for the second  CCD image, the width of psfCandidate is not 21 but 41.    Since psfCandidates are widened, stars positioned at edges of images  are rejected.  It results in a smaller number of PSF candidates than expected.    Only CCD images that are initially given to the worker processes  are processed with psfCandidate.getWidth() == 21. The other CCD images are  processed with psfCandidate.getWidth() == 41.  When the number of SMP cores changes, CCD images are processed with different  parameters.    The change in the number of PSF candidates results in different Psf, a different  result of image repair, and different catalogs.  {quote}    The line numbers are different on the LSST side because of refactoring (objectSizeStarSelector.py:466 has moved to starSelector.py:148), but the bug is still present.  The main problem appears to be that the {{PsfCandidate}} elements are {{static}}, are being set in both the star selector and the PSF determiner and one of those is conditional on what the value is.  I will investigate moving the {{static}} class variables to instance variables --- the desired size appears to vary by context, so it shouldn't be a class variable.",2,2.3452663
DM-7044,Additional constraints on reference band selection for multiband,"Reference band selection currently depends on the configured band priority order, with exceptions made for sources with low signal-to-noise in the high priority bands.  [HSC-1411|https://hsc-jira.astro.princeton.edu/jira/browse/HSC-1411] points out that some additional qualifications, such as success for major measurements (e.g., CModel and Kron), would be helpful.",3,3.300042
DM-7046,Prototype python cache for weak_ptr and weakref objects.,"There is a requirement for composite datasets that components of composites be cached and shareable, and we expect to use an object cache for this.   We have identified that we need to be able to cache C++ weak_ptr and python weakref in the same cache in an opaque way. This needs some prototype R&D.",2,2.4294229
DM-7047,Port pex_config to Python 3,Work involved in ensuring that pex_config passes all tests on Python 3 and legacy Python.,1,2.1280932
DM-7048,validate_drp is failing because it's accessing butler internals that have changed,need to change obs_decam's ingest task to use the newer class hierarchy to get the root of the butler's single repository. (longer term there should be a butler API for this or the task should get the value of root from somewhere else),1,1.2163881
DM-7049,Move patch/tract and config mapping definitions to daf_butlerUtils,"Implement RFC-204 by adding new entries for all patch/tract and config mapping definitions to .yaml files in daf_butlerUtils, and removing any such entries that are identical to the common ones from .paf files in obs* packages.    I think the ""common"" entry can usually be defined by consensus between any two of obs_cfht, obs_decam, and obs_subaru (and frequently all three).  If there are any patch/tract or config datasets for which no two cameras agree, I think we should use obs_subaru's definitions (but I doubt there are any such cases).    Entries that are not identical to the common ones should not be removed on this issue (that should make this change entirely backwards compatible), but should be documented in new per-camera issues for later standardization.",4,2.2736278
DM-7050,LTD Keeper: Use Google Cloud Platform SQL,"Currently LTD Keeper uses a sqlite DB. This ticket will migrate that DB to Googleâ€™s Cloud Platformâ€™s managed SQL. This solution provides automatic backups, and provides flexibility to run multiple ltd-keeper pods. Googleâ€™s SQL makes sense since LTD Keeper is run on Google Cloud Platform.",5,4.4075446
DM-7051,conda installation from the stack channel brings in astropy 1.2,If you do a conda install of lsst_sims from http://conda.lsst.codes/sims you get astropy-1.1.1.  If you do the same install from http://conda.lsst.codes/stack you get astropy-1.2.1.  This is a problem for the sims stack since the sncosmo package (on which we depend for our simulations of supernova light curves) is sensitive to which version of astropy you are running.    Was it intentional that the two channels deliver different versions of astropy?,2,2.6140964
DM-7053,Assemble a complete database with S13 DRP catalogs,Create a database populated with complete catalogs resulting from processing of the *SDSS Stripe 82* data at both NCSA and IN2P3 sites. The database has to be created at NCSA on the following database server:  * *lsst-db.ncsa.illinois.edu*    The database name will be:  * *gapon_SDRP_Stripe82*    The database will be populated with the contents of the following databases:  * *NCSA* (lsst-db.ncsa.illinois.edu):  {code}  daues_SDRP_Stripe82_ncsa  daues_SDRP_dedupe_byfilter_0  daues_SDRP_dedupe_byfilter_1  daues_SDRP_dedupe_byfilter_2  daues_SDRP_dedupe_byfilter_3  daues_SDRP_dedupe_byfilter_4  {code}  * *IN2P3* (ccdb02.in2p3.fr):  {code}  lsst_prod_DC_2013_2  lsst_prod_dedupe_byfilter_g  lsst_prod_dedupe_byfilter_i  lsst_prod_dedupe_byfilter_r  lsst_prod_dedupe_byfilter_u  lsst_prod_dedupe_byfilter_z  {code}    Additional requirements:  * The duplicate entries (due to the overlap in the RA range) will need to be carefully assessed and eliminated.  * the referential integrity of the resulted database will need to be tested  ,16,3.6074305
DM-7054,Kick-off meeting,[~nlust] & [~swinbank] will meet with the SUI/T team on 2016-07-26 and discuss how we can best engage with them.,1,1.9975835
DM-7055,fix miscellaneous table issues,# disable sorting when content is html  # table options: auto-adjust all column width based on content  # table refractoring: exposing more actions to saga.  #* renamed a few actions to better reflect what it's doing.  #* added TABLE_FILTER  #* added document for sequence of actions where applicable.  # update build script to skip buildClient when possible.  # Catalog overlay should not use table id in drawing layer description. (See the attached screenshot.) It should be using MetaConst.CATALOG_OVERLAY_TYPE attribute value,4,1.7596276
DM-7056,Wrap afw::table with pybind11,"Following the same pattern as DM-6926, DM-6297, etc.",8,4.7702746
DM-7057,Complete afw port to pybind11,,10,2.2435985
DM-7059,Plot sources/source density on WCS quiver plots,"We should show the individual sources (size/color scaled by S/N?) that went into the jointcal fit, and/or a density map of the sources (scaled by S/N?) under the quiver plots. This will help distinguish areas with poorly constrained fits or where the TAN-SIP function diverges, from those where the new WCS really is odd.",2,4.557473
DM-7060,Plot old/new jointcal WCS vs. tangent plane,"To better understand the jointcal WCS vs. the original single frame TAN-SIP, we need quiver and heatmap plots of each WCS (old and new) separately vs. a tangent_pixel or related ""non-distorted"" projection. This will let us compare the original single frame fit with jointcal's fit.    This probably could be done with CameraGeom, but would be easier with the upcoming new WCS/transform system, since it may involve pulling out a new Frame.",4,2.326116
DM-7061,"Plot ""real"" distortion by comparing with reference catalog","To compare the old WCS and jointcal's fit with the ""real"" distortion, we can use the matched reference catalog to plot a quiver diagram or an interpolated heat map showing how far each star is from its reference star. We may have to think about how to select objects for this plot, since centroiding errors would make it not so useful.    This would probably be most useful for lsstSim, since that has an infinite-precision reference catalog.",4,2.3403475
DM-7062,Support work related to PDAC effort,"This issue captures emergent work to support for example DM-6905 , for which I spent some cycles locating datasets of the 2013  SDRP, staging some files off of BW tape through globus online and unpacking to /nfs/scratch,  etc.    This effort may not fit exactly as 'emergent middleware',  but it was roughly the best fit at this time. ",3,3.1556737
DM-7063,support work for testing shared stack in NFS,"It was realized that the ""shared stack of lsstdev"" was not actually usable on the local condor pool due to /ssd usage.   In response to this,  an effort for a second shared stack on NFS  was initiated in DM-6968.  This issue captures the emergent work of pipeline testing to validate the new stack of that issue. ",2,3.2316203
DM-7065,Extend functionality of experimental Jupyter widgets for Firefly,"A package for experimental Jupyter widgets for Firefly is being developed in  https://github.com/Caltech-IPAC/firefly_widgets . Using the Firefly Javascript API for Images and Tables, add some further useful functionality for demonstration purposes.",4,6.3438973
DM-7066,Port pex_logging to Python 3,Work required to get pex_logging working on python 3. Will also include some package cleanups.,1,2.3071723
DM-7067,Break joincal's link to upstream lsst_france repo,"lsst/jointcal is still linked to the upstream repo at lsst_france. I believe all the relevant changes have been ported. It's time to break that upstream link, so that pull requests can be made in a more obvious fashion.",1,0.3713156
DM-7068,Firefly API bugs 2,"*Issues*    Gator:  * Missing feature: before migration, in expanded mode, the toolbar had an 'added image' button which was bringing an image search panel to add images to the current view.    * The Gator Multi-object search seems having problem with the coverage image.    Atlas:    * if marker/footprint overlay is clicked, that doesn't activate the image viewer and doesn't update the layer dialog either. Large drawing layers block viewer from becoming active, WFIRST footprint or WFC3/IR cause the problem.  *  -in expand mode and zoom 'fill the visible space' clicked, the magnifier image doesn't show anything from the coverage- - not a bug, magnifier is disable when zoom level is above 8x     API:  *  In API, it is not possible to drag dialogs (ex. Drawing Layers).    All Firefly (found by Tatiana):    * The highlight should of catalog or coverage overlay should just change if you are close to the point. For now I am setting it to 20 pixels  * -Catalog overlay should not use table id in drawing layer description. (See the attached screenshot.) It should be using MetaConst.CATALOG_OVERLAY_TYPE attribute value.- _Moved to_ DM-7055    * After using distance tool in one plot, then the other, clicking again in the first plot does not make it active. (You have to click on the border of the plot to make it active, clicking inside does not help.)    This seems to cause strange behavior, when selections do not work as expected. For example: select ruler, select some lines alternating first and second plot. Unselect ruler, select area icon. Selecting in the first plot will still show distance. I had to delete distance tool drawing layer or click on the border for things to start showing area selection.    In general, there is some confusion with active plot, when I have two viewers. Should a plot become active as soon as mouse enters is? Otherwise in readout, compass thumbnail will still show active plot, while readout thumbnail could use another plot.  _note from trey: this is the same problem as the marker/footprint in atlas described aboved_",4,6.2511363
DM-7069,Port daf_persistence to Python 3,Work relating to getting daf_persistence to run on python 3. Includes some code modernization.,1,2.8952584
DM-7070,Move consts from top of Associations.cc into JointcalConfig,There are three values at the top of Associations.cc under a TODO comment that should be lifted up into JointcalConfig so they can be configured at runtime. It would be good to try to add tests to check different values for them (and possibly just remove usnoMatchCut).,1,2.2273126
DM-7071,Fix Django admin interface ,"Django admin interface is useful to edit db entries in SQUASH if needed, e.g decam measurements that were incidentally pushed to the dashboard during X16.    A bug was found using the admin interface in development mode, due to a bad field returned by the Jobs model.    This ticket is to capture the fix for this bug, this new git ref will be deployed for better control of data in SQUASH database.    ",1,1.7563354
DM-7072,"visit DRP team, June 2016",Travel to Princeton June 13-17 and meet with the DRP team; work and learn about L2 processing; discuss the workflow requirements and use cases. ,8,3.3396766
DM-7073,Install ESXi on lsst-dm-mac.lsst.org,Install and configure ESXi on the Mac Pro server.,7,1.3163662
DM-7074,Install Mac OS X Mountain Lion on ESXi,"Install, configure and snapshot Mac OS X Mountain Lion. Unfortunately this is required to install any other Mac OS VM on ESXi.",1,2.6719296
DM-7075,Install Mac OS X Yosemite on ESXi,"Install, configure and snapshot Mac OS X Yosemite. This requires configuring the vmx file then installing Mac OS X Mountain Lion and upgrading.",2,2.2372758
DM-7076,Install Mac OS X El Capitan on ESXi,"Install, configure and snapshot Mac OS X El Capitan. This requires configuring the vmx file then installing Mac OS X Mountain Lion and upgrading.",2,2.9612453
DM-7077,Install MacOS Sierra on ESXi,"Install, configure and snapshot MacOS Sierra. This requires configuring the vmx file then installing Mac OS X Mountain Lion and upgrading.",1,2.459067
DM-7078,Firewall and SSH configuration on ESXi,"Figure out and configure the firewall, ssh server and ssh client for ESXi.    This isn't especially well documented since it's part of VMWare vSphere.    This part specifically was time consuming since most users by vSphere.",2,4.471883
DM-7079,Upgrade panopticon to 5.0.0-alpha4,This upgrade requires moving from Topbeat to Metricbeat which requires some minor rework and upgrading the entire system at once.,2,2.1934314
DM-7080,Doxygen isn't updating,"The current build of our Doxygen documentation, as displayed at https://lsst-web.ncsa.illinois.edu/doxygen/x_masterDoxyDoc/index.html, is labelled ""Generated on Mon Jun 27 2016 03:52:22 for LSSTApplications"". At time of writing, that's more than a month ago. Important additions to the documentations made during the last month are missing.  ",1,1.1097374
DM-7081,Airflow,Review [Airflow|https://github.com/apache/incubator-airflow] workflow management system against criteria defined in the epic.,6,6.852825
DM-7082,deploy django admin interface fix,Test and deploy django admin fix from DM-7071.,1,1.7477992
DM-7083,Install MySQL and PostgreSQL servers on ccqserv124,"Time to run my incomplete L! prototype on real hardware, for that I need MySQL and PostgreSQL servers on a dedicated machine in in2p3 cluster (ccqserv124). Probably start with installing what comes with the system repos before trying latest and greatest stuff.    Both servers need to be configured to allow me create databases/tables, and I only need to enable connections from localhost.  ",1,2.0772984
DM-7084,Astropy views not available on Catalog subclasses,Somehow the {{asAstropy}} isn't being inherited by {{BaseCatalog}} subclasses in Python; it's probably getting messed up by the fact that {{Catalog}} is a template and this is added at the Swig level.,1,4.177657
DM-7088,Image select panel not yet working correctly with coverage,The image select panel needs to be able to modify the coverage image.,4,2.7041197
DM-7090,"IrsaViewer catalog panel, labels and input fields moved as you type","Catalog search panel in IrsaViewer, the target panel label, feedback, and input box are jumping as input is being typed.  Their position should be fixed.",2,2.7601264
DM-7091,F16 Qserv Release Mgmt,"Developer work to support the monthly and end-of-cycle qserv releases.  Includes compiling release notes, updating package dependencies, updating installation docs, minor fixes in support of new compilers, etc.",20,10.039993
DM-7094,"Develop Sphinx configuration for Pipelines Documentation, including MVP HTML/CSS Template","This ticket will kick-off a pilot implementation of pipelines documentation in Sphinx. Specific goals are    1. Develop template for sphinx-ready doc/ directories in packages (based on SQR-006)  2. Setup a MVP sphinx template that works well with numpydoc and astropy automodsumm. Simply porting astropyâ€™s sphinx template would be pragmatic.  3. documenteer-driven configuration for sphinx.    These will be MVPs, and iterated upon in later tickets that implement sphinx API docs for stack packages.",1,3.4752378
DM-7103,Run DAX containers at NCSA,"This is an initial step to manually launch the containerized DAX services on the new PDAC cluster.  This is meant to expose container configuration, account setup, privilege, logging, debugging, etc. issues.",4,2.9667864
DM-7104,support PDAC Qserv deploy,"Support John in adapting scripts and methodology as necessary to support qserv deploy on the PDAC cluster at NCSA, as is currently done at IN2P3.  ",8,3.2466686
DM-7105,Qserv 2016_08 release,,1,1.6265582
DM-7106,PDAC Qserv Deploy,"Configure cluster and adapt scripts and methodology as necessary to support qserv deploy on the PDAC cluster at NCSA, as is currently done at IN2P3.  ",13,6.1997485
DM-7107,Deliver revised slides for Joint Status Review,"Deliver a modified version of the slides from the July 2016 Joint Directors (sic) Review, plus service any other requests from Project Management.",6,4.105985
DM-7108,Provide updated F16 DRP plan for PMCS ingest,"Only the first three months of F16 were concretely resource loaded and ingested into PMCS at the start of the cycle. A provisional plan was loaded for the remaining three months. Check, refine and update than plan as necessary.",4,3.8329728
