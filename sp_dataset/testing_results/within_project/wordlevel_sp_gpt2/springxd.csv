issuekey,title,description,storypoint,raw predictions
XD-3016,Document Kafka message bus properties,"For example, how to specify the partition count for topics that are created by the message bus.",1,2.80794
XD-3017,Fix package tangles,See:     https://sonar43.spring.io/drilldown/measures/7173?metric=package_tangle_index,5,2.4058204
XD-3018,Update to spring-data-hadoop 2.2.0.M1,"We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes, timeout).    A few things to keep in mind:  - this updates Cloudera CDH to 5.3.3  - Kite version is now 1.0 - need to test the hdfs-dataset sink  ",2,2.3374014
XD-3019,Document how to use the module registry backed by HDFS,"As a user, I'd like to refer to the documentation, so I can configure HDFS backed module registry (XD-2287) as recommended. ",1,4.0796523
XD-3020,Persist Deployment Properties,"As a user I would like the ability to undeploy or suspend a module without losing the deployment properties.  Currently when temporarily suspending a module an undeploy and redeploy is executed.  During the redeploy the deployment properties need to be added again.  Instead, it would be nice if the properties are persisted so they automatically included with the deployment.",5,2.9662385
XD-3021,Update Docker Versions,Update the current docker images to 1.1.0 Release,1,2.913477
XD-3022,Kafka Message Bus ignores consumer concurrency when computing partition count,"This is a combination of two issues:  - the internal property `next.module.concurrency` is computed from `concurrency` when it should be computed from `consumer.concurrency`  - even if `next.module.concurrency` is set, the KafkaMessageBus rejects it, since it's not set in SUPPORTED_CONSUMER_PROPERTIES    As a result, the value used in partition calculation is always 1.    A workaround exists, by setting the `module.[moduleName].producer.minPartitionCount` property to the expected total value. ",3,4.2297072
XD-3023,SSL Config for RabbitMessageBus Connections is Ignored,,1,2.583611
XD-3024,"Add new REST-API to get all the counters, gauges, and rich-gauges","As a user, I'd like to have a REST-API to get all the _counters_, _gauges_, and _rich-gauges_ in a single request, so I don't have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.    *Example:*  {code}  /metrics/counters/all (fetches all available counters)  /metrics/gauges/all (fetches all available gauges)  /metrics/rich-gauges/all (fetches all available rich-gauges)  {code}",5,2.3438213
XD-3025,SpringXD sqoop module is hanging,"The SpringXD Sqoop module is in execution status until it times out, it is hanging.     The container logs show:    2015-05-04 15:15:45,365 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'sqoop_lookup'  2015-05-04 15:15:45,536 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@239b037a moduleName = 'sqoop', moduleLabel = 'sqoop', group = 'sqoop_lookup', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map['args' -> '--connect=jdbc:oracle:thin:@************:****/******* —username=******** --password-file=/user/zeybeb/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d -m 1', 'command' -> 'import'], children = list[[empty]]]  2015-05-04 15:16:17,061 1.2.0.M1  INFO inbound.job:sqoop_lookup-redis:queue-inbound-channel-adapter1 sqoop.SqoopTasklet - Sqoop system.out: /tmp/Sqoop-948322291323951735.out    The /tmp/Sqoop-948322291323951735.out file content is:    15:16:17,612  INFO main sqoop.SqoopRunner - Sqoop command: import  15:16:17,613  INFO main sqoop.SqoopRunner - Using args: [--connect=jdbc:oracle:thin:@************:****/*******, —username=*********, --password-file=/user/zeybeb/workspace/secure-files/gdw.password, --table=MASTERDATA.W_LOOKUP_D, --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d, -m, 1]  15:16:17,613  INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd21  15:16:17,631  INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://ilabphd07.isus.emc.com:8020  15:16:17,753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=ilabphd08.isus.emc.com:8050  15:16:17,753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=/usr/hdp/2.2.0.0-2041/etc/hadoop/conf.empty,/usr/hdp/2.2.0.0-2041/hadoop/*,/usr/hdp/2.2.0.0-2041/hadoop/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-hdfs/*,/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-yarn/*,/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*,/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/*,/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*,/usr/hdp/2.2.0.0-2041/sqoop/*,/usr/hdp/2.2.0.0-2041/sqoop/lib/*,/usr/hdp/2.2.0.0-2041/flume/*,/usr/hdp/2.2.0.0-2041/flume/lib/*,/usr/hdp/2.2.0.0-2041/storm/*,/usr/hdp/2.2.0.0-2041/storm/lib/*  15:16:17,754  INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn  15:16:17,837  WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.  15:16:17,907  INFO main sqoop.Sqoop - Running Sqoop version: 1.4.5  15:16:18,282  WARN main util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable  15:16:19,552  WARN main sqoop.ConnFactory - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.  15:16:19,657  INFO main oracle.OraOopManagerFactory - Data Connector for Oracle and Hadoop is disabled.  15:16:19,673  INFO main manager.SqlManager - Using default fetchSize of 1000  15:16:19,673  INFO main tool.CodeGenTool - Beginning code generation  15:16:20,639  INFO main manager.OracleManager - Time zone has been set to GMT  15:16:20,853  INFO main manager.SqlManager - Executing SQL statement: SELECT t.* FROM MASTERDATA.W_LOOKUP_D t WHERE 1=0  15:16:21,018  INFO main orm.CompilationManager - HADOOP_MAPRED_HOME is /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd21  15:16:23,171  INFO main orm.CompilationManager - Writing jar file: /tmp/sqoop-spring-xd/compile/4e11123a52fa36d6677efdb47bcdc43b/MASTERDATA.W_LOOKUP_D.jar  15:16:23,191  INFO main manager.OracleManager - Time zone has been set to GMT  15:16:24,109  INFO main manager.OracleManager - Time zone has been set to GMT  15:16:24,825  INFO main mapreduce.ImportJobBase - Beginning import of MASTERDATA.W_LOOKUP_D  15:16:24,848  INFO main manager.OracleManager - Time zone has been set to GMT  15:16:24,876  WARN main mapreduce.JobBase - SQOOP_HOME is unset. May not be able to find all job dependencies.  15:16:25,083  INFO main client.RMProxy - Connecting to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:8050  15:16:25,977  INFO main db.DBInputFormat - Using read commited transaction isolation  15:16:26,117  INFO main mapreduce.JobSubmitter - number of splits:1  15:16:26,361  INFO main mapreduce.JobSubmitter - Submitting tokens for job: job_1429280992648_0019  15:16:26,717  INFO main impl.YarnClientImpl - Submitted application application_1429280992648_0019 to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:8050  15:16:26,782  INFO main mapreduce.Job - The url to track the job: http://http://ilabphd08.isus.emc.com:8088/proxy/application_1429280992648_0019/  15:16:26,783  INFO main mapreduce.Job - Running job: job_1429280992648_0019    The logs on the Hadoop side are:    Showing 4096 bytes. Click here for full log  mumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:04,026 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:05,033 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:06,042 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:07,049 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:08,056 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:09,062 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:10,069 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:41,093 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:42,100 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:43,107 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:44,113 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:45,120 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:46,129 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:47,136 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:48,143 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:49,150 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)  2015-05-04 15:36:50,156 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)    Even though  the maxRetries is set to 10 the process is going into several sets of retrials.     ",5,3.7317238
XD-3026,Support specifying the default values for the module at the module config,"As a spring developer, I can specify the default value for the module configs at the module config xml file and if no specific overriding options given the default value should get preferred.  Currently, I see that by design we want to rely on the default option values from the ModuleOption metadata. But, the cases where some module configurations can't have the default (say, customerKey for twitterstream module) and would be tempting to just try deploying after changing the twitterstream.xml with the default value expecting it to work.",3,2.179415
XD-3027,Update Spring Integration / Spring AMQP Versions,4.1.4 and 1.4.5 respectively.,1,2.3833716
XD-3028,5 occurrences of the typo 'properites' in comments/readme/doc,The typo 'properites' should be replaced with the correct 'properties' in the following places:  https://github.com/spring-projects/spring-xd/search?utf8=%E2%9C%93&q=properites,1,2.3723474
XD-3029,SqoopRunner class not found errror ,"We have installed the SpringXD 1.2 M1 release via the rpm and it seems that the sqoop-1.4.5-hadoop200.jar file are not part of the rpm. The sqoop jar file are not in the xd/lib directory.    This is causing a problem during customer module development if we include the sqoop-1.4.5-hadoop200 dependency as part of the pom file and forces us to redeploy the our jar as separate deployment.    Should we be referencing different dependencies or have or should the sqoop-1.4.5-hadoop200.jar be part of the rpm definition so it part of the xd/lib?    I have currently the following dependency in the pom file:    {code}  		<!-- Sqoop -->  		<dependency>  			<groupId>org.apache.sqoop</groupId>  			<artifactId>sqoop</artifactId>  			<version>1.4.5</version>  			<classifier>hadoop200</classifier>  		</dependency>  {code}    It would be great be great if the sqoop jar are part of rpm so we don't have to do any additional jar deployment.    Thanks, ",2,3.8062773
XD-3030,RabbitMQ queues not being removed on stream destroy,"As part of p-spring-xd testing we create, deploy, exercise, undeploy and destroy a RabbitMQ to RabbitMQ stream every minute. Spring XD does not appear to be deleting the queues it creates internally for each stream. We have seen as many as ~9800 xdbus queues (via the RabbitMQ web ui) before RabbitMQ runs out of memory and blocks.",5,2.2007365
XD-3031,Document the RabbitMQ Bus Cleanup REST API,,1,3.6227484
XD-3032,ModuleConfigurationException should not report HTTP 500,"See discussion at https://github.com/spring-projects/spring-xd/pull/1537#issuecomment-99583179  This is likely a client error, so should be in the 4xx family. This requires customization of RestControllerAdvice",2,2.787115
XD-3033,Upgrade to Spring Data Fowler Release,"Spring Data Gemfire is version 8.0.0 in Folwer, which is the same as in BDS (Should check minor version number in BDS).  ATM we are using gemfire 7.0.x",3,2.085011
XD-3034,Sqoop command should not require jdbc parameters,"Based on the OOTB sqoop.xml definition on GitHub we are required to provide the jdbc.url, jdbc.username and jdbc.password as a parameter definition.   {code} 	<bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet""> 		<property name=""arguments""> 			<list> 				<value>${command}</value> 				<value>${args}</value> 				<value>jdbc.url=${url}</value> 				<value>jdbc.username=${username}</value> 				<value>jdbc.password=${password}</value> 				<value>fs.defaultFS=${fsUri}</value> 				... {code}  This is causing a problem if we define the the sqoop connection parameters within the args list. We are using the --password-file option in the args list and need to specify the connection info via the --connect  option with the --username within the args list.   Our Job definition is:  {code} job create bdl_lookup --definition ""bdl-load --command=import --args='--connect=jdbc:oracle:thin:@<hostName>:1821/<dbName> --username=<user> --password-file=/user/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/<targetFolder/lookup_d -m 1' "" {code}  This results to an deployment:  {code} 2015-05-07 11:40:51,586 1.2.0.M1  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'bdl_lookup': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'sqoopTasklet' defined in class path resource [config/bdl-load.xml]: Could not resolve placeholder 'url' in string value ""jdbc.url=${url}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'url' in string value ""jdbc.url=${url}"" {code}  If we skip the jdbc connection info from the module.xml file, similar to:  {code} 	<bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet""> 		<property name=""arguments""> 			<list> 				<value>${command}</value> 				<value>${args}</value> 				<!-- Comment out jdbc info 				<value>jdbc.url=${url}</value> 				<value>jdbc.username=${username}</value> 				<value>jdbc.password=${password}</value> 				--> 				<value>fs.defaultFS=${fsUri}</value> 				... {code}  Custom module deploys fine but get a We get a NullPointerException in the container logs:  {code} 2015-05-07 11:46:04,450 1.2.0.M1 ERROR inbound.job:bdl_lookup-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step sqoopTask in job bdl_lookup java.lang.NullPointerException   org.springframework.xd.sqoop.SqoopTasklet.createCommand(SqoopTasklet.java:91)   org.springframework.batch.step.tasklet.x.AbstractProcessBuilderTasklet.execute(AbstractProcessBuilderTasklet.java:107)   org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:406)   org.springframework.batch.core.step.tasklet.TaskletStep$ChunkTransactionCallback.doInTransaction(TaskletStep.java:330)   org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:133)   org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271)   org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77) {code}",2,4.6321945
XD-3035,Kafka source module: Handling delete offsets,"When the *stream* that holds the kafka source module is undeployed(but not destroyed yet), the underlying offset manager deletes the offsets associated with the steam.  When same stream is re-deployed, the offset manager reads the offsets from kafka broker (if initial offsets are *not* provided) for each partition the module is configured to listen.  If the initial offset values are provided for the stream, then I think the offset manager should delete the offsets from the XD offset topic only when the stream is *destroyed*. Since we want to re-use the offset topic data upon stream undeploy/re-deploy.  ",5,2.5066936
XD-3036,Fix section headers in reference TOC,See:  http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26    There should be chapter/section title before this.,1,2.3464885
XD-3037,Create documentation for kafka source multiple topic support,"As a user, I want to have a documentation that shows how to configure multiple topics with Kafka source module.",1,3.7069373
XD-3038,Add value-expression to gauges,See http://stackoverflow.com/questions/30112430/payload-filters-transforms-rich-gauges/30115234 for the use case. It should be possible to extract both a numeric value and a gauge name from the message.,3,2.6418097
XD-3040,Create Boot based ModuleRunner (Phase III),"As a user, I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without _xd-containers_.    Scope:  * ",5,2.952255
XD-3041,Disable MongoDB boot autoconfiguration at XD runtime,"XD runtime (admin, container and singlenode) have MongoDB boot autoconfiguration enabled. This spins off MongoDB client and thereby the cleaner thread running on all these runtime.    The MongoDB based modules won't have any impact when we disable this autoconfiguration.   ",1,3.6683276
XD-3042,Upgrade to Reactor 2.0.1,,5,1.6067868
XD-3043,Document GF specific configuration properties,"As a user, I'd like to use the GF source along with native GF authentication enabled, so I can consume data from GF in a secured way. I'd like to refer to documentation on where the GF specific native and security properties needs configured.     See this [SC post|https://gopivotal-com.socialcast.com/messages/24377202] for more details.",1,2.578266
XD-3044,Add jdbcgpfdist batch job,"As a user, I'd like to have an OOTB _jdbcgpfdist_ batch job, so I can read from JDBC and write to HAWQ/GPDB using _gpfdist_ protocol.   The scope is to reuse the existing gpfdist sink code and adapt it to fit the batch model (_gpfdist_ writer).   ",8,3.5186357
XD-3045,Separate mocks and real repository responsibilities from test coverage,"As a developer, I'd like to separate mocks vs. real repository coupling from the test infrastructure, so it is easy to test against thin layer of dependencies.",8,2.3379724
XD-3046,Fix compilation errors after moving SingleNodeApplication package,Samples including Singlenode tests need to update for package changes,2,2.5787477
XD-3047,Complete Camera Ready DEBS submission,Complete and submit DEBS 2015 paper as described here:    http://www.debs2015.org/camera-ready-instructions.html,5,2.3721635
XD-3048,RabbitMQ queue cleanup uses wildcard unexpectedly,"Calling the API to delete queues uses a wildcard-like behaviour unexpectedly. If I request to delete:    {{test-1}}    I expect it to delete streams named with the pattern:    {{test-1.*}}    For example, it would delete:    {{test-1.0, test-1.1, etc}}    In fact I believe it wildcards before and after the period, e.g.:    {{test-1*.*}}    And hence would delete:    {{test-1.0, test-11.0, test-123.0, etc}}    That way of working is potentially helpful, but it's also dangerous because it removes the ability to know that you're only deleting the exact queue you want to in all cases.    For the record the commit (https://github.com/spring-projects/spring-xd/commit/2d5f3f706330a6ead8e91c9a7a23d4372715614d) implies that it should work in the more restricted way above, not the less restricted way.    (Note: I've marked this as an improvement because, absent documentation, I don't know what the correct functionality is and hence can't say this is a bug)",1,3.0942907
XD-3049,Profile byte array on In-Memory and Kafka Transport,Identify and report hotspots while running the load-generator source and the throughput sink on :  # Singlenode -> In Memory Transport  # Singlenode -> Kafka Transport  # Admin/Container -> Kafka Transport,3,3.7713227
XD-3050,Move Reactor based processor module from spring-xd-modules to core,"As a developer, I'd like to move the project reactor based [data processor module|https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor] from _spring-xd-module_ repo to the core, so I can natively use Reactor's Stream API to build processor modules. ",3,1.8908368
XD-3051,Gradle launch task is broken,Spring XD has a gradle task available in the build called launch that starts a single node instance.  This is currently broken.  The command I was using for this command was:  {code}  $ ./gradlew clean build -x test -x javadoc launch  {code},1,2.6086345
XD-3052,Move gpfdist sink from spring-xd-modules repo to the core,"As a developer, I'd like to move the project reactor based [gpfdist|https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist] from spring-xd-module repo to the core, so I can natively use this sink to write to GPDB/HAWQ.  ",2,1.8340831
XD-3053,Module configuration exception should not block admin leader election,"When the admin leader is elected, the leader recalculates the deployed stream/job states. If for some reason the stream/job couldn't be loaded with ModuleConfigurationException, then the leader fails and subsequently all the deployment requests are being queued.  We need to discuss how to handle this situation. A possible fix could be something like this: https://github.com/ilayaperumalg/spring-xd/commit/fa6a48072197e8c350eaebe841191e4b6310f437  The issue is that, if the stream was already successfully deployed into a container, then the stream status would still be set to 'undeployed' by the admin leader during the recalculation.  Also, this issue is very minor as the ModuleConfigException would be thrown only if someone upgrades Admin that uses different module options config than the existing stream definitions.",3,2.5121815
XD-3054,Deployment validation when processing the deployment message,"Currently, the deployment message is being validated before pushed the ZK distributed queue for deployment. When the message is consumed, there is no validation done. Since, the consumer consumes the messages asynchronously, we need validation at both sides.",1,3.1117523
XD-3055,Investigate failing tests in CI,Failure example: https://build.spring.io/browse/XD-MASTER-2152,3,2.5790396
XD-3056,Add a new source module to capture video frame from camera or video files,"This is a source module for video ingestion: the modules captures video frames from a camera or from a video file. For camera, the frames are grabbed from the rtsp video stream. This module will generate message with the frame image (encoded with JPEG) as the payload.   ",8,3.594338
XD-3057,Using Github repo for XD module registry,"As a devops, I would prefer having my module registry located in centralized github repository. This would allow all the admins and containers in the cluster pointing to the same module registry. Any new module upload would be pushed to the same github repo which will make the cluster always be in sync on the Module Registry.",5,3.8987057
XD-3058,Windows CI FTP based tests fail.  ,"Currently Windows EC2 (master, JDK8) test is failing  I've attempted to replicate on my EC2 environment.  The best bet is to try and reproduce using the AMI and machine size that CI uses.  We need to check with Trevor to get this info.  The error is: {noformat} java.lang.AssertionError: java.lang.AssertionError java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)   org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)   org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)   org.springframework.xd.shell.command.FtpModulesTests.testRefOptionEqualsFalse(FtpModulesTests.java:70)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {noformat}",3,3.2836986
XD-3059,DSL parser that reads both stream and job definitions from multi line definitions,"The story XD-2993 addresses the DSL parser to read the multi line stream definitions. We need to support adding multi line parser support for with the mixture of both stream/job definitions.  As a developer, I would setup job definition and have a stream definition that triggers the job in the same multi line content. ",3,2.904641
XD-3060,Provide more informative error message when ConversionService fails in Tuple,"When delegating to the conversion service, the ConversionFailedException does not have the context of which key caused the failure. Should probably wrap ConversionFailedException with IllegalArgumentException and add that context back in.",2,2.2780821
XD-3061,Remove id/timestamp from tuple and related methods on tuplebuilder,"As a developer, I'd like to remove _ID_ and _TimeStamp_ attributes from the {{Tuple}} class, so I can improve performance characteristics by not having them go through _serde_; instead, we could leverage message headers to collect such information.   ",3,2.486971
XD-3063,Add Property maxMessagesPerPoll to All Polled Sources,"Polled message sources return only one message per poll by default.    When polling, say, a file directory with many files, files will be emitted once per {{fixedDelay}}.    As a user I need to configure a limit for the number of messages that will be emitted per poll.",3,2.0959485
XD-3064,HdfsMongoDB Job failing due because of missing ID in Default Tuple,"Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577  Deployment: single admin, 2 container deployment using +RabbitMQ+ as the transport.  Below is a partial stacktrace (please check log for full stacktrace).  Log is attached.  {noformat)  2015-05-15 10:50:15,843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3  org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!          at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)          at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)          at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)          at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)          at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)          at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)          at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)          at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)          at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)          at java.lang.reflect.Method.invoke(Method.java:606)  {noformat)",3,1.9375852
XD-3065,"Provide an option ""--delete=true"" on the File Source","Provide an option ""--delete=true"" on the File Source  If the file reading is not *ref*, an option *--delete=true* will remove the file once it was read.  ",3,3.0539515
XD-3066,Make Enum Conversions for ModuleOptions more lenient,"If you have a an option *--mode=textLine*, presently the enum MUST be named *textLine*.  I think it would improve the user-experience if we allowed users to pass in values such as:  * --mode=textLine * --mode=text_line * --mode=TEXT_LINE  ",3,3.0430942
XD-3067,Spark streaming integration module fails to initialize codec,XD Spark streaming module fails to load:    Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.springframework.xd.tuple.serializer.kryo.TupleCodec] for bean with name 'org.springframework.xd.tuple.serializer.kryo.TupleCodec#2e8f5f36' defined in class path resource [META-INF/spring-xd/bus/codec.xml]: problem with class file or dependent class; nested exception is java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec    org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1331)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:453)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 67 more  Caused by: java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodec    java.lang.ClassLoader.defineClass1(Native Method)    java.lang.ClassLoader.defineClass(ClassLoader.java:760)    java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)    java.net.URLClassLoader.defineClass(URLClassLoader.java:455)    java.net.URLClassLoader.access$100(URLClassLoader.java:73)    java.net.URLClassLoader$1.run(URLClassLoader.java:367)    java.net.URLClassLoader$1.run(URLClassLoader.java:361)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:360)    java.lang.ClassLoader.loadClass(ClassLoader.java:424)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:357)    org.springframework.util.ClassUtils.forName(ClassUtils.java:249)    org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:395)    org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1349)    org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1320),3,2.9544916
XD-3068,Provide configuration option to specify the default output channel for router sink,"As a user, I would like to specify the default output channel when the channel name resolution doesn't occur. In cases where I won't prefer to lose the data and like to investigate the messages from errorChannel or that sort.",2,3.5407598
XD-3069,Investigate classloading leakage,"Using the gemfire module as an example, there is currently at least two sources of leakage, retaining classes that are loaded by the module classloader (and hence everything from there).  One of them is because of JMX monitoring.  Another one I'm not sure about, but here is a screenshot",8,4.6010327
XD-3070,Spike: introduce xolpoc-admin to XD Admin,"The POC for XD on Lattice uses the following interface for module deployment:    https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java    {code}  public interface ModuleDeployer {    	void deploy(ModuleDescriptor descriptor);    	void undeploy(ModuleDescriptor descriptor);    	ModuleStatus getStatus(ModuleDescriptor descriptor);    }  {code}    This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to:  * Demo a POC showing simple stream deployment with the existing shell/admin to Lattice  * Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).    Note that this work will not necessarily be merged into XD itself, although some of the concepts may be included in a future PR.",5,2.8780255
XD-3071,Spike: Produce Rabbit baseline on rackspace infrastructure,"As a developer, I'd like to bench Rabbit on rackspace infrastructure, so I can have a sense on how it scales as we add more _xd-container_ nodes.",8,3.271733
XD-3072,Flo parser improvements,"As a Flo developer, I'd like to add improvements to existing Flo parser endpoints, so I can streamline the error reporting strategy.",3,4.30198
XD-3073,LocalMessageBus Will Only Run 10 Jobs by Default,"The {{LocalMessageBus}} uses the Integration Scheduler to run batch jobs  Launching batch jobs with the {{LocalMessageBus}} uses the Integration default {{taskScheduler}} which only has 10 threads by default.  Use the {{LocalMessageBus.executor}} instead to free up the scheduler threads.  However, we need to consider whether a separate configuration is needed to limit the number of batch jobs - it's possible the existing bus executor configuration is enough.",3,2.1673725
XD-3074,Backport metadata retrieval stability improvements,Backport stability improvements added as part of XD-2958 to the 1.1.x branch.,1,4.095805
XD-3075,Backport Kafka Sink input fix,"As part of XD-2958, we've changed the input type of the Kafka sink from String to byte[]. The main reason for the change was that it required an arbitrary and often unneeded (but expensive) conversion to String for the bus payloads.     Apply the same change to 1.1 branch.",1,3.303966
XD-3076,Add SSL properties to the Mail source,"As a user, I'd like to use the _Mail_ source to connect to secured IMAP and/or SMTP mail servers.     _Mail_ source config file requires a <util:properties/> bean (with ssl/tls properties), provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}     <beans:beans profile=""default"">          <util:properties id=""javaMailProperties"">              <beans:prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</beans:prop>              <beans:prop key=""mail.imap.socketFactory.fallback"">false</beans:prop>              <beans:prop key=""mail.store.protocol"">imaps</beans:prop>              <beans:prop key=""mail.debug"">false</beans:prop>          </util:properties>      </beans:beans>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",1,1.4615865
XD-3077,Default HDFS as custom module registry for YARN deployments,"As a developer, I'd like to default to HDFS as distributed remote location for custom module registry, so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.",3,3.3833966
XD-3078,Spring XD admin fails to redeploy modules after Spring XD container successfully reconnectes to Zookeeper,"We are running Spring XD 1.1.1 in our production environment and Zookeeper 3.4.5.  Zookeeper is running in failover mode and consists of three independent nodes set up on three separate VMs. From time to time we get ""Connection to Zookeeper Suspended"" event which causes one of the containers in the cluster to be removed from the SpringXD cluster. Modules being deployed on this removed node fail to be re-deployed to other containers in the cluster.    Affected versions:  - SpringXD 1.1.1  - Zookeeper 3.4.5 and 3.4.6    Cluster set up in PROD environment where error occurs:  - 4 Spring-XD dedicated servers  - 4 spring-xd containers (each running on designated server )  - 2 spring-xd admins ( each running alongside one spring-xd container)  - 3 Zookeeper nodes ( 3 designated servers on PAITO environment )    Cluster set up in TEST environment where error also occurred:  - 2 Spring-XD dedicated servers running one spring-xd container and one spring-xd admin each  - 3 Zookeeper nodes running on 3 dedicated servers (PAITO Test environment)    Cluster set up to reproduce error found in PROD environment:  - 1 spring-xd admin  - 3 spring xd-containers (each running on a designated VM )  - 3 zookeeper servers running on one VM    Steps to reproduce:    1)	Set up three node Zookeeper cluster. Attached is example zoo.cfg, we are using default configuration values. In this particular test case we run all Zookeeper nodes on a single VM as we were not testing network layer interruptions.  2)	Set up one Spring XD admin node. Please note that we have also observed this on two node Spring XD admin cluster.   3)	Set up three Spring XD container nodes. All of them belong to one group (SA) and two of them also belong to second group (HA1). This is configured in $XD_HOME/config/servers.yml however so far group configuration never influenced test outcome.  4)	Create and deploy a test stream using following XD Shell commands:  stream create --name test-zookeeper-failover --definition ""syslog-udp --port=5140 | transform | file --dir='/opt/pivotal/spring-xd/xd/output'""  stream deploy --name test-zookeeper-failover --properties ""module.syslog-udp.criteria=groups.contains('HA1'),module.syslog-udp.count=2,module.file.criteria=groups.contains('SA'),module.file.count=3,module.transform.criteria=groups.contains('SA')""  5)	Ensure that test stream works and handles traffic on UDP port 5140  6)	Shutdown one of the Zookeeper nodes by issuing a stop command.  7)	Two Spring XD containers were not affected and remained in Spring XD cluster.  8)	One Spring XD container was kicked out of Spring XD cluster and was no longer visible on Spring XD admin Web UI. Modules previously deployed to this container were not redeployed to other cluster members.  9)	On the failed Spring XD container we have observed CONNECTION_SUSPEND, CONNECTION_RECONECTED and CHILD_REMOVE Zookeeper events (attached is container-log.txt). Please note that Java process is still running and we see “ConnectionStateManager-0 server.ContainerRegistrar - Waiting for supervisor to clean up prior deployments�? messages.  10)	Spring XD admin failed with exception in DepartingContainerModuleRedeployer (attached is admin-log.txt).   11)	We have observed that departing container node in Zookeeper (/sa/deployments/modules/allocated/1d3fd4cc-5a70-47ed-b4f3-22deef1f4d4f/) had no children. We did this after few minutes so we are not sure at which point it was cleared.   12)	Restarting failed Spring XD container fixed the problem, modules were correctly redeployed.  Exception from point 10 is very similar to XD-1983 and this code was rewritten in XD-2004.  ",8,2.2165463
XD-3079,Create a new Kerberos ticket instead of renew the current one,"Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7.  The kerberos ticket policies are:  * expiration: 24 hours  * renew: 7 days    I need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS, but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.    Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?    The Spring XD server has configured the hadoop.properties like:    # Use servers.yml to change URI for namenode  # You can add additional properties in this file  dfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COM  yarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COM    yarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*,/opt/cloudera/parcels/CDH/lib/hadoop/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*,/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*,/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*,/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*    hadoop.security.authorization=true  hadoop.security.authentication=kerberos    spring.hadoop.userKeytab=file:///export/home/user/user.keytab  spring.hadoop.userPrincipal=user@ERS.COMPANY.COM    #Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D)  spring.hadoop.security.authMethod=kerberos  spring.hadoop.security.userKeytab=/export/home/user/user.keytab  spring.hadoop.security.userPrincipal=user@ERS.COMPANY.COM  spring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COM  spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM",5,3.3413072
XD-3080,Add support for cluster rebalancing,When deploying streams to clustered Spring XD modules are deployed to all avilable Spring XD containers (assuming no additional deployment properties are specificed). Each container gets similar number of modules.   When Spring XD container departs from the cluster all departing modules will be migrated to remaining containers. After container rejoins the cluster the modules are not redeployed to it and the cluster looks unbalanced and the node is not used.  !unbalanced-cluster.png!,5,3.210388
XD-3081,When using file as a source and sink user can not use file sink --mode,"Cluster Type: SingleNode  Machine: Mac  PR: https://github.com/spring-projects/spring-xd/pull/1624,https://github.com/spring-projects/spring-xd/pull/1626  Stream that reproduces the problem:  {noformat}  stream create foo --definition ""filein: file --dir=/tmp/xd/a0180520-c7fa-4d9d-8cc3-e36fbf59496a --pattern=de59d1b8-f99c-4c43-a8c0-2f6043546689.out --mode=contents | fileout: file --binary=true --mode=replace ""  {noformat}  Error Message:  {noformat}  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module file of type sink:      mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found  {noformat}  Stacktrace:  {noformat}  2015-05-19 14:30:56,329 1.2.0.SNAP ERROR qtp671416633-35 rest.RestControllerAdvice - Caught exception while handling a request  org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module file of type sink:      mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found    org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)    org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:191)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)    org.springframework.xd.dirt.stream.AbstractDeployer.validateBeforeSave(AbstractDeployer.java:115)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:260)    sun.reflect.GeneratedMethodAccessor191.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:776)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)    org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)    javax.servlet.http.HttpServlet.service(HttpServlet.java:755)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)    javax.servlet.http.HttpServlet.service(HttpServlet.java:848)    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)    org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)    org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)    org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)    org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)    org.eclipse.jetty.server.Server.handle(Server.java:370)    org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)    org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)    org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)    org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)    org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)    org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)    org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)    org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)    org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors  Field error in object 'target' on field 'mode': rejected value [replace]; codes [typeMismatch.target.mode,typeMismatch.mode,typeMismatch.org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.mode,mode]; arguments []; default message [mode]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found]    org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)    org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)    org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)    org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:168)    org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:188)  	... 61 more  {noformat}",3,2.1509264
XD-3082,UI: Add Analytics Tab,,3,3.1395097
XD-3083,Creating multiple Stream/Job definitions from command file is broken,"I have a file that has the DSLs:  stream create a1 --definition ""http | log""  stream deploy a1    xd-shell --cmdfile test.cmd  May 19, 2015 1:49:29 PM org.springframework.shell.core.AbstractShell handleExecutionResult  INFO: Created new stream 'a1'  May 19, 2015 1:49:29 PM org.springframework.shell.core.SimpleExecutionStrategy invoke  SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is no stream definition named 'a1'",3,2.907018
XD-3085,Improve implementation of null sink,The null sink uses a bridge and in perf testing it seemed to introduce overhead.  Verify with throughput source and a hand-crafted 'no-op' MessageProcessor impl.,1,3.9920948
XD-3086,Fix random Spark streaming test failures,The {{testTapSparkProcessor}} has the test that checks the contents at the output of spark streaming word count processor. It turns out that the order in which these messages are processed are not always in order.,1,3.3218145
XD-3087,Unable to fully destroy hung batch job,"I created and launched a 'jdbchdfs' job. Due to network issues the job hung. Wasn't able to cancel it so I ended up destroying it.  After that I couldn't recreate the job since XD insisted hat there already was a job with that same name.   {code} xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false"" Successfully created job 'jdbc1' xd:>job deploy jdbc1 --properties ""module.jdbchdfs.count=3"" Deployed job 'jdbc1' xd:>job launch jdbc1 Successfully submitted launch request for job 'jdbc1'  (Here the job was hung)  xd:>job destroy jdbc1 Destroyed job 'jdbc1' xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists  xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists  xd:>job destroy jdbc1 Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is no job definition named 'jdbc1'  xd:>job create jdbc1 --definition ""jdbchdfs --columns=ID,FILE_PATH,FILE_NAME,YEAR,FILE_LENGHT,LAST_MODIFIED --tableName=SOMEFILES --checkColumn=ID --partitionColumn=ID --partitions=3 --partitionResultsTimeout=3000000 --rollover=128000000 --commitInterval=1000 --url=jdbc:oracle:thin:@//redwood:1521/XE --driverClassName=oracle.jdbc.OracleDriver --username=spring --password=spring --testOnBorrow=false"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name jdbc1 already exists {code}",3,2.9503796
XD-3089,Add incremental load feature to batch docs,The incremental load introduced with XD-2309 should be added to the batch docs,1,3.1624165
XD-3090,JdbcHdfsTests sporadically fail,Acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged XD-2309.    Additional tests were added but used fixed timeouts.  Will replace them with waitForJob.     ,2,2.6079693
XD-3091,Update build to use SHDP 2.2.0.RC1,,1,0.48321596
XD-3092,Synchronous deployment/undeployments,"There are a range of issues (such as XD-3083, XD-2671) that are caused by asynchronous deployments issued by the REST API. The flow of events is:  * deploy/undeploy request received by REST API  * controller queues up request to be processed by supervisor  * controller returns HTTP 2xx    This proposal is to have the thread executing the deploy/undeploy request block until the request has been processed by the supervisor. This will have the side effect of deploys appearing to take longer, but when the HTTP request completes, the deployment/undeployment will have been fulfilled. ",2,3.2554004
XD-3093,Sqoop list-tables doesn't work oob,"Commands from docs:    xd:>job create sqoopListTables --definition ""sqoop --command=list-tables"" --deploy  xd:>job launch --name sqoopListTables    2015-05-21 19:12:36,211 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop job for 'list-tables' finished with exit code: 1  2015-05-21 19:12:36,212 1.2.0.M1 ERROR task-scheduler-1 sqoop.SqoopTasklet - Sqoop err: Error: Required argument --connect is missing.    Adding --connect results    xd:>job create sqoopListTables --definition ""sqoop --command=list-tables --connect=jdbc:hsqldb:hsql://localhost:9101/xdjob"" --deploy  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module sqoop of type job:      connect: option named 'connect' is not supported      This is with singlenode.",1,2.762478
XD-3094,SparkApp batch job is not running,"From the latest master, I couldn't run sparkApp as batch job. The spark application process gets launched and it doesn't complete and there are no errors at the output.",2,3.191333
XD-3095,Update to Reactor 2.0.2,,1,1.1628263
XD-3096,Support for BroadcasterMessageHandler to work with concurrent producing threads,Also provide better lifecycle (shutdown) mgmt of handler.,3,3.4800127
XD-3097,Provide defaults for xd-shell,As a user I'd like to have shell to automatically configure itself against an environment I have setup.  This really came up with ambari work where shell can be anywhere in a cluster. Best I was able to do for now is to build an init file for commands(ambari xd-shell deploy already knows locations/addresses for xd admin and namenode): {code} $ cat /etc/springxd/conf/xd-shell.init  admin config server http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 {code}  and then run those after starting xd-shell: {code} server-unknown:>script --file /etc/springxd/conf/xd-shell.init admin config server http://ambari-2.localdomain:9393 Successfully targeted http://ambari-2.localdomain:9393 hadoop config fs --namenode hdfs://ambari-2.localdomain:8020 Script required 0.662 seconds to execute xd:> {code} ,1,1.8190308
XD-3098,Message Bus optimizations (Kafka + Redis),,5,2.6181245
XD-3099,Spike: Support graceful shutdown of modules in a stream,"As a user, I'd like to have the option to gracefully shutdown the stream, so when it is _undeployed_ while in the middle of its operation, we would want to complete its journey to the sink before XD stops the stream.    *Use case:*  One of the streams has a custom module that performs archive extraction. When this stream is ‘undeployed’ while in the middle of extraction, It looks like the message goes to the DLQ. However we would like the message to complete its journey to the sink of the queue before xd stops the stream. Is this possible?",8,3.3576066
XD-3100,module.*.count > 1 duplicates messages on taps,"Using module.name.count > 1 when deploying taps causes duplication of messages in those modules. This impacts balancing of the containers and modules in a cluster as messages should not be duplicated across modules if the same module is deployed twice to two containers in order to spread the load.  We use taps quite heavily in our project mainly for analytics of the life feed in real time but due to issue we have discovered and described in this bug we are currently facing a limitation where heavily processing modules can not be load balanced across the cluster as they are causing duplication of the messages and therefore the same module deployed to two  containers would still process the same message twice.  To demonstrate the problem please see test case scenario set up below:  h4. 1. Environment  - Spring-XD version 1.1.1-RELEASE - Running two spring-xd containers and one spring-xd admin  h4. 2. Set up  Stream definition is as follows:   {quote}stream create --name test-module-count --definition ""syslog-udp --port=5140 | transform | log"" stream deploy --name test-module-count --properties ""module.*.count=2"" stream create --name tap-test-module-count --definition ""tap:stream:test-module-count.syslog-udp > transform --expression='payload.toString() + \""TAPPED\""' | log"" stream deploy --name tap-test-module-count --properties ""module.*.count=2""{quote}   Please refer to the screen shots attached to see that after deploying those two streams we have:  - streams successfully deployed ( module-count-spring-xd-streams.png ) - streams successfully deployed with count=2 to both containers ( module-count-spring-xd-containers.png )  - 5 queues created in Rabbit ( module-count-rabbit.png ) where two were created for the syslog-udp collector as a result of using module.syslog-udp.count=2 - this is causing messages to be duplicated. Normally the expectation would be to have only one queue for the tap  h4. 3. Test input data  I have sent a very simple UDP message to the listening udp collector running on second container:   {quote}echo test-module-count >> /dev/udp/host02/5140{quote}  h4. 4. Test output data in the logs ( module-count-container01.log and module-count-container02.log )  h5. Expected result:  Below messages logged only on 1 container (it does not matter which one) {quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count}{quote} Below message logged only on one container (it does not matter which one)  {quote}2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  h5. Actual result:  Stream that has been create as a tap has duplicated the same message and as a result the same message was proccessed twice on both containers by the same module ( transformer ) and logged twice to the console on both containers  Container01: {quote}2015-05-26 14:52:21,143 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}  Container02: {quote}2015-05-26 09:52:21,630 1.1.1.RELEASE  INFO xdbus.test-module-count.1-1 sink.test-module-count - {UNDECODED=test-module-count } 2015-05-26 09:52:21,843 1.1.1.RELEASE  INFO xdbus.tap-test-module-count.0-1 sink.tap-test-module-count - {UNDECODED=test-module-count }TAPPED{quote}   ",5,1.8552308
XD-3101,Fix Gradle “dist�? build task,,1,3.0616488
XD-3102,Benchmark XD RC1 using Kafka 0.8.2 as transport,"As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Sinks to be included in test:  In-Memory Transport > Hdfs sink  Direct Binding Transport > Hdfs Sink  Kafka > Hdfs Sink",8,2.759194
XD-3103,Adapt to XD Reactor processor fixes and improvements,"As a developer, I'd like to upgrade to 2.0.3 release of Reactor, so I can inherit the latest optimizations to further improve XD performance characteristics. ",3,3.8288367
XD-3104,Update to Reactor 2.0.3 ,,1,1.7098058
XD-3105,Turn-off JMX by default,"As a developer, I'd like to have JMX turned-off by default, so I can take advantage of the performance throughput benefits. ",1,2.0654192
XD-3106,Support XD_JMX_ENABLED configuration,XD-EC2 needs  to allow user to set the XD_JMX_ENABLED flag in the environment prior to admin or container  startups. ,2,2.6256986
XD-3107,Fix gradle build issues,"As a XD build master, I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues, so I can evaluate that publish builds works as expected. ",3,1.7331846
XD-3108,Module failed to deploy because ZK said it already exists.,"Identified in a stream of commits ending with:0f4d4ea6b2f16c73c0048e32d8a8753aa25a48fd  Transport: Redis  Admin: 1   Container: 1   Stream deployed: time|file  Attachments: Admin and container logs.  [Description]  Admin reports that File sink Module failed to deploy at 00:19:32 because ZK stated it already exists.  Container shows no deployment of the file sink.  **** This could be an artifact in that the old Acceptance tests use the same stream name, hence a previous undeploy failed to remove the file.  This is not seen in the log per se'.  The filejdbc fail above is a legitimate test verifying that a job can't be deployed twice.    ",3,3.2634385
XD-3109,SFTP socket closed error. Infinite loop,"Having the follow messages poping up on xd log. It seems they are being generated indefinitely.     Log files getting huge.     [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsa,ssh-dss  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctr,aes192-ctr,aes128-ctr,arcfour256  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512,hmac-sha2-256,hmac-sha1,hmac-ripemd160  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: none,zlib@openssh.com  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:  [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1,diffie-hellman-group-exchange-sha1  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsa,ssh-dss  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctr,aes128-cbc,3des-ctr,3des-cbc,blowfish-cbc  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5,hmac-sha1,hmac-sha2-256,hmac-sha1-96,hmac-md5-96  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server->client aes128-ctr hmac-sha1 none  [2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client->server aes128-ctr hmac-sha1 none  [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent  [2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent  [2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received  [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent  [2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received  [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-mic,publickey,keyboard-interactive,password  [2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic  [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickey,keyboard-interactive,password  [2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey  [2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey).  [2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22  [2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception, leaving main loop due to Socket closed",2,2.8669784
XD-3110,Clean-up compiler and javadoc warnings from the build,"As a developer, I'd like to clean-up compiler and javadoc warnings from the build, so we don't see  the warnings in build sysout.",2,1.8194149
XD-3111,Upgrade to 1.2.0 RC1 SIK release,,1,1.9464103
XD-3112,Hide the passwords used as module properties in streams from being displayed.,This type is used in password field in the jdbc sink module provided by Spring XD (defined in org.springframework.xd.jdbc.JdbcConnectionMixin class). It seems that Spring XD Admin UI is always displaying the password in plain text please see attached screen shot.  Is there a way to somehow hide the passwords used as module properties in streams from being displayed in Spring XD Admin UI?  This is similar issue as below and fixed in batch jobs but not in streams.  https://github.com/spring-projects/spring-xd/pull/1325,2,3.2602763
XD-3113,Review 'critical' sonar warning...,https://sonar.spring.io/drilldown/issues/org.springframework.xd:spring-xd?severity=CRITICAL,3,3.0564146
XD-3114,Ensure proper lifecycle shutdown of processors in BroadcasterMessageHandler and MultipleBroadcasterMessageHandler ,,2,2.2495506
XD-3115,Improve ReactorReflectionUtils.extractGeneric to support classes with inheritance,Provide unit tests,1,2.855544
XD-3116,Update redis.tar.gz bundled in distribution to be version 3.0.1,RPM scripts will need to change.,3,1.7305101
XD-3117,Add Logging to ZooKeeperContainerRepository,"Occasional CI test build failures:    {quote}  Caused by: java.lang.IllegalStateException: Container cache not initialized (likely as a result of a ZooKeeper connection error)    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.ensureCache(ZooKeeperContainerRepository.java:184)    org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findOne(ZooKeeperContainerRepository.java:263)  {quote}    e.g. https://build.spring.io/browse/XD-JDK8-JOB1-1514    Add logging to {{ensureCache()}} (e.g. in {{childEvent()}} ) and {{closeCache()}} to log that the cache was closed; it appears that's the only way the ""cache not initialized"" message can be emitted.",1,3.644165
XD-3118,Update RPM script to include number of containers to be started,"As a user, I'd like to start multiple instances of {{xd-container}}'s through the RPM scripts, so I can easily spin-up instances on the same node/vm.",2,1.3445528
XD-3119,The performance of the pipe [in singlenode],"Do as a developer, in the case of large data from the source to the sink will after multiple processors, I found that even if the processor does not do anything, message from the source to the sink of performance, with the number of processors, the message forwarding performance will decrease very much. For example:  spring xd run in  singlenode  After the tcp-client connects the socket service, receive very many text (a line of text messages)  stream definition: tcp-client |t1:transform |t2:transform |t3:transform |t4:transform |null   Message passing rate: 20000 per second Transform didn't do anything.  stream definition: tcp-client|null Message passing rate: 170000 per second  Message is a line of text, my business requires me to a second processing 300000 pieces of data.(About 100 MB/s in a machine )  Tell me how to solve the performance bottleneck. Can stream only have source and sink to get high performance?",1,2.305558
XD-3120,SFTP Source Requires PassPhrase with Private Key,Private keys do not require pass phrases; hence it's bogus for the source to require one.,1,2.9885144
XD-3121,"skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]","when use rabbit as source, always have the warn message: skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]  similar issure is https://jira.spring.io/browse/XD-2567,  but i have no use rabbit sink.",2,2.9899194
XD-3122,Refactor deployment interfaces/class hierarchy (continued),"Refactoring of the {{ResourceDeployer}} to split apart the concepts of repository and deployment. For reference see XD-2835, XD-2671, XD-2877 and XD-3070.",8,2.7944536
XD-3123,Prevent classloader leakage thru javabeans infrastructure,,1,3.4477723
XD-3124,`minPartitionCount` is ignored by the consumer,"`minPartitionCount` is ignored by the consumer, so downstream modules end up listening to fewer partitions",3,2.4225411
XD-3125,Fail fast on Kryo registration conflicts,"Currently kryo class registration is hard coded in spring-xd-codec. Users may register their own classes using an extension mechanism, but it is possible to conflict with internal XD class registration, e.g., Tuple. Exposing this using the same extension mechanism will make it more transparent. ",2,2.6703234
XD-3126,Support for registering custom Kryo Serializers,"This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement, however initial benchmarks show that custom serializers are about 10% more performant than Serializable.",3,2.6205568
XD-3127,Create a landing section for OOTB batch jobs,"As a user, I'd like to refer to OOTB batch jobs and the documentation, so I can jump to the right job section and review details. ",1,2.9117167
XD-3128,Misleading instruction when admin server not running on localhost:9393,"Starting teh shell without having admin running on localhost:9393 results in the following message:  {code} 1.2.0.RC1 | Admin Server Target: http://localhost:9393 ------------------------------------------------------------------------------- Error: Unable to contact XD Admin Server at 'http://localhost:9393'. Please execute 'admin config info' for more details. ------------------------------------------------------------------------------- {code}  Running {code}admin config info{code} gives a nasty stacktrace though, so these instructions are misleading and should be changed",3,2.3693533
XD-3130,Move Bus cleaner util method from BusUtils,"Since `Spark-streaming` uses `BusUtils`, we need to move the bus cleaner util method that builds rest template so that spark streaming doesn't depend on `httpClient`",1,2.8792007
XD-3131,Spark streaming plugin shouldn't need tap listener cache,"Since Spark streaming doesn't use ZK to keep track taps being created, we don't need the tap listener cache setup at the container startup.",1,3.2150438
XD-3132,Sqoop job doesn't run when deployed on YARN on Ambari deployed HDP,"Got this error when submitting Sqoop job:    {code}  2015-06-01 19:09:42,932 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(75)) - Sqoop command: import  2015-06-01 19:09:42,939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(76)) - Using args: [--table, XD_JOB_REGISTRY, --target-dir, /xd/sqoop2, -m=1]  2015-06-01 19:09:42,939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(77)) - Mapreduce home: /usr/hdp/2.2.4.2-2/hadoop-mapreduce  2015-06-01 19:09:42,977 WARN [main] conf.Configuration (Configuration.java:(646)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml, mapred-site.xml and hdfs-site.xml to override properties of core-default.xml, mapred-default.xml and hdfs-default.xml respectively  2015-06-01 19:09:42,984 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: fs.defaultFS=hdfs://hawaii:8020  2015-06-01 19:09:43,743 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.hostname=hawaii  2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.address=hawaii:8050  2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii  2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.framework.name=yarn  2015-06-01 19:09:43,758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.jobhistory.address=hawaii  2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii:8030  2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.classpath=$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar:/etc/hadoop/conf/secure  2015-06-01 19:09:43,760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.framework.path=/hdp/apps/2.2.4.2-2/mapreduce/mapreduce.tar.gz#mr-framework  2015-06-01 19:09:44,141 INFO [main] sqoop.Sqoop (Sqoop.java:(92)) - Running Sqoop version: 1.4.5  2015-06-01 19:09:44,691 INFO [main] manager.SqlManager (SqlManager.java:initOptionDefaults(98)) - Using default fetchSize of 1000  2015-06-01 19:09:44,691 INFO [main] tool.CodeGenTool (CodeGenTool.java:generateORM(92)) - Beginning code generation  2015-06-01 19:09:45,057 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=0  2015-06-01 19:09:45,074 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=0  2015-06-01 19:09:45,148 INFO [main] orm.CompilationManager (CompilationManager.java:findHadoopJars(94)) - HADOOP_MAPRED_HOME is /usr/hdp/2.2.4.2-2/hadoop-mapreduce  2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(184)) - It seems as though you are running sqoop with a JRE.  2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(185)) - Sqoop requires a JDK that can compile Java code.  2015-06-01 19:09:45,230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(186)) - Please install a JDK and set $JAVA_HOME to use it.  2015-06-01 19:09:45,232 ERROR [main] tool.ImportTool (ImportTool.java:run(609)) - Encountered IOException running import job: java.io.IOException: Could not start Java compiler.  at org.apache.sqoop.orm.CompilationManager.compile(CompilationManager.java:187)  at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:97)  at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:478)  at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:601)  at org.apache.sqoop.Sqoop.run(Sqoop.java:143)  at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)  at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)  at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)  at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:87)  {code}  ",3,3.1580856
XD-3133,Update YARN deployment classpath settings for HDP 2.2 and PHD 3.0,Need to update classpath settings for PHD 3.0 and HDP 2.2 ,1,2.0582392
XD-3134,Create a spark standalone cluster on CI to run spark streaming tests,We need to setup Spark standalone cluster on the CI environment so that the Spark streaming tests can be run on the standalone cluster along with the local mode (that we run now).,5,3.8824341
XD-3135,Spark streaming module includes logback jar when using dist zip,"When running spark streaming module on spark standalone cluster from XD distribution, I see the following error:    [Stage 3:=============================>                             (1 + 1) / 2]2015-06-02T10:05:53-0700 1.2.0.SNAP WARN task-result-getter-3 scheduler.TaskSetManager - Lost task 0.0 in stage 3.0 (TID 50, 192.168.2.8): java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/Users/igopinatha/workspace/git/ilayaperumalg/spark/assembly/target/scala-2.10/spark-assembly-1.2.1-hadoop2.2.0.jar). If you are using Weblogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml Object of class [org.slf4j.impl.Log4jLoggerFactory] must be an instance of class ch.qos.logback.classic.LoggerContext       at org.springframework.util.Assert.isInstanceOf(Assert.java:339)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:151)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLogger(LogbackLoggingSystem.java:143)       at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:89)       at org.springframework.boot.logging.LoggingApplicationListener.onApplicationStartedEvent(LoggingApplicationListener.java:152)       at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:139)       at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)       at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)       at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)       at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:54)       at org.springframework.boot.SpringApplication.run(SpringApplication.java:277)       at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)       at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusConfiguration.createApplicationContext(MessageBusConfiguration.java:82)       at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.start(MessageBusSender.java:105)       at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:58)       at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:53)  ",2,2.388851
XD-3136,Example hashtag-count MR job fails when running XD on YARN with PHD 3.0,"Running XD on YARN on PHD 3.0 Ambari install.    Uploading and submitting a custom job fails with the following:    {code}  2015-06-02 16:54:15,580 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1433273561345_0009_m_000000_0: Error: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found    org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)    org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)    org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:742)    org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)    org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)    java.security.AccessController.doPrivileged(Native Method)    javax.security.auth.Subject.doAs(Subject.java:415)    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)    org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)  Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found    org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)    org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)  	... 8 more  {code}    Same example jar works fine when submitted from XD cluster.",5,2.3279269
XD-3137,Upgrade to 3.1.1 of the Gradle Artifactory Plugin ,This addresses The plugin issue https://www.jfrog.com/jira/browse/GAP-172 to disable spring-xd/pom.xml,1,1.7132369
XD-3138,Better classloader strategy for XD admin/container,This is in reference to the investigation done as part of XD-2548,8,2.5177817
XD-3139,Document the new analytics tab features,"As a user, I'd like to refer to the analytics tab docs, so I can understand how to use various widgets from streaming pipeline.  ",2,1.977358
XD-3140,Create a landing page with links for all OOTB modules,"As a user, I'd like to have a landing page with higher-order links for sources, processors, sinks and jobs, so I can jump to right section from one place. ",1,4.3379726
XD-3141,Uploaded custom module requires restart to get in effect,"When a custom module is uploaded to module registry, though the module registry is updated with the changed module after deleting the existing one, the module changes aren't loaded when deployed.",5,2.7471068
XD-3142,Enable/Disable Boot and Integration MBeans when JMX is enabled/disabled,Spring Integration MBeans are enabled by default even though XD_JMX_ENABLED is set to false. We need to disable JMX on these MBeans as well as Spring Boot MBeans.,1,2.966458
XD-3143,Test coverage for RuntimeModuleDeploymentPropertiesProvider,There are more calculations done at the RuntimeModuleDeploymentPropertiesProvider implementations and would be good to have some tests to cover them.,3,2.9603682
XD-3144,Expose Retryable Exceptions in the RabbitMessageBus Retry Configuration,"As a developer, I would like to be able to configure which exceptions thrown by a module should be retryable within the {{RabbitMessageBus}}.  As usual, these should be configurable at the bus and/or stream deployment property level.  Also consider disabling retry for kryo deserialization problems. ----  We are running Spring XD with RabbitMQ transport and we'd like to have a way to stop retries in certain situations. In [Spring XD 1.2.0.RC1 docs|http://docs.spring.io/autorepo/docs/spring-xd/1.2.0.RC1/reference/html/], in chapter about RabbitMQ transport, in ""A Note About Retry"" section, it's written:  {quote}Message deliveries failing with a MessageConversionException (perhaps when using a custom converterClassName) are never retried; the assumption being that if a message could not be converted on the first attempt, subsequent attempts will also fail.{quote}  Following is unclear: # Are we speaking about {{org.springframework.messaging.converter.MessageConversionException}} or {{org.springframework.amqp.support.converter.MessageConversionException}}? Based on XD-1597 and AMQP-390 it's the latter. # Only {{org.springframework.messaging.converter.MessageConversionException}} is available for custom module developers. Attempting to throw {{org.springframework.amqp.support.converter.MessageConversionException}} which is provided by {{$XD_HOME/lib/messagebus/rabbit/spring-amqp-1.4.5.RELEASE.jar}} results in {{java.lang.ClassNotFoundException}} even after Spring XD is configured to use {{rabbit}} transport. # Throwing  {{org.springframework.messaging.converter.MessageConversionException}} from custom processor module written with Spring Integration's {{transformer}} or {{service-activator}} doesn't stop retries.",5,3.1604815
XD-3145,Update batch modules to be short lived,"h2. Narrative  As a developer, I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.    h2. Back story  While streams are never ending, batch jobs have a true lifecycle with a beginning and and end.  By having a job bootstrapped when it's not executing, it eats up precious resources.  For example, if I have a job that creates connections to a database via a connection pool, the job module will hold those connections from the moment it's deployed to the moment it's undeployed, even if the job isn't being executed.  A more efficient use of resources would be to have the job module provide just enough to receive the launch request and then bootstrap the job's context    h2.  Notes  https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",8,1.8200386
XD-3146,Strict flag for jdbchdfs,"h2. Narrative  As a developer, when using jdbchdfs's incremental imports, I need to be notified that something went wrong in a previous run of the jdbchdfs job so that I can take the appropriate actions based on the data previously imported.    h2.  Back story  As the incremental import currently works, if the job fails half way through, there is no check on the next run to see if the last run failed or not and how to address partially imported data.",2,4.201324
XD-3147,Composing Jobs via the DSL,"h2. Narrative  As a developer, I want to be able to construct jobs using a DSL similar to the current syntax for streams.    h2.  Back story  Streams currently provide a DSL for assembling modules into flows (streams) that consist of a source, n processors, and a sink.  While constructing the steps of jobs themselves would be difficult in this manor, creating flows of jobs (essentially a job that consists only of job steps) would be very useful.  It would allow a developer to create something like the following:    {code}  filejdbc | mycustomjob | jdbchdfs  {code}    This approach also allows the existing packaging/module registry/etc to work out of the box.  This gets us closer to what Oozie provides out of the box without the need to create custom jobs to do the orchestration.",8,3.2832603
XD-3148,Remove mr1 jar from cdh5 hadoop build,There is an hadoop-core-2.5.0-mr1-cdh5.3.3.jar in the lib/cdh5 directory - we need to remove that from the dist,3,1.4015927
XD-3149,Batch job filepollhdfs docs are outdated,"The stream definition example uses old style syntax, should be --mode=ref instead of --ref=true ",1,1.8323702
XD-3150,the 'filepollhdfs' job fails on second submission,"Definitions:    >job create pollHdfs --definition ""filepollhdfs --names=name,age"" --deploy true    >stream create csvStream --definition ""file --mode=ref --dir=/Users/trisberg/Test/files --pattern=*.csv > queue:job:pollHdfs"" --deploy    Here is the exception:    {code}  org.springframework.data.hadoop.store.StoreException: Error while flushing stream; nested exception is java.nio.channels.ClosedChannelException    org.springframework.xd.batch.item.hadoop.HdfsTextItemWriter.update(HdfsTextItemWriter.java:135)    org.springframework.batch.item.support.CompositeItemStream.update(CompositeItemStream.java:74)    org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy54.run(Unknown Source)    org.springframework.batch.integration.launch.JobLaunching  {code}",3,2.1863163
XD-3151,Update Modules - Build and Package sections,Some info is obsolete and add more content re. dependency management,1,2.1119614
XD-3152,Update to Spring Integration 4.1.5 ,"As a developer, I'd like to update to the 4.1.5 SI release, so I can pickup the latest improvements to message channels.",1,1.3367221
XD-3153,Update to Spring Integration Kafka 1.2.0 GA,"As a developer, I'd like to update to SI Kafka extension 1.2.0, so I can leverage the latest performance improvements.",1,0.03746994
XD-3154,Update to Spring Hadoop 2.2.0 GA ,"As a developer, I'd like to update to Spring Hadoop 2.2.0 GA release, so I can leverage the latest improvements. ",1,-0.071867354
XD-3156,Add tap notification (Step/Chunk events) support for Java DSL based Batch job creation,"As a developer I would like to create DSL based jobs using Spring XD.   Currently BatchJobRegistryBeanPostProcessor implementation has an assumption in postProcessAfterInitialization( ) method (line 92). It checks if the beans are instanceof StepParserStepFactoryBean which is XML based steps. Therefore any XD step listeners for tap events are not getting registered, effectively I'm not getting any Step events out of my DSL based jobs.  Apparently everything else is working alright for the Java DSL job. Java DSL jobs are far easier to write Test/Integration Tests with.  Please review issue type - I was not sure if this was a bug or improvement, i supposed it is an improvement. ",1,3.660489
XD-3157,"How to get in the module's container ID, and module id","As a developer, I in the new development of component (source/processor/sink), how to get the module id and container id  Because components need to generate log, log information must include the unique identifier   xd:>runtime modules ",1,2.760158
XD-3158,The ModuleOptions in ModuleMetadata should contain type information ,"When querying the *ModuleMetadataRepository*, the *ModuleOptions* in class *ModuleMetadata*  are currently only provided as *properties*. This is a problem in cases where I need to determine the type of the property.   For instance, security sensitive properties should not be exposed verbatim but rather be masked.   Right now it seems impossible (easily) to determine whether a property is e.g. of type:  *org.springframework.xd.module.options.types.Password*    ",5,2.736091
XD-3159,Better handle the lifecycle of module classloaders,"The various methods is ModuleUtils sometimes create module classloaders just for the sake of loading a single file. URLClassLoader are now closeable, which we should try to do, but not too early.  Some of the signatures in that class are problematic (esp the ones that return a Resource) because we don't know when the client will be done with that resource. So we can't close the underlying CL for them.  Investigate other approaches:  * callback style signatures (ie doWithClassLoader(cl) for certain cases)  * global CL caching mechanism per module type:name  (but then issues arise when module bytecode is changed, etc)",5,2.7883472
XD-3160,Reorganize OOTB module list in docs,"Sort alphabetically, nest ""Available modules"" section appropriately. Optionally, move to a whole different ""PART"" in reference doc",2,3.1607041
XD-3161,Add CI Acceptance Test for 1.2.x,Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x,3,2.4254508
XD-3162,Update Master Environment for 2.0 CI Acceptance Tests,,3,3.2269
XD-3163,Modify Acceptance tests to give a pause time for deployment different than default,Kafka deployments take nearly 4 times as long as other transports because of the creation of the topic an partitions.  Currently all test use the same wait time whether it is for waiting for connections or file writes.   So to get a CI build for kafka build would take a long period of time.  The goal of the Story is to allow deployments to have a different pause_time to give Kafka bus the extra time it needs but not affect the timeout for other stages of the tests.    ,3,2.574408
XD-3164,Kafka bus defaults configurable at producer/consumer level,"As a developer, I want to be able to override Kafka bus defaults for module consumers and producers, so that I can finely tune performance and behaviour.     Such properties should include  - autoCommitEnabled,queueSize,maxWait,fetchSize for consumers  - batchSize,batchTimeout for producers",3,2.6095264
XD-3165,Synchronize XD and XD + Ambari RPMs into a single repo,"As a PM, I'd like to have XD and XD + Ambari RPM scripts into a single public repo, so that users can go to a single location to use the respective build scripts.",3,2.7190893
XD-3166,Publish performance benchmarks,"As a developer, I'd like to publish performance benchmarks along with the infrastructure specifics, so the users can use it as a reference while setting up Spring XD cluster.  ",8,2.9106495
XD-3167,STS import using Gradle Plugin broken,"How to reproduce:  * Menu: File -> Import --> Gradle Project * Press Next * Select the Spring XD Root Folder * Press button *Build Model*   This fails with the following log output:  {code}  FAILURE: Build failed with an exception.  * Where: Script '/Users/hillert/dev/git/spring-xd/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle' line: 32  * What went wrong: A problem occurred evaluating script. > dependencies.properties (No such file or directory)  * Try: Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.  BUILD FAILED  Total time: 29.05 secs  {code}  If I comment out / remove in *spring-xd-starters/spring-xd-module-parent/publish-maven.gradle* the following lines, everything works:  {code} diff --git a/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle b/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle index 6dea47f..202f884 100644 --- a/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle +++ b/spring-xd-starters/spring-xd-module-parent/publish-maven.gradle @@ -28,10 +28,6 @@ def getAllDependentProjects(project) {   // load versions  def versions = new Properties() -def propertiesFile = new File('dependencies.properties') -propertiesFile.withInputStream { -       versions.load(it) -}   def customizePom = { {code}",2,2.960894
XD-3168,Type conversion should set Content-Type header,See http://stackoverflow.com/questions/30714828/spring-xd-http-client-processor-sends-text-plain-instead-of-application-json,2,2.969993
XD-3169,Spike: Explore options for batch modules to be short lived,"As a developer, I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.",8,2.3573487
XD-3170,Update Spark streaming documentation,As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.  The documentation also needs some more information on `Reliable` receiver.,1,1.1422526
XD-3171,Composed modules not working on YARN,"From https://github.com/spring-projects/spring-xd/issues/1704  I am trying to use composed modules when running on YARN.    In ZK, each child module definition of the composed module gets serialized as follows:  ``` {""@class"":""org.springframework.xd.module.SimpleModuleDefinition"",""name"":""transform"",""type"":""processor"",""location"":""file:/tmp/hadoop-hduser/nm-local-dir/usercache/hduser/appcache/application_1433789137218_0001/filecache/17/spring-xd-yarn-1.1.2.RELEASE.zip/modules/processor/transform/""} ```  When I try to use the composed module on YARN, it may be deployed to a different container where the ""location"" file path is not valid.  In this case I get the following exception:  ``` java.lang.IllegalArgumentException: File must exist   org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:67)   org.springframework.boot.loader.data.RandomAccessDataFile.<init>(RandomAccessDataFile.java:51)   org.springframework.boot.loader.jar.JarFile.<init>(JarFile.java:95)   org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:61)   org.springframework.boot.loader.archive.JarFileArchive.<init>(JarFileArchive.java:57)   org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:54)   org.springframework.xd.module.support.ModuleUtils.createModuleClassLoader(ModuleUtils.java:47)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:186)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)   org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveComposedModuleMetadata(DefaultModuleOptionsMetadataResolver.java:175)   org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:167)   org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174) ```  I think the issue may be related to the following line in ArchiveModuleRegistry:  ``` String filename = resource.getFile().getCanonicalFile().getName(); ```  ",5,4.045296
XD-3172,Provide a source option to enable the SOF/EOF markers when splitting a file into lines,Depends on INT-3727,2,2.138495
XD-3173,Improve User Experience on HTTP Shell Commands,"As a user I'd like to be able to understand the root cause of an error on the {{http}} shell command.  When an exception occurs on an {{http}} shell command, the user gets  {{""Failed to access http endpoint %s"", target}}  No information from the exception is conveyed to the user (nor is it logged by the admin).",1,2.7094495
XD-3174,UI: Analytics Tab - Ensure that graphs are responsive,"Even for relatively large resolutions, e.g. 1024px the graph breaks the browser window. We should ensure that the graphs work on smaller screens.",3,2.300999
XD-3175,Consider using the ConversionService to convert incoming message payload to Reactor based processor's input type.,"In  {noformat} BroadcasterMessageHandler.handleMessageInternal {noformat} , the call   {code:java} } else if (ClassUtils.isAssignable(inputType, message.getPayload().getClass())) {             //TODO handle type conversion of payload to input type if possible             ringBufferProcessor.onNext(message.getPayload()); {code}  could try to invoke a conversion service         ",3,3.2254095
XD-3176,Using HDFS for custom module home doesn't work with Kerberized Hadoop cluster,"I tried setting the xd.customModule.home property to point to a Kerberized Hadoop cluster with all usual security config settings provided. It failed with the following exception:    {code}  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1139) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.SpringApplication.run(SpringApplication.java:320) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]    org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  	... 22 common frames omitted  Caused by: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]    java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]    org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2755) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2724) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:870) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:859) ~[hadoop-hdfs-2.6.0.jar:na]    org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817) ~[hadoop-common-2.6.0.jar:na]    org.springframework.xd.dirt.module.ExtendedResource$HdfsExtendedResource.mkdirs(ExtendedResource.java:127) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]    org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]    org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:79) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]  	... 25 common frames omitted  Caused by: org.apache.hadoop.ipc.RemoteException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS]    org.apache.hadoop.ipc.Client.call(Client.java:1468) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.ipc.Client.call(Client.java:1399) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.6.0.jar:na]    com.sun.proxy.$Proxy79.mkdirs(Unknown Source) ~[na:na]    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:539) ~[hadoop-hdfs-2.6.0.jar:na]    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) ~[hadoop-common-2.6.0.jar:na]    org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[hadoop-common-2.6.0.jar:na]    com.sun.proxy.$Proxy80.mkdirs(Unknown Source) ~[na:na]    org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2753) ~[hadoop-hdfs-2.6.0.jar:na]  	... 37 common frames omitted  2015-06-10T14:49:20-0400 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed  {code}",3,3.468058
XD-3177,Make RabbitMessageBus RabbitMQ Config Properties Optional,"When the bus is used outside of the XD container (e.g. spring-bus), the inheritance from Spring Boot configuration is broken (no application.yml or servers.yml on the cp).    Make the bus properties optional (Add "":"")",1,4.4015036
XD-3178,Hadoop Distro log message shows wrong version when set via env var,"If we export HADOOP_DISTRO env var instead of using --hadoopDistro parameter then the logging message is wrong, it always says    Hadoop Distro: hadoop26    even if we set HADOOP_DISTRO to something else    The classpath is built correctly. Maybe we should just remove this logging message since we log the actual version used in the next log message.  ",1,2.3706553
XD-3179,Remove ConnectionFactorySettings (after move to Boot 1.3),"Now that Boot (1.3) supports SSL (and other settings), we can remove the {{ConnectionFactorySettings}} {{@Configuration}}.",2,1.806488
XD-3180,"Spring xd, to configure the stream drag and graphic ",spring xd Can drag way to configure flow in the form of figure?  Similar to configure a workflow graphical interface   Looking forward to reply,1,2.6500163
XD-3181,XD Container not closing file descriptors,"Currently when running the {{p-spring-xd}} stream tests, we run into an issue where the XD Container starts throwing errors because it cannot open the module configuration file.  This happens reliably after 3-4 days of running and always fails on the same {{modules.yml}} configuration file.  This is not to say that the file leak is guaranteed to be related to the {{modules.yml}}, but it's certainly a place to start looking.  A restart of the container (only) causes the error to go away for 3-4 days at which point it reappears, indicating that the problem is definitely in the XD Container and not in the operating system's configuration.  Failure stack trace: {noformat} [XD ADMIN] 1.2.0.RC1 INFO DeploymentSupervisor-0 zk.ZKStreamDeploymentHandler - Deployment status for stream 'end-to-end-http-9630': DeploymentStatus{state=failed,error(s)=java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files)   at org.springframework.beans.factory.config.YamlProcessor.handleProcessError(YamlProcessor.java:186)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:178)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:138)   at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:100)   at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:57)   at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:381)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:369)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:339)   at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:174)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$1.apply(EnvironmentAwareModuleOptionsMetadataResolver.java:229)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.loadPropertySources(EnvironmentAwareModuleOptionsMetadataResolver.java:219)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.lookupEnvironment(EnvironmentAwareModuleOptionsMetadataResolver.java:181)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.access$000(EnvironmentAwareModuleOptionsMetadataResolver.java:61)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.<init>(EnvironmentAwareModuleOptionsMetadataResolver.java:144)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:132)   at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:206)   at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)   at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)   at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)   at org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:331)   at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)   at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   at java.lang.Thread.run(Thread.java:745)  Caused by: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files)   at java.io.FileInputStream.open0(Native Method)   at java.io.FileInputStream.open(FileInputStream.java:195)   at java.io.FileInputStream.<init>(FileInputStream.java:138)   at java.io.FileInputStream.<init>(FileInputStream.java:93)   at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)   at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)   at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:158)   ... 36 more  ; java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files)   at org.springframework.beans.factory.config.YamlProcessor.handleProcessError(YamlProcessor.java:186)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:178)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:138)   at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:100)   at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:57)   at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:381)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:369)   at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:339)   at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:174)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$1.apply(EnvironmentAwareModuleOptionsMetadataResolver.java:229)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.loadPropertySources(EnvironmentAwareModuleOptionsMetadataResolver.java:219)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.lookupEnvironment(EnvironmentAwareModuleOptionsMetadataResolver.java:181)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.access$000(EnvironmentAwareModuleOptionsMetadataResolver.java:61)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.<init>(EnvironmentAwareModuleOptionsMetadataResolver.java:144)   at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:132)   at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:206)   at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)   at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)   at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)   at org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:331)   at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)   at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)   at java.util.concurrent.FutureTask.run(FutureTask.java:266)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   at java.lang.Thread.run(Thread.java:745)  Caused by: java.io.FileNotFoundException: /var/vcap/jobs/xd-container/packages/spring-xd/config/modules/modules.yml (Too many open files)   at java.io.FileInputStream.open0(Native Method)   at java.io.FileInputStream.open(FileInputStream.java:195)   at java.io.FileInputStream.<init>(FileInputStream.java:138)   at java.io.FileInputStream.<init>(FileInputStream.java:93)   at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)   at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)   at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)   at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:158)   ... 36 more  } {noformat}",8,3.0752184
XD-3182,Fix minor bug with Gemfire sources,"https://github.com/spring-projects/spring-xd/blob/master/modules/common/gemfire-connection.groovy#L8 is syntactically incorrect. It looks like the intention was to pass this a property, but it appears it is treated as a literal value which Groovy coerces to true. Thus subscription-enabled is always true. It should be configurable  although some modules require subscription-enabled to be true. ",1,2.182529
XD-3183,Upgrade to Spring Boot 1.2.5,"Spring Boot 1.2.4 (and earlier) does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of (for example) {{vcap.services.rabbitmq.credentials.protocols.amqp.ssl}} it will fail, as that value returns a boolean.    Spring Boot 1.2.5 (as yet unreleased) contains a fix for this issue (https://github.com/spring-projects/spring-boot/pull/3237)",1,1.8145344
XD-3184,Update spring-xd-yarn servers.yml with settings for HDP 2.2.6.0,We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.,1,1.5055007
XD-3185,Create separate doc sections for reactor-ip's tcp and udp functionality,It isn't obvious from looking through the table of contents on the left hand side that reactor-ip does both tcp and udp.  Breaking up the section into two  would make it more clear - even though they would still use the same module.,1,3.1578877
XD-3186,DefaultModuleOptionsResolver to use parent classloader to load options metadata classes,There are cases where it would be required to load the options metadata classes from the parent classloader *first* than the module's ParentLastURLClassLoader. It would be nice to have a configuration option in DefaultModuleOptionsResolver to set which classloader to use.,1,2.3350365
XD-3187,XD admin leader should cleanup deployment after initializing the container path cache,The admin leader starts cleaning up the deployments for the container(s) that is/are no longer connected to the ZK. This clean up needs to happen after the container path cache is started by the admin leader. ,1,3.257918
XD-3188,FileDeletionListener resolves resources once,"In the {{filejdbc}} job, there is the option to delete the imported files.  This functionality is created using a listener called the {{FileDeletionStepExecutionListener}}.  When you run the job the first time with the {{--deleteFiles=true}}, everything works as expected.  The second time you run the job, the files are not deleted.    I believe the issue here is that since the {{FileDeletionStepExecutionListener}} is a singleton, the resources are resolved only once (the first time the job runs) and so it works the first time, but if the job is run again later and new files match the expression, they are not picked up.  I believe the fix is to make the {{FileDeletionStepExecutionListener}} used in this job step scoped.",1,2.3411613
XD-3189,Testers need ability to wait for a file to be created in XD directory,User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  ,3,2.6737328
XD-3190,No way to remove a job from Job repository if its gone from job definitions,"I am trying to deploy a job I destroyed after running a few times. I removed all the jobs using job all destroy. When i try to recreate the same name job it is saying it already exists. JobController.java save() method is throwing the exception if job exists in Job Repository database, but they are gone from job definition list. These jobs were originally created using XD Template REST client dynamically, but that should not make any difference.  This leaves me in an inconsistent state between XD definitions/job repository. How do I get rid of the job without having to log in to the database and play with the job repository tables.  I had to delete data folder for myself to continue development.   There should be a force mechanism to recreate a job with the same name, a flag that by passes this validation against the repository or overwrites the information in the repository.  ",1,3.0834205
XD-3192,Spike: Investigate Boot export metrics and the XD fit,"As a user, I'd like to have the module/app specific metrics consumed directly from Boot actuator [export()|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java] API, so I can have insight on how it is performing, being used and that it works etc.    ",8,3.2725291
XD-3193,Spike: Investigate bootification of module options,"As a developer, I'd like to handle module options via pure boot property source management, so I can leverage Boot's module [METADATA|http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core Spring XD runtime CP.  ",8,2.8173254
XD-3194,Spike: Investigate spring-cloud-config and the XD fit,"As a developer, I'd like to have a central place to manage external properties for applications across all the environments, so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers. ",8,2.8231688
XD-3195,Investigate Rabbit performance issues,"As a developer, I'd like to troubleshoot the performance issues with Rabbit as message bus implementation, so I can isolate the bottleneck and fix as appropriate.",8,2.6513593
XD-3196,Move MASTER branch CI builds to EC2 based infrastructure,"As a developer, I'd like to migrate the current MASTER branch CI builds to EC2 instances, so I can manage them all in one-place reliably.",8,2.7620902
XD-3197,Add support for Ambari installed Spring XD on YARN,"As a developer, I'd like to add an option to support Apache Ambari installed Spring XD on YARN, so I can easily establish the cluster up and running.",5,3.8443925
XD-3198,Spike: Investigate the use of config server for spring-cloud-stream modules ,"As a developer, I'd like to use spring-cloud-config server for spring-bus modules, so I can centrally manage external properties.",8,3.3280942
XD-3199,Split core dependencies between spring-bus and XD proper,"As a developer, I'd like to split up spring-xd dependencies to more fine-grained, so I can get the ones ""below the line"" down to spring-bus-* instead of spring-xd-* bundle. ",8,2.790786
XD-3200,Module delete command on windows does not delete the module entirely,"As a user, I'm trying to delete the custom module using the {{module delete}} command via shell; though the command is successfully, I'm still seeing the associated artifact (_.jar file_) present in the custom_modules folder. Refer to [SO thread|http://stackoverflow.com/questions/30984922/springxd-module-delete-command-does-not-delete-the-uploaded-jar-file] for more details.    ",5,2.158994
XD-3201,Documentation for reactor-ip source has conflicting information,"According to the documentation at: http://docs.spring.io/spring-xd/docs/current/reference/html/#reactor-ip one of the options available for this source is {{transport}}. It's listed as having no default, but the sample definition doesn't provide it yet appears to default to {{tcp}}. The two should match up.  It might also be useful if the possible values for {{transport}} were listed (I assume {{TCP}} and {{UDP}})",1,2.4899445
XD-3202,Investigate performance of channel metrics in SI 4.2 ,"As a developer, I'd like to investigate channel performance issues in SI 4.2, so I can determine the bottlenecks and take corrective actions to improve overall channel performance. ",8,2.3300087
XD-3203,Measure serialization baseline,"As a developer, I'd like to measure the baseline serialization characteristics in XD, so I can determine the areas of performance improvements. ",5,2.880786
XD-3204,Review spring-bus design specs,"As a spring-bus lead, I'd like to review the current spring-bus architecture and the design specs, so I can address any foundation level gaps.",5,2.7758799
XD-3205,Investigate the steps to Ambari upgrade Spring XD,"As a user, I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin, so I can work on the latest release bits. I'd like to refer to the documentation to do so.",1,4.2505913
XD-3206,An error message occurs about the shortDescription (header-enricher),"Here is an error I got using the header-enricher from spring-xd-modules :      {code:java}  Field error in object 'info' on field 'shortDescription': rejected value [A Header Enricher to set message headers in a stream]; codes [Pattern.info.shortDescription,Pattern.shortDescription,Pattern.java.lang.String,Pattern]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescription,shortDescription]; arguments []; default message [shortDescription],[Ljavax.validation.constraints.Pattern$Flag;@11eeec65,^\p{IsUppercase}.*\.$]; default message [Short description must start with a capital letter and end with a dot]  {code}    And if I look the config properties, indeed, short description doesn't end with a dot.  {code:java}  info.shortDescription = A Header Enricher to set message headers in a stream  {code}",1,2.1764455
XD-3207,spring-xd-extension-sqoop dependency overrides test logger setup,As per [Chapter 3: Logback configuration|http://logback.qos.ch/manual/configuration.html] only XML configuration can be overidden with {{-test}} file. It's impossible to do this with groovy configuration.  There are Spring XD modules that are packaging {{logback.groovy}} e.g. {{spring-xd-extension-sqoop}}. If a custom module depends on those libraries it becomes impossible to nicely override log settings for tests\[1\]. The configuration is taken from classpath because {{logback.groovy}} is always prioritized over {{logback-test.xml}}.  If those modules would switch to {{logback.xml}} there will be no such problem and custom modules would be easier to set up.  \[1\] One can put own {{logback.groovy}} file under {{src/test/resources}} but this setup will output a number of warning into console. Forcing logback configuration path with {{-D}} option is not nice either.,1,1.7621104
XD-3208,Change in file source breaks backward compatibility ,With version 1.2.0 the option ref of the file source was removed and a new option mode was introduced.  see XD-2850 and PR  https://github.com/spring-projects/spring-xd/pull/1624.  This means you have to destroy all streams using the ref option before you do an upgrade.  It would have been much better to leave the ref option in the code and emit a deprecation warning if it is still used. This way an upgrade would be possible without interruption.     ,1,2.4499567
XD-3209,ClasspathEnvironmentProvider should support packaged Spring XD modules,"Custom Spring XD modules are packaged into a JAR file with 3rd party libraries packaged into {{lib}} folder.  Let's say we have a {{my-job}} custom job module, packaged as JAR and deployed with {{module upload}} shell command. It wants to use {{org.springframework.xd.sqoop.SqoopTasklet}} provided by {{spring-xd-extension-sqoop}} library. Unfortunately {{org.springframework.batch.step.tasklet.x.ClasspathEnvironmentProvider}} will only add {{my-job.jar}} to {{SqoopRunner}} classpath (code in {{ClasspathEnvironmentProvider#createClassPath()}} method).  {{ClasspathEnvironmentProvider}} should add all 3rd party JARs packaged in custom job module to classpath.  This works with {{sqoop}} module shipped with Spring XD because it's deployed as ""exploded"" module under $XD_HOME/modules/job. In such case {{ClasspathEnvironmentProvider}} correctly adds all JARs from $XD_HOME/modules/job/sqoop/lib to classpath.",1,3.854683
XD-3210,Remove Usage of IntegrationEvaluationContextAware,This deprecated in SI 4.2.  Use   {{this.evaluationContext = ExpressionUtils.createStandardEvaluationContext(getBeanFactory());}}  in {{afterPropertiesSet()}} instead.  Not that this can safely be done in 1.2.x - the preferred mechanism is available in SI 4.1.x too.,1,1.9392531
XD-3211,HdfsTextItemWriter does not work with Hadoop LocalFileSystem fsUri:file://,"As a user I would like to use fsUri = file:// to use Hadoop LocalFileSystem instead of a running cluster. In my use case my data scientist team requested to provide me a local CSV of data that is being loaded using jdbchdfs job. The quickest way to solve this was to change the fsUri to file://. and it should have just worked.   This will work alright for singlenode setups, for multiple containers hosted on multiple machines will split the file across different machines - but then I believe it is fair to assume that the developer must know what he is doing.",1,2.579158
XD-3212,JSonStringToObject transformer used for GemFire JSON sink should accept a Map,"Should be renamed as well. org.springframework.integration.transformer.MessageTransformationException: ; nested exception is org.springframework.messaging.MessageHandlingException: ; nested exception is org.springframework.expression.spel.SpelEvaluationException: EL1004E:(pos 8): Method call: Method toObject(java.util.LinkedHashMap) cannot be found on org.springframework.integration.x.gemfire.JsonStringToObjectTransformer type   org.springframework.integration.transformer.MessageTransformingHandler.handleRequestMessage(MessageTransformingHandler.java:74) ~[spring-integration-core-4.1.5.RELEASE.jar:na]   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99) ~[spring-integration-core-4.1.5.RELEASE.jar:na]   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) ~[spring-integration-core-4.1.5.RELEASE.jar:na] (...) with 1.2 RELEASE when trying to persist a JSON payload using the GemFire-json-server sink.. It works  great on 1.1.RELEASE and 1.2 Build snapshot 2015-04-23.001857    The demo repository is open, so I can definitely share it with your developers, but wondered if we changed something recently on that sink that could cause an issue.",1,3.0263903
XD-3213,Use Deque instead of LinkedList when gathering metrics,"When profiling metrics we noticed a small improvement when using Deque instead of LinkedList in ExponentialMovingAverageRatio, ExponentialMovingAverageRate...  ",3,2.521477
XD-3214,Enabling security breaks Jobs page in Admin UI,"After enabling Spring XD security in {{XD_HOME/config/servers.yml}}:    {code}  spring:    profiles: admin  security:    basic:      enabled: true      realm: SpringXD  xd:    security:      authentication:        file:          enabled: true          users:            user: password, ROLE_VIEW            admin: password, ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN  {code}    after logging in as {{user}} with only {{ROLE_VIEW}} privilege, Jobs admin page is broken and is not displaying data. 403 error code is returned for following URLs:    {code}  http://localhost:9393/jobs/configurations.json?page=0&size=10  http://localhost:9393/jobs/definitions.json?page=0&size=10  {code}    Looks like {{/jobs/configurations.\*}} and {{/jobs/definitions.\*}} URLs are not covered in security section of applications.yml file.",2,3.6781576
XD-3215,Add a way to specify system properties for Sqoop job,"As a user, I'd like to have the option to specify system properties that will be passed in to the Sqoop job which runs in it's own Java process. This is needed for defining memory usage and also for defining some options for various connector implementations.",5,2.792028
XD-3216,"On specific shutdown scenarios, the stream resumes from the start of the bus topic",https://github.com/spring-projects/spring-xd/issues/1727,8,2.5277596
XD-3217,Cannot connect to admin server with basic security enabled,"As a user, I'm trying to connect to {{xd-admin}} server with basic security enabled; however, I'm unable to successfully connect to the server and I get the following error message.      {code:java}  server-unknown:>admin config server --uri http://localhost:9393 --username bob --password bobspwd  Unable to contact XD Admin Server at 'http://localhost:9393'.  {code}",5,2.321515
XD-3218,[Backport] Handle stream/job deployment status recalculation failures,"The admin leader election fails when the stream/job module definitions doesn't exist in `module-registry` but still some of the references still exist in ZK (via some of the previous deployments that had this module in module registry).     Though this is expected, this behavior will make *all* the subsequent deployments in *deploying* state because the admin leader isn't elected.    ",1,3.9047477
XD-3219,Fix random configuration in SecuredShellTests,"Since the SecuredShellTests initialize singlenode app in a static way, the random configuration needs to be setup statically as well.",1,1.8696451
XD-3220,Enabling security breaks job launching from Admin UI,"After enabling security (see XD-3214) and granting user {{ROLE_VIEW, ROLE_CREATE, ROLE_ADMIN}} privileges it's not possible to launch jobs from Admin UI.     For {{bdl-sqoop-combo-lukasz-MONGO-DEV}} job, 403 error is returned when Admin UI attempts to access following URL after ""Launch Job"" button is pressed:  {code}  http://ilabphd12.isus.emc.com:9393/jobs/executions?jobParameters=%7B%7D&jobname=bdl-sqoop-combo-lukasz-MONGO-DEV  {code}    Please see attached screenshot.",2,3.6896174
XD-3221,Enabling security breaks xd-shell,"After enabling security in {{XD_HOME/config/servers.yml}}  {code} spring:   profiles: admin security:   basic:     enabled: true # false to disable security settings (default)     realm: SpringXD   user: # valid only if security.basic.enabled=true     name: johndoe     password: johndoe     role: ADMIN, VIEW, CREATE {code}  It's no longer possible to connect to admin server through xd-shell  {code} server-unknown:>admin config server --username johndoe --password johndoe Unable to contact XD Admin Server at 'http://localhost:9393/'. server-unknown:>admin config info   -------------  --------------------------------------------------------------   Credentials    [username='johndoe, password=****']   Result         Unable to contact XD Admin Server at 'http://localhost:9393/'.   Target         http://localhost:9393/   Timezone used  Greenwich Mean Time (UTC 0:00)   -------------  -------------------------------------------------------------- ------------------------------------------------------------------------------- An exception ocurred during targeting: org.springframework.web.client.HttpClientErrorException: 403 Forbidden     at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:91)     at org.springframework.xd.rest.client.impl.VndErrorResponseErrorHandler.handleError(VndErrorResponseErrorHandler.java:50)     at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:614)     at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:570)     at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:545)     at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:253)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:114)     at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:102)     at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:112)     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)     at java.lang.reflect.Method.invoke(Method.java:606)     at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:202)     at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)     at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)     at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)     at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:533)     at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)     at java.lang.Thread.run(Thread.java:745) {code}  It looks like admin base URL (http://localhost:9393/) is not defined in security section of {{application.yml}} so {{SpringXDTemplate}} can't be initialized.",1,1.2598063
XD-3222,Find a way to connect Sqoop job to Teradata,"As a user I would like to connect the Sqoop batch job to Teradata for import jobs.     I have tried the Teradata JDBC driver directly using:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}    but that results in an NPE.    The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gz    That one allows me to use the following:    {code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""  {code}",3,2.0256858
XD-3223,Configure logging directory outside of xd.home,As a user I would like to be able to configure the logging directory to be outside of what is defined as xd.home. The logging directory is currently hard coded as {code}${xd.home}/logs{code}.    This would be useful for RPM installations where the logs really should be going to `/var/logs/spring-xd` instead of the current `/opt/pivotal/spring-xd/xd/logs` location.  ,3,2.1778982
XD-3224,Move message-bus implemenation from XD to spring-cloud-streams [Phase #1],"As a developer, I'd like to move message-bus from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency.   ",8,2.1801262
XD-3225,Move input/output type-conversion from XD to spring-cloud-stream,"As a developer, I'd like to move 'input/output type conversion' from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency. ",8,2.8365722
XD-3226,Move serialization codec from XD to spring-cloud-stream [Phase #1],"As a developer, I'd like to move 'serialization codec' from Spring XD repo into spring-bus, so I can update Spring XD to inherit the features/functionalities via maven dependency.",8,2.198864
XD-3227,Spike: Kickoff singlenode implementation of Admin SPI,"As a developer, I'd like to develop a “singlenode�? (in a single JVM) implementation of XD Admin SPI (based on Module Launcher), so I can run data pipeline use-cases locally.  ",8,3.7594233
XD-3228,Spike: Kickoff distributed Receptor implementation of Admin SPI,"As a Spring XD user, I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF Lattice/Diego.   ",8,3.7303905
XD-3229,Spike: XD Admin SPI to discover s-c-s modules,"As a s-c-s user, I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery, so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.",8,3.3345103
XD-3230,Update to Reactor 2.0.4,"As a developer, I'd like to upgrade to Reactor 2.0.4 release, so I could leverage the latest improvements and bug-fixes.",1,1.1639208
XD-3231,Add support to Ambari install multiple XD Admin's ,"As a developer, I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers, so it is setup for HA. ",5,3.6550283
XD-3232,Update Spring Integration to 4.2.0.M2 (4.1.6 on 1.2.x),"Also Spring Framework 4.2.0.RC2, Spring AMQP 1.5.0.M1    Also Batch 3.0.4",1,2.122643
XD-3233,Enable component model for spring-cloud-streams,"As a developer, I'd like to create an annotation ({{@EnableModule}}) driven programming model for modules, so instead of explicitly defining I/O channels as beans on the module, for classes annotated with {{@EnableModule}}, the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.    The {{@Input}} and {{@Output}} annotations will be used to indicate the input and output channels of the module. ",8,3.3448567
XD-3234,Remove XML REST Endpoints,The XML REST endpoints:  * are not working correctly * interfere with security * are not used   ,3,3.3275855
XD-3235,FileJdbc Job throws exception during Acceptance Tests ,Currently the testFileJdbcJobMultipleInvocations fails on line 156 stating data is different in table that what is expected.  Currently this is failing on the single admin/container deployment using redis as a transport.      Also seeing the following exception in the attached log:  {noformat}  2.0.0.SNAP ERROR xdbus.job:ec2Job3.0.requests-1 step.AbstractStep - Encountered an error executing step step1 in job ec2Job3  org.springframework.batch.item.ItemStreamException: Failed to initialize the reader  ...  Caused by: java.lang.IllegalStateException: Input resource must exist (reader is in 'strict' mode): URL [file:/tmp/xd/output/filejdbctest/filejdbctest1.out]  {noformat}  The file is should be present and data present for the test.  At least according to the checker on EC2 and local deployments.        ,3,3.8728805
XD-3237,Additional REST endpoint not working with security enabled,I see the following error from the Admin UI:  GET http://localhost:9393/jobs/executions/4/steps/4/progress.json 403 (Forbidden),1,2.965748
XD-3238,Complete remaining Kryo optimization changes,"As a developer, I'd like to complete the remaining Kryo optimization changes, so I can polish and get the guidelines documented appropriately. ",1,3.3853889
XD-3239,Move 1.2.x branch to EC2 CI infrastructure,"As a developer, I'd like to move 1.2.x branch to EC2 infrastructure, so I can reliably run CI test suites.",2,2.3829186
XD-3240,Add better support for using control file with gpfdist,Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.,2,2.640157
XD-3241,Add support for update in gpfdist sink,"Currently we can only do plain inserts, should follow same logic from native gpfdist sink and add upserts.",1,3.9133906
XD-3242,Copy spring-xd-codec to SCS as spring-cloud-streams-codec,Create the equivalent library in spring-cloud-streams,2,2.1980467
XD-3243,Remove spring-xd-codec from Spring XD source tree and build,replace with spring-cloud-streams (or spring-cloud-streams-codec) dependency,3,1.3558875
XD-3244,Copy spring-xd-messagebus-* to SCS as spring-cloud-binding-*,,2,2.0298362
XD-3245,Replace spring-xd-messagebus-* dependencies with SCS,XD 2.0 will not have direct dependency on the s-c-s Binder (as MB has been renamed).  The message bus code is obsolete/orphaned in XD 2.0 but some is required to support current integration tests. We can look at pruning it some more but complete removal likely depends on integrating the s-c-s enabled Admin SPI.  MB will remain in XD 1.x.,3,2.3009021
XD-3246,Automatic support for --fooExpression style options,"It would be nice if either one of the two options would come ""for free"" when you're authoring a module. Currently, it has been a pain, including handling exclusivity of options at the module options level.  Also, it would be nice if XD/S-C-S provided ease of creation of xxExpression style options (ie not having the author have to deal with ExpressionParser, etc)",6,2.9144905
XD-3247,Support transparent boxing/unboxing of Tuples (or other containers),"Working with rich structured messages is currently painful when we have modules that know how to handle some sub-part of the structure.  Case in point: I have a Tuple made of {document: byte[], metadata: Map} and I have a module that knows how to extract textual content from the document byte[].  If I want to extract the document but still retain metadata, I need to either - rewrite the extract content module to accept a tuple (urghh) - fork the stream to extract the document field, apply module, aggregate with metadata (that comes from side channel)  ",8,2.564012
XD-3248,Investigate inconsistent Spark streaming test failure,"These tests fail inconsistently:  org.springframework.xd.spark.streaming.LocalTransportSparkStreamingTests > testTapSparkProcessor FAILED    java.lang.AssertionError  org.springframework.xd.spark.streaming.RedisTransportSparkStreamingTests > testTapSparkProcessor FAILED    java.lang.AssertionError  java.lang.AssertionError:  Expected: an existing metric, trying at most 20 times     but: failed after 20*100=2000ms: counter named 'random5656' did not exist,",2,2.8168006
XD-3249,Change module option type from Class to String,"This better aligns with boot. Moreover, using Class was a bad design choice (one can always get a Class from a String [modulo knowing which CL to use], while to converse is not always easy [CL not being available])  ",3,1.5994154
XD-3250,Refactor s-c-s samples to use @ConfigurationProperties,"The spring-cloud-streams samples have module options classes copied over from XD.  They should use a pure @ConfigurationProperties approach, making sure metadata is generated/hand written as appropriate.    @Mixins are still referenced there but obviously can't work, so provide an equivalent",3,2.1667225
XD-3251,A a boot ConfigurationPropertiesModuleOptionsResolver,This allows incremental adoption of boot @ConfigurationProperties as a way of being recognized as XD options,2,2.2551353
XD-3252,Refactor XD to use boot's options metadata internally,"This is to get rid of (ultimately) ModuleOption, ModuleOptionsMetadataResolver etc in favor of classes written by Stéphane Nicoll (currently here: https://github.com/snicoll-scratches/spring-boot-config/blob/master/spring-boot-config-metadata/src/main/java/org/springframework/configurationmetadata/)",8,2.7402487
XD-3253,Strange language prefix shown on some code listings when hovering the mouse over them,"Looking at the online docs the code listings have inconsistent  syntax highlighting and when you hover the mouse over some of them there is a language  prefix like ruby or javascript inserted at the beginning of the first line. Very strange.  To see this go to http://docs.spring.io/spring-xd/docs/1.2.0.RELEASE/reference/html/#_server_configuration and scroll down to the HSQLDB section. The listing for HSQLDB looks fine, but scroll down further and put the mouse pointer on the MySQL or PostgreSQL listings and you should see 'javascript' being inserted on the first line. ",3,2.3142993
XD-3254,SCS-  Rename codec packages,,1,2.946505
XD-3255,SCS - split kryo implementation to spring-cloud-streams-codec-kryo,,1,2.190748
XD-3256,Spike: Investigate installation of XD modules from maven repo,"As a developer, I'd like to brainstorm and investigate various techniques around installation of XD modules from a maven repo, so I could define the module {{artifactId}} from CLI to have the module downloaded from the repo and installed to a running Spring XD runtime.",8,2.9425814
XD-3257,xd-shell doesn't work with SSL proxy,"After connecting to admin endpoint over HTTPS xd-shell will use plain HTTP for all further calls, which fails if HTTPS is mandatory:  {code} server-unknown:>admin config server https://my-host/ Successfully targeted https://my-host/ xd:>job list Command failed org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://my-host/jobs/definitions?size=10000&deployments=true"":Connection refused; nested exception is java.net.ConnectException: Connection refused {code}  In above example {{my-host}} is a proxy that provides load balancing and enforces HTTPS for users. It forwards the traffic to to spring-xd-admin service REST API over regular HTTP and port 9393. Admin service is returning {{_links}} with plain HTTP because it's unaware of the network proxy.  Can this be solved without employing server side HTTP->HTTPS url rewrite? Is enabling SSL in spring-xd-admin the only way?",2,3.5510974
XD-3258,Add jars for Avro and Snappy compression to Sqoop job submission,We need to have some jars as part of the Sqoop job submission to YARN:    for Avro we need:    avro-1.7.6.jar    avro-mapred-1.7.6.jar    for Snappy we need:    snappy-java-1.0.5.jar (note: the 1.1.0.1 version from xd/lib doesn't work)    commons-compress-1.4.1.jar    We can either have these included using the --libjars option or automatically include them.  ,3,2.3701227
XD-3259,[SCS] Rename xd.messagebus binder properties ,replace with xd.messagebus prefix with spring.cloud.stream.binder,3,2.5209806
XD-3260,Move serialization codec from XD to Spring Integration,"As a developer, I'd like to move 'serialization codec' from Spring XD repo into SI, so I can update Spring XD to inherit the features/functionalities via maven dependency.",2,3.6030228
XD-3261,Update Groovy to 2.4.4,There is a vulnerability in Groovy that is fixed in 2.4.4:    CVE-2015-3253: Remote execution of untrusted code    See:    http://groovy-lang.org/security.html    http://mail-archives.apache.org/mod_mbox/incubator-groovy-users/201507.mbox/%3CCADQzvmmYC7RbZnsQ8O63XN4HCMYh9RGRdMiuWupVt=u=pjH8+g@mail.gmail.com%3E      ,1,1.2766519
XD-3262,UI: Add Pagination to Containers Page ,Add Pagination to Containers Page,2,3.1719518
XD-3263,"Pagination for containers, it is limited to only 20","Hi ,    Customer has 48 containers, but it only shows 20 containers. We need pagination to browse all containers.",2,3.2153304
XD-3264,Spring Data BytecodeGeneratingEntityInstantiator throws ClassNotFoundException when mapping custom classes,"{{spring-data-commons}} 1.10.0.RELEASE introduced an improved instantiation strategy based on byte code generation. It's now the default instantiation strategy however it can't be used in custom Spring XD modules due to class loader issues.  Please see attached custom module source code which can be build with Maven. You might want to change MongoDB connection parameters in {{custom-mongo-processor.xml}}.  Execute following xd-shell commands  {code} module upload --name custom-mongo-processor --type processor --file [location] stream create --name k2 --definition 'time --fixedDelay=10 | custom-mongo-processor | log' --deploy {code}  The stream will output following message when the MongoDB collection is empty: {code} 2015-07-17T11:09:38+0100 1.2.0.RELEASE INFO task-scheduler-3 sink.k2 - {""content"":[],""count"":0} 2015-07-17T11:09:48+0100 1.2.0.RELEASE INFO task-scheduler-3 sink.k2 - {""content"":[],""count"":0} {code}  After documents are inserted into collection by executing {{db.karolWidgets.insert(\{ ""name"": ""bulbator"", ""color"": ""red"" \})}} following exception will be thrown:  {code} 2015-07-17T11:09:59+0100 1.2.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: ; nested exception is java.lang.IllegalStateException: Cannot process message   org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)   org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)   org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)   org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)   org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)   org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)   org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalStateException: Cannot process message   org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:292)   org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)   org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75) 	... 59 more Caused by: java.lang.NoClassDefFoundError: com/test/mongodb/MongoWidget   com.test.mongodb.MongoWidget_Instantiator_monxdt.newInstance(Unknown Source)   org.springframework.data.convert.BytecodeGeneratingEntityInstantiator$EntityInstantiatorAdapter.createInstance(BytecodeGeneratingEntityInstantiator.java:193)   org.springframework.data.convert.BytecodeGeneratingEntityInstantiator.createInstance(BytecodeGeneratingEntityInstantiator.java:76)   org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:250)   org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:231)   org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:191)   org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:187)   org.springframework.data.mongodb.core.convert.MappingMongoConverter.read(MappingMongoConverter.java:78)   org.springframework.data.mongodb.core.MongoTemplate$ReadDbObjectCallback.doWith(MongoTemplate.java:2191)   org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:1873)   org.springframework.data.mongodb.core.MongoTemplate.findAll(MongoTemplate.java:1286)   com.test.mongodb.MongoService.processWidgets(MongoService.java:21)   sun.reflect.GeneratedMethodAccessor83.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)   org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)   org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)   org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)   org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)   org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)   org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)   org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)   org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276) 	... 61 more Caused by: java.lang.ClassNotFoundException: com.test.mongodb.MongoWidget   java.lang.ClassLoader.findClass(ClassLoader.java:531)   java.lang.ClassLoader.loadClass(ClassLoader.java:425)   java.lang.ClassLoader.loadClass(ClassLoader.java:358) 	... 85 more {code}  This exception affects both custom stream and job modules. One workaround is to force {{ReflectionEntityInstantiator}} in {{MappingMongoConverter}} however this has to be done in every custom module.  Perhaps that's an issue with Spring XD custom module classloaders (or DATACMNS-710)?",3,2.4884
XD-3265,Spike: Investigate distributed implementation of CloudController Admin SPI,"As a Spring XD user, I'd like to use {{CloudController}} based implementation of XD Admin SPI (based on ModuleLauncher), so I can run data pipeline use-cases running on CF.    Relevant repos: [spring-cloud-data|https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers] | [spring-cloud-stream|https://github.com/spring-cloud/spring-cloud-stream]    Please refer to XD-3194 or XD-3229 as sample spike-deliverables (_google doc_) that were completed in the last sprint. ",8,3.7774506
XD-3266,No pagination for Jobs / Deployments page in Admin UI,After successfully deploying 12 jobs the Jobs / Deployments page still shows only 10 results.    It looks like {{http://localhost:9393/jobs/configurations.json?page=0&size=10}} always returns {{content.page.totalPages}} of 1 regardless of the {{size}} parameter.,2,3.4293978
XD-3267,Add support for Receptor SPI to query module status,"As a Spring XD on CF user, I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics.    *Possible APIs:*  {code}    ModuleStatus getStatus(ModuleDescriptor descriptor);    Collection<ModuleDescriptor> listModules();    Map<ModuleDescriptor.Key, ModuleStatus>    {code}",5,2.219107
XD-3268,Add support for CloudController SPI to query module status,"As a Spring XD on CF user, I'd like to use {{cloudController}} implementation of Admin SPI every time I deploy Spring XD modules, so I can leverage the SPI to query for module status and health metrics.  *Possible APIs:* {code}  ModuleStatus getStatus(ModuleDescriptor descriptor);  Collection<ModuleDescriptor> listModules();  Map<ModuleDescriptor.Key, ModuleStatus>  {code}",8,2.219107
XD-3269,Find a permanent home for SPI,"As a Spring XD developer, I'd like to have a permanent location of SPI implementations, so I could use the common repo every time I contribute or enhance the test coverage.  ",3,4.0734487
XD-3270,Create module registry abstraction,"As a Spring XD developer, I'd like to create initial version of the new module registry abstraction, so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.",5,3.8423853
XD-3271,Add automatic wiring of profile-driven SPI implementations,"As a Spring XD user, I'd like to make SPI implementation profile aware, so I can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.",3,2.1766171
XD-3273,Add support for modules to registry itself to Eureka,"As a s-c-s user, I'd like to have the modules self-register itself with {{Eureka}} whenever they're installed, so I can also discover the same modules using Spring XD Admin SPI and reuse them to create data pipelines. ",5,2.5199857
XD-3274,Make s-c-s modules searchable by it's name,"As a s-c-s user, I'd like to search the modules by it's name aside from the default {{spring.application.name}} offered by boot, so I can also fetch modules by it's name.",2,2.4790988
XD-3275,Add support to store metadata in Eureka,"As a s-c-s user, I'd like to store module metadata in {{Eureka}}, so I can use the repository to determine the current state.",2,2.4945376
XD-3276,Add state to Eureka when deploying s-c-s modules,"As a s-c-s user, I'd like to have my modules add/update it's current state to Eureka, so I can use the repository to discover the current sate of the module as needed.   ",2,3.6139824
XD-3277,Replace controller calls with respective SPI implementation,"As a Spring XD developer, I'd like to refactor current controller with SPI calls, so I can invoke the respective Admin SPI implementation based on the deployment.     *Controllers to Refactor*  * ContainersController  * StreamsController  * ModulesController  * JobsController  ",5,3.1380186
XD-3278,Add support to capture module (App) metrics directly,"As a Spring XD user, I'd like to capture module (aka: {{cf apps}}) metrics directly, so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently, there are two different ways we could consume this information from applications. SI's {{channel()}} and SBoot's {{actuator()}} APIs are the few to explore as part of this scope.",5,2.9137545
XD-3280,FilePollHdfsTest needs to write to a unique directory vs. the default,Occasionally 2 acceptance tests are running simultaneously and the filepollhdfs tests writes their data to the same hdfs directory.  This will cause the test to fail sporadically.  By creating a unique directory each time we can share the hadoop instance and not have a conflict.   ,3,1.7510798
XD-3281,Self-register xd-admin server with Eureka,"As a Spring XD developer, I'd like to self-register {{xd-admin}} server with {{Eureka}}, so I could have admin server exposed as discoverable endpoint. ",3,1.8437073
XD-3282,Create CI infrastructure for s-c-s,"As a s-c-s developer, I'd like to setup CI builds for s-c-s builds, so I can incrementally build and test code commits automatically.",3,3.5107436
XD-3283,Port FTP/SFTP as s-c-s source module,"As a Spring XD developer, I'd like to port {{FTP/SFTP}} modules from XD to s-c-s repo, so I can use them as {{source}} modules to build streaming pipeline.",2,2.2495153
XD-3284,Add support to persist captured module (App) metrics,"As a Spring XD user, I'd like to persist module (aka: {{cf apps}}) metrics directly, so I can relay that information via REST-APIs and not depend on the current coupling of {{xd-container}}'s.    Currently, SBoot's {{export()}} API allows us to snapshot metrics (default = {{redis}}) on a specific interval (default = {{5s}}). This could be something to explore as part of this scope.",5,2.9400263
XD-3287,Add HA support for NameNode when installed using Ambari,"As a user, I'm trying to setup HA cluster using Ambari installed Spring XD; however, I'm running into issues with the overrides. More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].",5,2.7829082
XD-3288,"Add CI workflow to build, bundle and upload module-launcher image to DockerHub","As a s-c-s developer, I'd like to setup a CI workflow to build, bundle and upload the {{module-launcher}} image to DockerHub, so I don't have to worry about having a local-private docker registry for development/testing.    It could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] DockerHub location. ",5,2.3094046
XD-3290,Add IPython notebook integration through Flo,"As a Spring XD user, I'd like to have [IPython Notebook|http://ipython.org/notebook.html] integration, so I can perform interactive data computations in real-time.",8,3.3116183
XD-3292,Add Azure Event Hubs integration,"As a Azure user, I'd like to read/write data from Azure Event Hubs. so I can leverage the pub-sub service to process and analyze large volumes of data.",8,4.194519
XD-3293,Spike: Investigate integration options with ipython,"As a Spring XD user, I'd like to have IPython Notebook integration, so I can perform interactive data computations in real-time.  ",8,3.0522478
XD-3294,RPM upgrades should not to wipe-out previous installation configs/settings,"As an operator, I'd like to upgrade to the latest releases of Spring XD and yet not lose the older installation {{dirs}}/{{files}}, so I can copy and reuse the previously used {{servers.yml}} configurations. ",5,3.534216
XD-3295,Spike: Determine options for configuring shared module dependencies,"h2. Narrative  As a developer, I'd like to be able to configure common dependencies for the entire environment.  An example could be that I use MySql for my databases.  I want to be able to configure the MySql driver once and have all modules use it.    h2. Back story  Spring Batch uses a database to store job state (the job repository).  This is a shared resource across all jobs (both custom developed and OOTB).  In order to support OOTB jobs, we'll need to have a way for users to provide the db driver to each module.  Ideally this would be possible without requiring that each of our OOTB modules be repackaged.  ",8,2.2607493
XD-3296,Spike: Design a tasks repository,"h2. Narrative  As a developer, I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.    h2. Back story  Currently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However, obtaining the result of said task can be an issue.  There are two ways to do so:    # Poll for the result.  # Register a callback URL to be called once the task completes.    Since a task is only available for a short time after its completion before it is deleted, polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.    Registering a callback URL would be a better option, however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  ""Successful"" is defined in this case as anything other than a 502 or a 503 return code.    In order for Spring XD to be able to support Diego tasks, a more durable option for maintaining the result of tasks will need to be developed.    *Note:* The outcome of this spike may be feature requests for the CF/Diego team.",8,2.4326677
XD-3297,Spike: Determine how to integrate job events into spring-cloud-streams,"h2. Narrative  As a developer, when running a batch job on Diego/Lattice as a task, I want to be able to receive events based on the job lifecycle.    h2. Back story  XD 1.x provides exposure to all of the main listeners Spring Batch supports via streams so they can be listened to.  This needs to be supported in the new spring-cloud-streams model.    *Note:* We may want this to depend on XD-2841?",8,3.511327
XD-3298,Create TaskLauncher,"h2. Narrative  As Spring XD, I will be able to launch Spring Boot jar files as Diego Tasks.    h2. Back story  The {{TaskLauncher}} will be responsible for listening for launch requests, looking up the definition in the {{TaskDescriptorRepository}}, and launching it.  The first implementation of this would be a Receptor based implementation.    *See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",8,3.5413048
XD-3299,Create a Receptor PartitionHandler and related StepExecutionRequestHandler,"h2. Narrative  As a developer, I need to be able to create a partitioned batch job that uses Diego Tasks for partition slaves.    h2. Back story  A new partition handler should be created that uses the Receptor API to launch tasks for each of the slaves (configurable via grid size).",5,4.3618407
XD-3300,Spike: Determine best way to centrally configure the job repository for batch jobs.,"h2. Narrative  As a developer, I need to be able to run batch jobs that use the centrally configured job repository to store job state.    h2. Back story  The XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.",5,3.5978606
XD-3301,Move config files in RPM install to /etc/spring-xd directory,We need better controll over how config files are preserved during upgrades. The RPM process handles that better for files that are designated as %config and they should reside outside of the directory where the software is installed so they can be kept around during version upgrades.,5,2.4297192
XD-3303,Update 1.3 installation instructions,"As a user, I'd like to refer to documentation while migrating to 1.3 release.",3,1.0177894
XD-3304,Exception during ModuleRedeployer causes additional modules to not deploy,"If an exception occurs during the deployment of a module within the ModuleRedeployer.redeployModule, the exception will cause the process to break out of the for loops in DepartingContainerModuleRedeployer and ContainerMatchingModuleRedeployer leaving other failed/undeployed modules still undeployed.  This is particularly bad for ContainerMatchingModuleRedeployer as a module with an issue deploying will be retried next time a container starts breaking all modules after it.",3,2.2296462
XD-3305,Spring XD Docker Hub site needs to have images for all XD versions,"Currently Admin & Container only support latest, 1.0.x and 1.1.0 while singlenode only has tags for 1.0.x and latest.    We need to have a tags for 1.1.0, 1.2.0, 1.2.1 for all XD Docker images.  ",5,3.2605357
XD-3307,Add support for offline module resolution,"h2.  Narrarive As a developer, I need to be able to test modules without pushing them to a remote maven repository.  I should be able to do {{$ mvn install}} in my module project locally (which will install the artifact into my local repository) and have it resolvable by spring-cloud-streams.",5,3.8858192
XD-3308,With Security - Unable to upload module,"Once security is enabled, one cannot upload modules using the shell any longer.",2,2.417772
XD-3309,Add direct binding option for s-c-s modules,"As a s-c-s user, I'd like to have the option to direct bind _modules_, so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases.     ",8,3.6502762
XD-3310,Add REST support for spring-cloud-data,"As a s-c-d developer, I'd like to establish the foundation to expose REST-APIs to interact with the {{xd-admin}} and likewise perform CRUD operations to maneuver streaming and batch pipelines. ",5,2.6291444
XD-3311,Create ModuleRegistry stubs,"As a s-c-d developer, I'd like to create {[ModuleRegistry}} stubs, so I can create mock streams by interacting with the registry APIs.",3,5.05189
XD-3312,Move spring-cloud-stream-modules to spring-cloud repo,"As a s-c-s developer, I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo, so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.",3,2.300361
XD-3313,Add in-memory stream definition repository,"As a spring-cloud-data developer, I'd like to use an in-memory stream definition repository, so I don't have to spin up a store; obviously, this will not persist between application executions, but it will be useful for a simplified development experience.  ",5,2.6703176
XD-3314,Validate stream commands from shell,"As a s-c-d developer, I'd like to invoke REST APIs via shell, so I can validate {{StreamController}} operations.",8,1.1527653
XD-3315,Port Redis counter as s-c-s sink,"As a s-c-s developer, I'd like to adapt redis {{counter}} from XD to s-c-s, so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards. ",3,3.370601
XD-3316,Create CI infrastructure for s-c-d repo,"As a s-c-d developer, I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data], so I can build the project continuously on every commits. ",5,3.2562926
XD-3317,Spike: Investigate right approach to support externals libraries,"As a s-c-s developer, I'd like to investigate the right approach to include external library as dependency (ex: MySQL), so I can decide better handling of libraries, which needs loaded and available in root CP at the runtime. ",8,2.0690382
XD-3318,Bootify ModuleLauncher,"As a s-c-s developer, I'd like to _bootify_ {{ModuleLauncher}}, so I can use Spring Boot's support for property, setting, as well as adding options and new functionality in the future, such as CP augmentation.  ",5,2.3711336
XD-3319,Add PHD HDFS as s-c-s module,"As a s-c-s developer, I'd like to investigate the right approach to port {{PHD}} as the provider to support {{HDFS}} module from XD, so I can decide better handling of HDFS dependencies, which needs loaded and available in root CP at the runtime. ",5,2.627013
XD-3320,Migrate StreamController from XD 1.0,"As a s-c-d user, I'd like to add REST support for stream commands, so I can maneuver streaming pipeline backed by StreamController.",5,1.9276952
XD-3321,Make requirement for MD5 hash files configurable for the custom module registry ,"Post 1.2 upgrade, the custom modules no longer show up by just copying the jars to the {{xd.customModule.home}} directory. Instead I have to use the 'module upload' command to install the modules. This is because an MD5 file is required. More details in [SO thread|http://stackoverflow.com/questions/31792220/spring-xd-1-2-0-custom-module-deployment]. ",3,3.6796343
XD-3322,Create CI infrastructure for s-c-s-m repo,"As a s-c-s developer, I'd like to setup CI infrastructure for {{spring-cloud-stream-modules}} (s-c-s-m) repo, so I can build the project continuously on every commits.  ",3,3.2650716
XD-3323,Test Spark Module with maven spring-xd-module-parent java.lang.NoClassDefFoundError,"A test for a java spark module managed by maven, with parent *spring-xd-module-parent* launch a _*java.lang.NoClassDefFoundError*_.  I've forked the example repo [https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor|https://github.com/morfeo8marc/spring-xd-samples/tree/master/spark-streaming-wordcount-java-processor] the samples project and created the *pom* file for the *spark-streaming-wordcount-java-processor* project and the corresponding test.  Partial stack trace:  {code:title=StackTrace} 2015-08-04 09:30:07,211 ERROR [DeploymentsPathChildrenCache-0] listen.ListenerContainer (ListenerContainer.java:run(96)) - Listener (org.springframework.xd.dirt.server.container.DeploymentListener@729c251b) threw an exception java.lang.NoClassDefFoundError: org/eclipse/jetty/util/component/AggregateLifeCycle   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   java.lang.ClassLoader.defineClass1(Native Method)   java.lang.ClassLoader.defineClass(ClassLoader.java:760)   java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)   java.net.URLClassLoader.defineClass(URLClassLoader.java:467)   java.net.URLClassLoader.access$100(URLClassLoader.java:73)   java.net.URLClassLoader$1.run(URLClassLoader.java:368)   java.net.URLClassLoader$1.run(URLClassLoader.java:362)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:361)   java.lang.ClassLoader.loadClass(ClassLoader.java:424)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)   java.lang.ClassLoader.loadClass(ClassLoader.java:357)   org.apache.spark.HttpServer.org$apache$spark$HttpServer$$doStart(HttpServer.scala:74) {code}  When the *WordCountTest* test is launched the exception is launched.  Is there a problem with the  *spring-xd-module-parent* module ? Are some dependencies left?",2,1.4818369
XD-3325,Add binding information to application definition,ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application's environment.,2,3.6508055
XD-3326,Add parameter information to application definition,"A ModuleDefinition contains parameters, which need to be passed to the CloudFoundry application. Currently these are put directly into the application's environment. This issue will verify they are correctly named.",1,3.6178682
XD-3327,Add Unit Tests for CC SPI infrastructure,"Test Converter, Configuration, Definition and Status objects.",3,3.7823467
XD-3328,Return full ModuleStatus information,Remove all stubs and check all required information is returned accurately.,2,2.7411258
XD-3329,Return full ModuleInstanceStatus information,Currently there is no ModuleInstanceStatus returned. This issue will fill in the details.,2,2.7411258
XD-3330,Implement undeploy operation for CC SPI,Currently undeploy is a no-op.,2,3.9549837
XD-3331,Add real ModuleRunner application,The current ModuleRunner is test app used for validation. This should be replaced by a real app.,2,3.956829
XD-3332,Obtain username and password credentials for CloudFoundry,As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.,2,2.8608174
XD-3333,Refactor CloudFoundryApplicationFactory,This class should not know what the test app is. This means changing the constructors on CloudFoundryApplication.,1,2.654435
XD-3334,Refactor to use RestOperations,"The current implementation makes use of cf-java-client, which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See https://github.com/Zteve/test-cc-oauth for sample code.",5,2.1480222
XD-3335,Kafka Source must set autoStartup=false on KafkaMessageDrivenChannelAdapter,"If the value is not set, the source may start before being bound to the bus, throwing a ""Dispatcher has no subscribers"" error",3,2.2082915
XD-3337,Spike: Investigate the inclusion of message bus binding libaries,"As a s-c-d developer, I'd like to investigate how to include/exclude msg bus/binding jars, so I can decide the binding selection and fallback mechanism when there is none setup.",5,2.5344257
XD-3338,Include multiple libraries via BOM template,"As a s-c-d developer, I'd like to add as many jars via a bom (e.g. hadoop distro deps), so I don't have to explicitly worry about individual but related libraries. ",2,2.814399
XD-3339,Dependency resolution support for modules with different versions,"As a s-c-d developer, I'd like to add support for dependency resolution, so when two or more modules use different version of jars (ex: direct binding of two modules that include different versions of spring data), I have the capability to resolve and include the right bits at runtime.",2,3.25926
XD-3341,Publish s-c-d image to DockerHub,"As a s-c-d developer, I'd like to publish the s-c-d image to DockerHub, so I can incrementally push the latest commits to the remote location.",1,1.9462838
XD-3343,Create a public screencast of 'firehose | counter',"As a s-c-s developer, I'd like to create a public screencast of {{firehose| counter}} pipe, so I can demonstrate s-c-s and the development experience.",3,2.7089188
XD-3344,Implement undeploy operation for singlenode SPI ,"As a s-c-d developer, I'd like to implement _undeploy_ operation for {{singlenode}} (single JVM), so I can use this target to undeploy a running stream. More details in [this PR|https://github.com/spring-cloud/spring-cloud-data/pull/19].    *Note:* Its a prerequisite to determine consistent _undeploy_ strategy for both {{jobs}} and {{streams}}. ",8,3.7030337
XD-3345,Job creation fails saying it exists (there isn't any job with that jobName),"Running Spring-XD in singlenode using Pivotal HD 2.1 as the Hadoop Distribution.   xd-singlenode --hadoopDistro phd21  I was testing  jdbchdfs job definitions. I am seeing this error that the job exists when in reality, there is no job with that jobName.   xd:>job create testEmployeeJobAgain1 --definition ""jdbchdfs --sql='select employee_id, employee_name, employer from EMPLOYEE' --url=jdbc:oracle:thin:@//localhost:1521/orcl --driverClassName=oracle.jdbc.OracleDriver  --username=springxd --password=xdpwd --testOnBorrow=false --directory=/usr/swatest1""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Batch Job with the name testEmployeeJobAgain1 already exists  xd:>job list   Job Name  Job Definition  Status   --------  --------------  ------",2,2.690918
XD-3346,Accessing step progress via REST fails with 403,"As a XD user, I'm trying to access URI (- GET /jobs/executions//steps//progress => hasRole('ROLE_VIEW')), but it fails with 403 forbidden error for the role with view access. More details [here|https://issuetracker.springsource.com/browse/VESC-475].    Another URL with the same error: http://<HOST>:9393/streams/definitions.json?page=0&size=10",1,3.2727249
XD-3347,Run all shell integration tests also with enabled security,Apply the same strategy for the Module Command Tests also to all other Shell integration tests.,5,2.4321802
XD-3348,Add profile support for stream repositories,"As a s-c-d developer, I'd like to add support for _profiles_ to the core {{Admin}} application, so I can back the stream repository with respective backend strategy. For example: {{local}} profile would use in-memory strategy to store the metadata.",3,3.3857803
XD-3349,Design the foundation to port XD modules to s-c-s,"As an s-c-s developer, I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules, so I can use it as the base and start migrating the modules.",5,2.7380378
XD-3350,Add support to expose counter metrics for dashboarding,"As a s-c-d developer, I'd like to add support to expose counter (metrics) endpoints, so I can consume to feed the dashboards to demonstrate {{firehose | counter}} pipe.",3,2.7070441
XD-3351,[SCS]- Replace codec impl in spring-cloud-stream-codec with SI-Codec,,2,3.3560846
XD-3352,[SCS] - Replace Binder XML config with @Configuration,Create Confguration and ConfigurationProperties. Configuration must support replacing the default Kryo Codec implementation with something else.,3,2.9145908
XD-3353,Add shell as a rest client to the spring-cloud-data REST API,As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.,5,3.2620893
XD-3354,Move shell integration tests to spring-cloud-data shell ,This could focus only on the subset (Stream operations),3,1.6335746
XD-3355,Add module metadata support using @ConfigurationProperties,"As a s-c-d developer, I'd like to collaborate with Boot engineering team and derive a strategy for module metadata via {{@ConfigurationProperties}}, so I can implement the functionality to support {{shell}}, {{autocompletion}}, {{flo}}, and {{ascii}} documentation in _spring-cloud-data_.     Eric's [gap analysis|https://docs.google.com/document/d/1A-9RpgSNL6SXD61q9eW2YRkrkn3tXk09rdkx7eCKlxY/edit#] document captures all the specifics in detail. ",8,2.8599973
XD-3357,MongoDB Batch Job Broken,"As a Spring XD user, I'm trying to use a custom MongoDB Batch job; however, I'm getting an error running it against 1.2.0/1.2.1 release, while the same works with older releases of Spring XD. More details in this [SO thread|http://stackoverflow.com/questions/31838720/mongodb-batch-job-broken-in-spring-xd-1-2-0].  ",3,3.1829555
XD-3358,Admin UI deploys job with wrong module count,When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1.    More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties],1,3.9085052
XD-3359,Standardize Spring Cloud Data configuration,"User can configure spring cloud data via  via Spring Cloud Config, data-admin.yml or Spring Cloud Connector * Add bootstrap.yml to spring cloud data * create a default data-admin.yml and configure spring data to look for this vs application.yml. * Spring Cloud Data will have Spring Cloud Config enabled by default ** User has the ability to disable it via the bootstrap.yml",5,2.644636
XD-3360,Add Spring Cloud Config to SPI Module Parent,Enable spring cloud config for all modules  * Add spring cloud config client to pom dependencies.  * Add bootstrap.yml to scs project ,2,3.9771404
XD-3361,Create a standard way to configure Spring Cloud Data and Stream projects,,8,4.2219434
XD-3362,Port HTTP as s-c-s module,"As a Spring XD developer, I'd like to port {{http}} module from XD to s-c-s repo, so I can use it as {{source}} module in streaming pipeline.  ",2,2.1411483
XD-3363,Port TCP as s-c-s module,"As a Spring XD developer, I'd like to port {{tcp}} module from XD to s-c-s repo, so I can use it as {{source}} module to build streaming pipeline.  ",2,2.1866252
XD-3364,Port Twitterstream as s-c-s module,"As a Spring XD developer, I'd like to move {{twitterstream}} module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.  ",2,2.124639
XD-3365,Port Twittersearch as s-c-s module,"As a Spring XD developer, I'd like to move {{twittersearch}} module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline.  ",2,2.124639
XD-3366,Port Filter as s-c-s module,"As a Spring XD developer, I'd like to port {{filter}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.168283
XD-3367,Port Transform as s-c-s module,"As a Spring XD developer, I'd like to port {{transform}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.152467
XD-3368,Port Router as s-c-s module,"As a Spring XD developer, I'd like to port {{router}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,2.1915042
XD-3369,Port File as s-c-s module,"As a Spring XD developer, I'd like to port {{file}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,2.1512513
XD-3370,Port FTP/SFTP as s-c-s sink module,"As a Spring XD developer, I'd like to port {{FTP/SFTP}} module from XD to s-c-s repo, so I can use it as {{sink}} modules to build streaming pipeline.",2,2.422268
XD-3373,First deploy/launch of Pig job that includes yarn-site.xml file fails,Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.    The error is:     Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster    which indicates that the yarn-site.xml file never made it to the classpath.    Un-deploying and re-deploying the job seems to fix the problem.,5,2.2084067
XD-3374,Port Redis as s-c-s sink,"As a Spring XD developer, I'd like to move {{redis}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",2,3.2385123
XD-3375,Port Rabbit as s-c-s module,"As a Spring XD developer, I'd like to move {{rabbit}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",2,2.219257
XD-3376,Port Gemfire as s-c-s module,"As a Spring XD developer, I'd like to move {{gemfire}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",2,2.269113
XD-3377,Refactor Task parsing ,Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.,8,3.3986392
XD-3378,Upgrade HDP/PHD distrubutions,"As a Spring XD user, I'd like to use the latest releases of {{HDP}}/{{PHD}} distros, so I can leverage the latest features to create pipelines involving {{HDFS}}.",8,2.6139605
XD-3379,Document migration strategy from 1.2 to 1.3 ,"As a Spring XD developer, I'd like to create a section on migration strategy from {{1.2}} to {{1.3}} releases, so I can document new improvements and backward incompatibility specifics.",3,2.018102
XD-3380,Refactor Binder @Configuration to use AutoConfiguration,"Currently, @EnableModule hardcodes references to both the redis and rabbit configuration classes, which trigger or don't trigger based on the presence of another jar (which itself has the meat of the configuration).  This is typically what boot AutoConfiguration is for.    Moreover, adding a new binding (eg Kafka or a stub for module testing) would require to crack open @EnableModule",5,2.3310668
XD-3381,Provide test infrastructure for module authors,"As a module author, I want to be able to test my code in ""next to real world"" conditions (ie Integration Testing, but not really):  - I want all my module wiring to be testable  - I want all my module configuration (@ConfigurationProperties) to be in effect, and I want to be able to test various combination of props  - I want to be able to send data to my module and assert what is coming at the other end  - I want an idiomatic way of asserting the above (eg integration with Hamcrest, etc)  - I DONT want to have to send data to an actual bus (redis, rabbit, etc)",5,4.609614
XD-3382,RetryTemplate props in Rabbit binder are not used,"The `@ConfigurationProperties` class for Rabbit binder has some props related to RetryTemplate, but those are not used",1,2.626187
XD-3384,Spike: Investigate distributed deployment of s-c-s modules via YARN SPI,"As an s-c-d developer, I'd like to investigate the distributed deployment of s-c-s modules on YARN, so I can experiment the implementation of YARN SPI and derive the strategy for {{YARNModuleDeployer}}.",8,3.9186885
XD-3385,Can't build and run singlenode spring-cloud-data-rest app on Ubuntu,"Building and then running spring-cloud-data-rest app on Ubuntu fails when trying to create the first stream. The configuration ends up with a CloudFoundryConfig instead of LocalConfig for the moduleDeployer.  Env: Ubuntu 15.04 java version ""1.8.0_51"" Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode)  Error: {code} 2015-08-10 11:43:47.199 ERROR 11062 --- [nio-9393-exec-1] o.s.c.d.r.c.RestControllerAdvice         : Caught exception while handling a request java.lang.UnsupportedOperationException: null   org.springframework.cloud.data.module.deployer.cloudfoundry.CloudFoundryModuleDeployer.deploy(CloudFoundryModuleDeployer.java:30) ~[spring-cloud-data-module-deployer-cloudfoundry-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   org.springframework.cloud.data.rest.controller.StreamController.deployStream(StreamController.java:213) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   org.springframework.cloud.data.rest.controller.StreamController.save(StreamController.java:140) ~[spring-cloud-data-rest-1.0.0.BUILD-SNAPSHOT.jar!/:1.0.0.BUILD-SNAPSHOT]   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_51]   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_51]   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_51]   java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_51]   org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:111) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   javax.servlet.http.HttpServlet.service(HttpServlet.java:648) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:235) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:85) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:69) [spring-boot-actuator-1.3.0.BUILD-SNAPSHOT.jar!/:1.3.0.BUILD-SNAPSHOT]   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.0.RELEASE.jar!/:4.2.0.RELEASE]   org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:668) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1521) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1478) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51]   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51]   org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.23.jar!/:8.0.23]   java.lang.Thread.run(Thread.java:745) [na:1.8.0_51] 2015-08-10 11:43:47.284  WARN 11062 --- [nio-9393-exec-1] .m.m.a.ExceptionHandlerExceptionResolver : Handler execution resulted in exception: null {code}",3,3.4538903
XD-3386,check whether the field exists or not in  #jsonpath evaluation,"I am parsing Json(source)  into CSV  in Transform function All of my Json records may not have all the fields. Some records have only Field1,field2.. some other records have all 3 fields. if the specific field is not exists in specific record, that record got rejected.(by saying field is not exist) Could you please let me know how to check the field exists or not. Here my expression part of the stream transform --expression=#jsonPath(payload,'$.field1').concat('|').concat(#jsonPath(payload,'$.field2')).concat('|').concat(#jsonPath(payload,'$.field3'))  My Spring XD version is  1-0-0-m7",1,3.6382427
XD-3387,Hide the passwords in custom modules from being displayed.,"Hi,  Passwords are visibly when using custom modules.    Attached is example custom module code and xd-shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE.     Compile with Maven (mvn clean install) and run xd-shell script (xd-shell --cmdfile ./runme.cmd).  ",2,3.364771
XD-3388,Port Trigger as s-c-s module,"As a Spring XD developer, I'd like to move {{trigger}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.  ",2,2.3820045
XD-3389,Add Boot config to support user/pass combination for redis/sentinel cluster,"As a Spring XD user, I'd like to use redis/sentinel cluster as the 'message bus', so I could create streams and batch pipelines.",8,3.504524
XD-3390,"UI + Shell: Remove any usage of REST endpoints using the "".json"" notation","Accessing REST endpoint using the "".json"" file extension causes maintenance issues for the authorization rules and is not necessary. Remove any usage for the Admin UI and the Shell.   At the same time the "".json"" endpoint shall be deprecated or removed ultimately.",5,2.7132785
XD-3391,Come up with a consistent Link consumption scheme on the REST client side,See discussion at https://github.com/spring-cloud/spring-cloud-data/pull/37#discussion_r36849117  Also relevant: http://docs.spring.io/spring-hateoas/docs/current/reference/html/#client,3,2.786282
XD-3393,Upgrade receptor-client to comply with latest Receptor APIs,"As a s-c-d developer, I'd like to upgrade {{receptor-client}} to comply with latest {{Receptor}} API changes, so I can sync-up and take advantage of the recent improvements. ",3,2.4045649
XD-3394,Known Hosts Configuration for SFTP Source,"Spring Integration 4.2 changed the default SFTP session factory to *not* accept keys from unknown hosts by default. This is more secure.  You either have to provide a pre-populated {{known_hosts}} file or set {{allowUnknownKeys}} to true.  If you do both, the keys will be automatically added to the known hosts file.  When updating XD to 4.2.0.RC1 I simply set the boolean to true, to retain the previous behavior.  Add properties to the SFTP source to allow configuration of these properties at the stream level. ",1,3.7115767
XD-3395,Module Launcher properties improvments,Improve Spring Cloud Stream module launcher/resolver properties:  1) Support comma separated remoteRepositories 2) Classify/group the properties,3,2.9183593
XD-3396,Add cloud connector dependencies for spring-cloud-data admin,"Spring-cloud-data admin requires lattice connector and `spring-cloud-spring-service-connector` dependencies so that the admin controllers get access to any services while running on lattice.  One example is, CounterContoller using `redis` service for MetricRepository.",3,2.7520697
XD-3397,Port admin web UI to Spring Cloud Data admin,As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.,2,2.4405954
XD-3398,Create auto configuration/properties for Local Binder,"As a s-c-s developer, I'd like to create auto configuration for {{singlenode}} binder configuration/properties, so I can automatically configure the Spring application based on the dependencies.",1,3.5792632
XD-3399,Create CI Builds for SCD and Receptor Client,Build SCS and SCD projects upon change in github repo. Push docker image for SCD-Admin to docker hub,5,2.5781794
XD-3400,Add support for passing parameters to YARN container,"As a s-c-d user, I'd like to have the option to support passing definition parameters into YARN container, so I can effectively use those _params_ within the module running inside the container.",3,2.8724294
XD-3401,Add support for deploying YARN app into HDFS,"As a s-c-d developer, I'd like to add support to deploy YARN App into HDFS automatically, so I can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.",3,4.5716767
XD-3402,Add support to start Apps in YARN automatically by type,"As an s-c-d developer, I'd like to add support to negotiate with the ResourceManager REST-APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as  {{appType=CLOUDDATA}} and {{appName=spring-cloud-data-yarn-app}}. ",3,3.0645986
XD-3403,Add support to spin-up multiple App instances,"As a s-c-d developer, I'd like to support multiple app instances:  * This is simply to make controlling app instances more clever. Potentially we could use deployment properties to define different yarn app instances like:    {code}  cloud-data:>stream deploy --name ticktock --properties ""module.*.yarn.app.name=app""     cloud-data:>stream deploy --name ticktock --properties ""module.time.yarn.app.name=app""  {code}    * Motivation to this is that different yarn apps can have different queues and priorities. Yarn administrator can define that some app queues have higher priority to reserve resources from    * Using deployment properties like this allows to customize runtime parameters like how much we try to reserve mem/cpu for modules, etc.",2,2.7090294
XD-3404,Refactor YARN deployer to deploy asycnhrounously,"As a s-c-d developer, I'd like to make the deployer work asynchronously, so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.",2,2.5260665
XD-3405,Spike: Study how to resolve and add JARs to Boot loader,"As a s-c-d developer, I'd like to experiment how do we resolve and then add module dependent JAR's to Boot loader, so I have an approach to handle external libraries required by OOTB modules. ",5,2.8290555
XD-3406,Refactor to use Boot's JarLauncher,"As a s-c-s developer, I'd like to refactor the current {{ModuleLauncher}} contract with Boot's {{JarLauncher}} API, so we don't have to maintain duplicate functionality.",1,2.4615417
XD-3407,Document the process of resolving and adding JARs to Boot loader,"As a s-c-d developer, I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader, so we could use this as a reference while porting modules with external dependencies. ",3,2.6696656
XD-3408,Support adding new libraries,"As a s-c-d developer, I'd like to add support to add external libraries, so I can consume such dependencies for modules in an uniform way.",2,2.235725
XD-3409,Prevent external libraries from overriding uber-jar dependencies,"As a s-c-d developer, I'd like to enforce external libraries from overriding any existing library in the uber-jar.",2,1.9994421
XD-3411,Move external library resolver to its own project,"As a s-c-d developer, I'd like to move the external library to its own project, so we have a clear separation of functionalities in s-c-d repo.",3,2.674668
XD-3412,Port SFTP as s-c-s source module,"As a Spring XD developer, I'd like to port SFTP module from XD to s-c-s repo, so I can use it as source modules to build streaming pipeline. ",5,2.290961
XD-3413,Enhance TaskLauncher,"h2. Narrative As Spring XD, I will be able to launch Spring Boot jar files as Diego Tasks.  h2. Back story The {{TaskLauncher}} will be responsible for listening for launch requests, looking up the definition in the {{TaskDescriptorRepository}}, and launching it.  The first implementation of this would be a Receptor based implementation.   *See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit",5,2.1713908
XD-3414,Create a new project for @RedisRule,"As a s-c-d developer, I'd like to create a new project to contain all the rules associated {{@RedisRule}} contract, so it is isolated from core functionalities and reusable by test coverage as needed.      Consider moving this coverage to SI ""commons"" or equivalent. ",5,3.0778391
XD-3415,[SCS]Replace MessageCollector with generic SI Components,"Ultimately module IntegrationTest classes should themselves be a module so that testing a Source for example would use a TestSink and the message verified on the sink input().  This is currently a placeholder which includes: * SCS enhancements to support proxying of Pollable or Subscribable MessgeChannels * Corresponding Changes to the s-c-s-test-support to eliminate MessageCollector and provide support for easily using the test's PollableChannel(s) if necessary, e.g. test-specific annotations * Related to or may depend on implementing direct binding (composed modules) in s-c-s  * Refactor existing module test code",8,3.530107
XD-3416,Create foundation to support s-c-s 'processor' modules,"As a s-c-d developer, I'd like to create foundation to support _processor_ as OOTB modules, so I can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.",5,3.7378583
XD-3417,Add SmartLifecycle to ChannelBindingAdapter,Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.,1,2.6800566
XD-3418,"Enable ""offline"" mode for AetherModuleResolver","As a s-c-s developer, I'd like to enable {{offline}} mode for {{AetherModuleResolver}}, so I can pull the module artifacts from local instead of remote maven repo.",3,2.4386497
XD-3419,Add registry to lookup module coordinates by name,"As a s-c-d developer, I'd like to create {{ModuleRegistry}} implementation, so I can use this infrastructure to lookup module coordinates by name.",8,2.6753528
XD-3420,RedisSink to support in-memory store,,2,2.8947308
XD-3421,Create a Rabbit|Kafka Available Rule in s-c-s-m,"Can take from previous implementation in XD/SI/Boot.  Should have a way to enforce not skipping tests based on an environment variable.    Consider moving this coverage to SI ""commons"" or equivalent. ",3,3.2028155
XD-3422,Create unit tests for CounterSinkProperties in s-c-s-m,,1,3.2081623
XD-3423,Update Shell to support tasks,"h2. Narrative As a user, I need to be able to deploy a task (boot jar) via the CLI.  h2.  Back story Since the concept of jobs as an explicit primitive within Spring XD is going away in spring-cloud-data, the shell needs to be updated to reflect that.",5,1.7095785
XD-3424,Fix Cloud connector dependencies and service resolution,"This JIRA addresses couple of issues: 1) When the modules are deployed into cloud environment there is an issue where local configuration beans collide with cloud service beans. We witnessed an issue where there are two `RedisConnectionFactory` beans registered in the same application context. We need to have a control the way in which the auto configuration gets invoked and service beans are created. 2) We need to align the cloud connector dependencies into a common place so that we don't have to specify them at various places like (SCS, SCS-Binder, SCS-modules) etc., It is a good idea to have these dependencies specified in SCS-modules so that it get used subsequently by SCS when the module is assembled at runtime.",3,2.6987302
XD-3425,Support shell commands to interact with module registry,"As a s-c-d developer, I'd like to have {{module info}}, {{module list}}, {{module register}}, and {{module unregister}} commands, so I can interact with {{ModuleRegistry}}.",8,3.2887502
XD-3426,"Add ""module info"" command","As a s-c-d developer, I'd like to have {{module info}} shell command, so I can query each of the module specifics such as description and support options. ",2,1.9206837
XD-3427,"Add ""module list"" command","As a s-c-d developer, I'd like to have {{module list}} shell command, so I can query and list all the modules supported within the {{ModuleRegistry}}.",2,2.0459177
XD-3428,"Add ""module register"" command","As a s-c-d developer, I'd like to have {{module register}} shell command, so I can register new modules in the {{ModuleRegistry}}.",2,1.9781823
XD-3429,"Add ""module unregister"" command","As a s-c-d developer, I'd like to have {{module unregister}} shell command, so I can unregister an existing module from the {{ModuleRegistry}}.",2,2.0325336
XD-3430,"Add support for ""deployment properties""","As a s-c-d developer, I'd like to provide optional key-value pairs as deployment properties, so I could leverage them at the runtime to instruct how the modules will be deployed.   _The scope of this story is to specifically support {{count}} to represent {{N}} instances of modules that share the same environment variables._",8,3.4232912
XD-3431,Use mocks in shell tests,"Instead of using real `moduleDeployer`, try using mocks so that the module deployer downloading the maven co-ordinates from repo can be avoided (for module deployment case).  Since module deployer and controllers are tested individually, it would be good to focus on shell functionality only for the shell tests.",2,2.9634302
XD-3432,Update documentation for module launcher,"The s-c-s-module-launcher document requires update for running it on standalone, docker, lattice. Also, the docker-compose yml requires fix so that modules in there are bound together.",1,2.099458
XD-3433,[Flo] UI unresponsive after some time,"The Chrome UI Interface for flo stream creation stops responding after some time. It starts working once the browser history/ cookies etc. are cleaned up.   . The drop down stops working,   . i'm unable to look at or edit module properties,  . connecting different modules doesn't work either . Drag and drop operations still work . command line stream creation still works  is anyone else facing these issues ?   Thanks ! ",2,3.5417497
XD-3434, Issue with pagination in web UI,"In JOBS tab; Quick-filter search box paging functionality is not working as expected. Items stay in the page they were first loaded after filtering.   ex. If there were 500 pages of jobs and you are filtering for a job which was in 345. page, after the filtering you have to navigate to that page in order to see the job. It needs to be rendered on the first page.     ",3,3.4005165
XD-3435,Add search box to the Admin UI for Deployments page,"If there is a large number of deployments it would be helpful to have a quick search filter in place to enable users to find deployments faster, as can be done in the Definitions page.",3,2.268538
XD-3436,Create a spring cloud stream timestamp task module,Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs.    ,3,2.9547925
XD-3437,The state of a task or job should be recorded such that it can be monitored by a user,The state of a task or job should be recorded such that it can be monitored by a user.  ,8,2.956383
XD-3438,Spike: Study options for loading reusable configurations ,"SCD Admin will have connection information for a task and job repository.  This information will need to be transferred to the Task Launcher.    The scope is to study the following options:  * Would the default place for configurations be in the YAML file?  * {{config-server}} should be an option?  * If nothing specified, the default is always YAML?",5,2.867938
XD-3439,User wants the ability to check the status of a job or task from the CLI,,5,1.698137
XD-3440,Tasks Launcher should be able to record status to a central repository,"Need infrastructure to capture the state from the environment (lattice, local) running the task.    Task Launcher needs ability to map the task state as it is reported from the cloud environment (lattice, local) to the enumerated state as specified [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].    The state information needs to be recorded in the task_execution table enumerated [#here|https://docs.google.com/document/d/1tTmQMIwSUEFewYYsafK8Ji4Z9NI-5F1VFeAiWHuZSgg/edit#heading=h.2ec94f2he9ly].",8,2.5314403
XD-3441,User wants ability to cancel a running task from SCD CLI,"User should be able to execute a task cancel <task name>.  Which will terminate a running task.  And set the state of the task to ""cancelled"".    ",8,1.7202204
XD-3442,User wants to restart failed job from SCD,User wants to restart a failed Job via the CLI.     i.e.  task relaunch job-instance id,8,1.984588
XD-3443,User wants a task status command to retrieve all task & Job info for the running or completed job,,8,2.4655411
XD-3444,Create gh_pages for s-c-d and s-c-s-m repos,"As a s-c-d developer, I'd like to setup {{gh_pages}} branch for s-c-d and s-c-s-m repos, so I can start pushing documentation with PR commits.",5,3.341016
XD-3445,Fix Kafka Binder for s-c-s modules,"As a s-c-s developer, I'd like to fix the {{Kafka}} binder, so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. ",3,3.0047426
XD-3446,The tooltip for source displays incorrect information when using HDFS as sink,"Deploying a Stream with HDFS sink and JDBC as source displays incorrect information on the tooltip for the JDBC source. The issue occurs when there are more than 1 containers deployed and the source is deployed on one container and the sink is deployed on another container. I have checked the REST endpoints and they seem to show the correct information. (http://localhost:9393/runtime/containers.json)    In my test case, say if there are 2 containers and source and sink are deployed on the same container, the tooltip's show correct information. The Stream I used for testing purposes is as follows -  {noformat}   stream create swagataTestIssue --definition ""jdbc --query='select employee_id, employee_name, employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy   {noformat}    I will attach the screenshots. This issue has also been reported when using Gemfire as source and HDFS as sink.    Thanks,  Swagata",1,3.6135557
XD-3447,Document s-c-d architecture and deployment variants,"As a s-c-d developer, I'd like to produce ref. documentation for s-c-d architecture, so I could define 1.x and 2.x deployment differences. ",8,2.873169
XD-3448,Spike: Evaluate Concourse for CI pipelines,"As a s-c-d developer, I'd like to study [Concourse CI|http://concourse.ci/] so I can understand how to use it for s-c-d going forward. ",3,1.790367
XD-3449,Task Repository,"h2. Narrative  As a user I need to be able to query the current state of a task that has been launched.    h2. Back story  Given the fact that tasks are intended to go away, we need to record the state of them as well as their end result in a repository for a user to be able to query.  This repository will be the system of record when reporting the state of an executing/executed task.",8,3.3775384
XD-3450,Deploy multiple instances of a module,"Currently we deploy a single instance, and ignore the ModuleDeploymentRequest instances setting.    It is easy to change this in the ModuleDeployer, but there is no guarantee this will work in the ModuleLauncher, so we hold off until that can be verified.",2,3.0632617
XD-3451,Correctly report state of module instances,Currently only the STARTED application (and application instance) status is recognised. This issue will look at the other possible states and report them as module instance states.    This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.,2,2.3628263
XD-3452,Handle paginated responses,"Currently we handle only a single page response from CC SPI list requests, but potentially there could be multiple ones.",2,1.907565
XD-3453,Speed up upload of Module Launcher jar,"Upload of module launcher bits is slow because we do not take into account the  CC cache. To fix this we need to use an async upload, and to somehow generate  the SHA, etc, for the Module Launcher so that CC can pre-empt uploading all  the bits every time.",3,3.797496
XD-3454,Add RxJava processor module,"As a module author, I would like to apply RxJava processor module with spring cloud stream. ",3,2.6931245
XD-3455,Remove hard-coded 'app' name from config file,,2,2.058329
XD-3456,Create infrastructure for Spring cloud task modules,Create Parent pom file for build  Create .settings file  Migrate Timestamp task from SCSM to SCTM.  ,3,4.3972654
XD-3457,Remove Timestamp task from SCSM,,1,1.7664317
XD-3458,Create CI Build for SCTM,,3,3.3028307
XD-3460,Support underscore delimited module args for module launcher,"If the module launcher's module arg is delimited by underscore (--args_0_fixedDelay=1), then boot ignores that property. It is important to support the underscore delimited property arguments as we set environment properties of these in CF and lattice environment.    The spring boot fix (https://github.com/spring-projects/spring-boot/commit/5a287455273270a20742f03e4546acde9e857bee) doesn't resolve the property if the value type of the Map is Map itself.",2,3.3196788
XD-3461,Remove hardcoded yarn app version jars,We currently use fixed paths like `spring-cloud-data-yarn/spring-cloud-data-yarn-appmaster/target/spring-cloud-data-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar` in yml files. Need to make define version during a build and allow to override location of those files.,1,1.7816683
XD-3462,Create a new banner for spring-cloud-data-flow,"As a s-c-d user, I'd like to create a new banner, so I can embed and display the banner when the shell server boots-up.     Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?",1,3.012369
XD-3463,Complete 'Running on Cloud Foundry' section in README,"As a s-c-d developer, I'd like to document [Running on Cloud Foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in README, so it can be publicly available as deployment guideline.",2,2.0323288
XD-3464,Stream Destroy fails if stream deploy failed,"(From Eric)  Deploying using the following stream fails (probably because of issues around quoting):  `stream create foo --definition ""time | filter --expression=payload.contains('0') | log"" --deploy`  When you try to destroy the stream the destroy fails, which shouldn't happen whether the stream was valid or not.",2,2.8420942
XD-3465,NPE in AbstractReactorMessageHandler,"When the {{BroadcasterMessageHandler}} is defined as a {{@ServiceActivator}} {{@Bean}} , the output channel must be set on the handler, not in the annotation.    The handler should detect a {{null}} {{outputChannel}}.    See http://stackoverflow.com/questions/32462059/spring-xd-reactor-streams-with-configuration-npe",1,2.2186227
XD-3466,Add hdfs sink to module registry,"As a s-c-d developer, I'd like to add _hdfs_ sink to module registry, so I can use this module to build streaming pipeline and write to Hadoop.",1,3.819875
XD-3467,Spike: Study scope to add support for hdfs commands in shell,"As a s-c-d developer, I'd like to add support for hadoop commands in shell, so I can use it to query the hadoop file system.",3,1.5697502
XD-3468,Unable to set --closeTimeout on SCSM hdfs sink module,"Creating a stream like this:      stream create --name myhdfsstream1 --definition ""time | hdfs --closeTimeout=5000"" --deploy    causes:    java.lang.IllegalArgumentException: Task executor must be set          at org.springframework.util.Assert.notNull(Assert.java:115) ~[spring-core-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.data.hadoop.store.support.PollingTaskSupport.init(PollingTaskSupport.java:105) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]          at org.springframework.data.hadoop.store.support.StoreObjectSupport.onInit(StoreObjectSupport.java:97) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]          at org.springframework.data.hadoop.store.support.OutputStoreObjectSupport.onInit(OutputStoreObjectSupport.java:81) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]          at org.springframework.data.hadoop.store.support.LifecycleObjectSupport.afterPropertiesSet(LifecycleObjectSupport.java:67) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]          at org.springframework.cloud.stream.module.hdfs.sink.DataStoreWriterFactoryBean.afterPropertiesSet(DataStoreWriterFactoryBean.java:175) ~[hdfs-sink-1.0.0.BUILD-SNAPSHOT-exec.jar!/:1.0.0.BUILD-SNAPSHOT]          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1637) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        ... 35 common frames omittedWrapped by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataStoreWriter' defined in class path resource [org/springframework/cloud/stream/module/hdfs/sink/HdfsSinkConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Task executor must be set          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1578) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]          at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBea",2,2.2868118
XD-3469,The new SCSM twitterstream module should produce same json as old XD source,The new SCSM twitterstream module uses a different format than XD 1.x source module. It should match what Twitter uses so existing processors etc. will continue to work.,3,1.7824407
XD-3470,Unnecessary format enforcement on module short description,"What is the functional justification for enforcing this validation on modules? Is it really necessary to enforce that the short description must start with a capitol letter and end with a period? Seems a bit unnecessary and opinionated to me.    Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors  Field error in object 'info' on field 'shortDescription': rejected value [...snip...]; codes [Pattern.info.shortDescription,Pattern.shortDescription,Pattern.java.lang.String,Pattern]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [info.shortDescription,shortDescription]; arguments []; default message [shortDescription],[Ljavax.validation.constraints.Pattern$Flag;@3984374e,^\p{IsUppercase}.*\.$]; default message [Short description must start with a capital letter and end with a dot]  ",1,2.7846813
XD-3471,Improve resilience of route creation/removal,"The CF implementation requires that a route be created for each new app. This works fine on the happy path, but is brittle. For example, it will fail if the route required already exists.",2,2.1632154
XD-3472,Spring XD processor module classloader issue: ClassNotFoundException,See http://stackoverflow.com/questions/32525290/spring-xd-processor-module-classloader-issue-classnotfoundexception,3,2.487529
XD-3473,Web Admin app not loading for slow connections,"When opening manager webapp, if the internet connection is slow enough to make one of the biggest javascript dependencies to make requirejs throw a timeout the webapp becomes unusable, displaying only the loading gif, and showing a javascript error saying:    Uncaught Error: Load timeout for modules: angular    It typically takes ~ 10 seconds to throw that error.",1,3.0531645
XD-3474,Composing modules ignores output/input type specified in definition,"When composing two or more modules together, if any output or input type is specified between modules, it is ignored.     I created a stream with definition:  {code}  mySourceModule --outputType=application/json | myProcessorModule  {code}  that worked fine as expected. When i composed this definition as a composed module, I got errors stating that the processors message handler had no handler method for the object the source module emitted. The process was only configured to accept JSON as string. I simply had to create a second handler method but if i didnt own the module, this could be an issue.",1,3.5374732
XD-3475,Composed modules destination binding order incorrect,"Created a stream with definition:  {code}  mySourceModule | myProcessorModule | log  {code}  This stream worked fine, but when created composed module with definition  {code}  mySourceModule | myProcessorModule  {code}  Then stream definition  {code}  myComposedModule | log  {code}    get an error stating that the output channel of mySourceModule has no subscribers. Looking at previous bugs, this appears to be a module binding order in which the source is started before the processor has subscribed to the output channel of the source.",1,3.5782363
XD-3476,Add the various property sources to the Spring Environment bean,It would be extremely nice to have the various property sources available in the Spring Environment bean for a module to use.,1,2.3506713
XD-3478,Spike: Investigate options for composed jobs repository,"As a XD developer, I'd like to explore repository options for ""composed jobs"", so I have the leverage to read/write composed job definitions.",5,2.6806066
XD-3479,Orchestrate job composition,"As a XD user, I'd like to orchestrate composed jobs, so I can bring multiple jobs into single workflow and operationalize.",5,3.3258898
XD-3480,Unit test shell commands in isolation,"As a s-c-d developer, I'd like to add test coverage to test {{shell}} commands in isolation, so I don't have to run end-to-end full stream deployment based functional tests.    More details [here|https://docs.google.com/document/d/18uNqRAgVGO0BHdvDsVg3X78gDBeqXA_LN_C6jJ0YpKw/edit#].",5,3.0769346
XD-3481,Bind message properties to modules,"As a s-c-s developer, I'd like to support XD-like features where modules bind to incoming messages via expressions or other mechanism, so I can bind message properties to every microservice modules. ",5,3.565961
XD-3482,Port JDBC as s-c-s sink,"As a s-c-s-m developer, I'd like to move {{jdbc}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.   See also XD-2250",5,3.567052
XD-3483,Port Kafka as s-c-s source,"As a s-c-d developer, I'd like to move {{kafka}} module from XD to s-c-s repo, so I can use it as {{source}} to build streaming pipeline.",2,1.2090243
XD-3484,Port Kafka as s-c-s sink,"As a s-c-d developer, I'd like to move {{kafka}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",2,3.4655042
XD-3485,Port Rabbit as s-c-s sink,"As a s-c-d developer, I'd like to move {{rabbit}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",2,3.3451695
XD-3486,Spike: Study support for different binder-types for module channels,"As a s-c-d developer, I'd like to add support for having different binder types for module's channels, so I can plug {{rabbit}}, {{redis}}, or {{kafka}} as the source or sink to read and write respectively.",8,2.9530487
XD-3487,Add property override support for modules via external config file,"As a s-c-d developer, I'd like to pass any overrides via external config file, so I can influence and override the default module configurations. (ex: module resolution from a different maven coordinate). ",3,2.8647704
XD-3488,Refactor CF SPI with CF java-client library,"As a s-c-d developer, I'd like to refactor CC SPI deployer with CF java-client, so I can improve the overall design and performance. ",8,2.669211
XD-3489,Add support to load Hadoop distribution of choice,"As a s-c-d user, I'd like to have the option to choose Hadoop distribution of choice, so I can load the right Hadoop libraries in the CP.   ",5,2.4162436
XD-3490,Port load-generator & throughput modules to SCS-Modules,Migrate load-generator and throughput to SCS.  ,5,2.8278692
XD-3491,Move Cassandra sink to XD proper,,3,2.7659059
XD-3492,Move header-enricher to XD proper,"As a XD developer, I'd like to move header-enricher from modules repo to XD proper. ",1,2.605931
XD-3493,"Update SI, Spring, and AMQP dependencies","As a XD developer, I'd like to upgrade to SI 4.2, Spring 4.2.1, and AMQP 1.5 dependencies, so I can take advantage of the latest improvements. ",3,1.1176264
XD-3494,Document how to use to BOM template,"As a s-c-d developer, I'd like to document the use of BOM templates, so the general audience can use it as a reference to include external libraries dynamically.",1,2.027599
XD-3496,[Int Tests] Enhance test coverage for Lattice SPI,"As a s-c-d developer, I'd like to enhance integration test coverage for {{Lattice}} SPI, so I can continuously evaluate functionalities via CI pipeline.",3,3.6917562
XD-3497,[Int Tests] Enhance test coverage for CC SPI,"As a s-c-d developer, I'd like to enhance integration test coverage for {{CC}} SPI, so I can continuously evaluate functionalities via CI pipeline.  ",3,3.8736827
XD-3498,Spike: Explore options to support YARN integration tests,"As a s-c-d developer, I'd like to enhance integration test coverage for {{YARN}} SPI, so I can continuously evaluate functionalities via CI pipeline.  ",5,3.3714888
XD-3499,[Unit Tests] Enhance test coverage for Lattice SPI,"As a s-c-d developer, I'd like to enhance unit test coverage for {{Lattice}} SPI, so I can continuously evaluate functionalities via CI pipeline.  ",3,3.6713011
XD-3500,[Unit Tests] Enhance test coverage for YARN SPI,"As a s-c-d developer, I'd like to enhance unit test coverage for {{YARN}} SPI, so I can continuously evaluate functionalities via CI pipeline.  ",3,3.782144
XD-3501,Admin UI container shutdown not working,"As a user, I'm not able to shutdown {{container}} from Admin UI with the following stream definition deployed.    {code}  stream create swagataTestIssue --definition ""jdbc --query='select employee_id, employee_name, employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy   {code}    More details [here|https://issuetracker.springsource.com/browse/VESC-504].",2,2.3370984
XD-3502,Upgrade SCSM hdfs sink to SHDP 2.3.0.M3,,1,2.6480923
XD-3503,Document the setting of the CORS allow_origin property,We do set a default value in: xd/lib/spring-xd-dirt-1.2.1.RELEASE.jar/application.yml    {code}  ...  xd:    data:      home: file:${XD_HOME}/data    config:      home: file:${XD_HOME}/config    module:      home: file:${XD_HOME}/modules    customModule:      home: file:${XD_HOME}/custom-modules    ui:      home: file:${XD_HOME}/spring-xd-ui/dist/      allow_origin: http://localhost:9889  ...  {code}    We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using **servers.yml**,2,1.9462856
XD-3504,Support for multiple connections to the same binder implementation,"As a s-c-s user, I'd like to have the option to use more than one binder connection factory, so I can mix and match where I consume and publish data.     More details [here|https://github.com/spring-cloud/spring-cloud-stream/issues/140].",5,2.8709097
XD-3505,Admin app crashes with SSL certification errors,"As a s-c-d user, I'm unable to push admin app to CF due to SSL certification errors while bootstrapping.     Consider adding [CF trusted certificate|https://github.com/pivotal-cf/cloudfoundry-certificate-truster] as a CF SPI dependency.    Adding CF trusted certificate as dependency doesn't help either:    {code}  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.Validator.validate(Validator.java:260)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)  > Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)  > Fri Sep 25 2015 12:55:32 GMT-...  {code}",3,2.8554218
XD-3506,UI - Container List - Module Properties - Escape Passwords,,1,3.006087
XD-3507,Upgrade to spring boot 1.3,Upgrade dependencies to Spring Boot 1.3.x,5,2.152218
XD-3508,Refactor to replace codec implementation with SI library,"As a XD developer, I'd like to refactor and replace {{codec}} code from XD with SI library, so I don't have to maintain duplicate code.",3,2.9991515
XD-3509,CORS issue when trying to use HTTP in singlenode,"When I'm trying to send a json object to spring-xd I get the following error even though I opened up requests to allow all.     XMLHttpRequest cannot load http://localhost:9000/. No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://localhost:3000' is therefore not allowed access.    Config:   spring:    profiles: singlenode  xd:    transport: local    ui:       allow_origin: ""*""",3,2.045219
XD-3510,Spark Tap Tests Do Not Clean Up RabbitMQ,2 Exchanges left behind.,1,2.8256462
XD-3512,Implement Gemfire message-channel binder,"As a s-c-s user, I'd like to have {{Gemfire}} message-channel binder, so I can use {{Gemfire}} as the messaging middleware for low latency use-cases. ",8,2.53777
XD-3513,Implement Gemfire SPI,"As a s-c-d user, I'd like to have the option of {{Gemfire}} SPI, so I can use {{Gemfire}} and the infrastructure to orchestrate s-c-d data microservices. ",8,3.906366
XD-3514,Add support for Gemfire as stream repository,"As a s-c-d user, I'd like to have the option of {{Gemfire}} as stream repository, so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.",8,2.940302
XD-3515,Add support for Gemfire as module registry,"As a s-c-d user, I'd like to have the option of {{Gemfire}} as module registry, so I can build data pipelines that are entirely orchestrated within {{Gemfire}}.",8,3.9820745
XD-3516,Document partitioning through deployment properties,"As an s-c-d user, I'd like to have documentation on deployment manifest, so I could refer to the relevant bits on {{partitions}}. I'd like to understand how streams withe    ",2,2.9775267
XD-3517,Document direct binding ,"As an s-c-d user, I'd like to refer to documentation on ""direct binding"", so I can use it as a reference to deploy a stream that includes directly bound modules.     Example:  {code}  java -jar spring-cloud-stream-module-launcher/target/spring-cloud-stream-module-launcher-1.0.0.BUILD-SNAPSHOT.jar --modules=org.springframework.cloud.stream.module:time-source:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT,org.springframework.cloud.stream.module:filter-processor:1.0.0.BUILD-SNAPSHOT --args.0.fixedDelay=7 --args.1.expression='payload.contains(""6"")' --aggregate=true --spring.cloud.stream.bindings.output=filtered  {code} ",2,3.1312852
XD-3519,Add TAP support for Rabbit binder,"As an s-c-d user, I'd like to {{tap}} the primary pipeline, so I can fork the same data and do some ad-hoc analysis without impacting the original stream.",8,3.184585
XD-3520,Add TAP support in DSL/Shell,"As an s-c-d user, I'd like to have {{tap}} support in s-c-dataflow DSL/Shell, so I can fork the same data and do some ad-hoc analysis without impacting the original stream.",3,2.261091
XD-3521,Add support to upload custom modules ,"As an s-c-d user, I'd like to upload custom modules using shell/rest-api, so I can contribute modules and create streaming/batch pipelines. ",8,3.9361274
XD-3522,Add dynamic addition to module registry,"As an s-c-d user, I'd like to contribute modules that immediately reflects in module registry, so I can create stream or task definitions using the shell/rest-api's.     Currently the registry isn't flexible, as it is pretty much [hard-coded at registry bootstrap level|https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-admin/src/main/java/org/springframework/cloud/dataflow/admin/config/ModuleRegistryPopulator.java#L75]. ",8,3.767411
XD-3523,Port JMS as s-c-s source,"As a Spring XD developer, I'd like to move {{jms}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.  ",2,1.1771691
XD-3524,Port Mail as s-c-s source,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.  ",2,1.1811122
XD-3525,Port MongoDB as s-c-s source,"As a Spring XD developer, I'd like to move {{mongo}} module from XD to s-c-s-m repo, so I can use it as source to build streaming pipeline.  ",2,1.2676651
XD-3526,Port MQTT as s-c-s source,"As a Spring XD developer, I'd like to move {{mqtt}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.  ",2,1.0022949
XD-3527,Port ReactorIP as s-c-s source,"As a Spring XD developer, I'd like to move {{reactor-ip}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",2,1.054035
XD-3528,Port STDOUT as s-c-s source,"As a Spring XD developer, I'd like to move {{stdout}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",2,1.054035
XD-3529,Port syslog as s-c-s source,"As a Spring XD developer, I'd like to move {{syslog}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.  ",2,1.2014577
XD-3530,Port Tail as s-c-s source,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",2,1.2142946
XD-3531,Port TCP as s-c-s source,"As a Spring XD developer, I'd like to move {{tcp}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.",2,1.1462103
XD-3532,Port TCP Client as s-c-s source,"As a Spring XD developer, I'd like to move {{tcp-client}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.  ",2,1.1885681
XD-3533,Port GPFDIST as s-c-s sink,"As a Spring XD developer, I'd like to move {{gpfdist}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.2881517
XD-3534,Port HDFS DataSet as s-c-s sink,"As a Spring XD developer, I'd like to move {{hdfs-dataset}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",5,3.4694612
XD-3535,Port Mail as s-c-s sink,"As a Spring XD developer, I'd like to move {{mail}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.46055
XD-3536,Port MongoDB as s-c-s sink,"As a Spring XD developer, I'd like to move {{mongo}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.528807
XD-3537,Port MQTT as s-c-s sink,"As a Spring XD developer, I'd like to move {{mqtt}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.220943
XD-3538,Port NULL as s-c-s sink,"As a Spring XD developer, I'd like to move {{null}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.412661
XD-3539,Port Shell as s-c-s sink,"As a Spring XD developer, I'd like to move {{shell}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.398753
XD-3540,Port Splunk as s-c-s sink,"As a Spring XD developer, I'd like to move {{splunk}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.3885326
XD-3541,Port TCP as s-c-s sink,"As a Spring XD developer, I'd like to move {{tcp}} module from XD to s-c-s repo, so I can use it as sink to build streaming pipeline.  ",2,3.3827631
XD-3542,Port JDBC as s-c-s source,"As a Spring XD developer, I'd like to move {{jdbc}} module from XD to s-c-s repo, so I can use it as source to build streaming pipeline.  ",2,1.327146
XD-3543,Port aggregator as s-c-s processor,"As a Spring XD developer, I'd like to port {{aggregator}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.05258
XD-3544,Port HTTP-Client as s-c-s processor,"As a Spring XD developer, I'd like to port {{http-client}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.0344605
XD-3545,Port JSON to Tuple as s-c-s processor,"As a Spring XD developer, I'd like to port {{json-to-tuple}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.0466456
XD-3546,Port Object to JSON as s-c-s processor,"As a Spring XD developer, I'd like to port {{object-to-json}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.0463703
XD-3547,Port Script as s-c-s processor,"As a Spring XD developer, I'd like to port {{script}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.0236359
XD-3548,Port Shell as s-c-s processor,"As a Spring XD developer, I'd like to port {{shell}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,2.0359714
XD-3549,Port Splitter as s-c-s processor,"As a Spring XD developer, I'd like to port {{splitter}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",2,1.9707547
XD-3550,Re-add Spark job acceptance test with spark standalone cluster ,The spark app test on spark standalone cluster is currently commented out:  https://github.com/spring-projects/spring-xd/blob/9307f1fba347adf59c8b489ae7fe0aa9bfd9b6a6/spring-xd-integration-test/src/test/java/org/springframework/xd/integration/test/SparkAppTests.java#L74    We need to add it back once the cluster is setup on acceptance test environment.,1,3.575935
XD-3552,Improve automated documentation generation process for modules to handle array arguments,"For example the generated value for the cassandra sink results in     {{-$$entityBasePackages$$:: $$the base packages to scan for entities annotated with Table annotations$$ ($$String;$$, default: `[Ljava.lang.String;@2638011`)}}    where the default value changes each time the build is run.  ",3,3.013695
XD-3554,Spike: Destroy composed job,"As an XD developer, I'd like to explore options to remove composed job, so I can clean-up unused resources and memory footprints. ",8,3.398407
XD-3555,Spike: Store DSL definition in ZK,"As an XD developer, I'd like to explore options to save composed job definition in ZK metadata, so I can use the repository to recreate jobs to recover from failure scenarios.",5,3.3050518
XD-3556,Develop tasklet to execute a Job,"h2. Narrative  As the system, I would like a way to launch a previously deployed job module from another job module.    h2.  Back story  For the composed job story, we will have a driver job that consists of each step that represents the execution of a job.  This story is the creation of a {{Tasklet}} that will launch the child job, and upon it's completion, set the results of the driver's step to that of the slave job's results.  ",5,3.465304
XD-3557,Expose status for each job within the composition,"h2. Narrative  As the xd user, I would like a way obtain the result of each child job as it is represented as a step in the parent job's graph.    h2.  Back story  Each child job will have a completion status of its own that will be displayed in the Spring XD UI as well as the shell's job execution list.   ",5,3.058526
XD-3558,Add ability to launch job composition,h2. Narrative  Verify that the job launch works as we expect for the composed job.  ,1,3.142341
XD-3559,Add support to restart job composition,"h2. Narrative  As a XD user, I'd like to restart the composed job workflow from Shell/UI. ",5,3.082972
XD-3560,Better printing of array default valuesin documentation,"When a default value is an array, the current behavior (using toString()) not only produces useless results (like `[Ljava.lang.String;@2638011`) but also constantly changing results.",5,1.4009186
XD-3561,Configurable response status code in HTTP Source,We have a use case where we need the HTTP source module to return a 204 status instead of the 200 status that is currently returned. There may be other status codes that it would be useful to be able to return. A simple additional option on the module would allow this to be configured.  ,5,3.6443322
XD-3563,Create BinderFactory abstraction,"As a developer, I want to have a {{BinderFactory}} abstraction, so that I can support multiple binder types in the future.",5,3.579798
XD-3564,Add support for registering multiple BinderFactories ,"As a developer, I want to be able to connect to multiple types of transports in an application, so that I can receive and send messages to different transport types.",5,3.438764
XD-3565,Add support for multiple binders per binder type,"As a developer, I want to be able to connect to multiple external systems for the same binding type, so that I can read data from a system and write it to another.",5,3.5235977
XD-3566,TwitterStream test must use unique name to prevent test collision,XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.,3,2.2204843
XD-3567,Fix classpath and servlet container issues,"Several issues with 1.3.0.M1 staged version    - we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN    - we now have Guava 18.0 on classpath instead of 16.0.1    - xd-yarn push doesn't work, hadoop client for 2.7.1 needs Servlet API     - updating Hadoop to 2.7.1 instead of 2.6.0    -- this causes Curator to also update to 2.7.1 which throws exception on startup  ",3,1.9413786
XD-3568,AdminServer fails on HDP 2.3,"Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795    The xd-admin sysout is:    {code}  Started : AdminServerApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    02:51:36,624  ERROR main boot.SpringApplication - Application startup failed  java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer    org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)    org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)    org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)    org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)    org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)    org.springframework.boot.SpringApplication.run(SpringApplication.java:320)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)    org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)  Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type, name or annotation)    org.springframework.util.Assert.isTrue(Assert.java:68)    org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)    org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)    org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)  	... 17 more  02:51:36,628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context close  java.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015]; root of context hierarchy    org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)    org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)    org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)    org.springframework.boot.SpringApplication.run(SpringApplication.java:342)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)    org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)  02:51:36,642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer  {code}  ",3,2.4534833
XD-3569,ResourceModuleRegistry doesn't support HA namenode for hdfs custom module location,"As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA.     We had an issue filed in the `spring-xd-ambari` project:    ""It seems like custom module doesn't pickup namenode HA? and still use NameNodeProxies.createNonHAProxy?""    see: https://github.com/spring-projects/spring-xd-ambari/issues/14",3,3.4107723
XD-3570,Readme has conflicting CF information,"In https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/README.md#running-on-cloud-foundry the section starting 'Now we can configure the app' needs to be revised - the information is both out of date and, even if up-to-date, misleading (it includes some values as if they are universal, when they are really just examples).",1,2.873604
XD-3571,Port Cassandra as s-c-s sink,"As a Spring XD developer, I'd like to move {{cassandra}} module from XD to s-c-s repo, so I can use it as {{sink}} to build streaming pipeline.",5,3.4118102
XD-3572,Port analytic-pmml as s-c-s processor,"As a Spring XD developer, I'd like to port {{analytic-pmml}} module from XD to s-c-s repo, so I can use it as {{processor}} module to build streaming pipeline.",5,2.2976682
XD-3573,Include job-composition flag in REST endpoint,"As an XD user, I'd like to have a REST endpoint that returns job composition {{flag}}, so I can use it to differentiate visual representation between parent-child relationship and standalone jobs.  ",2,2.4010274
XD-3574,Include job-composition graph in REST endpoint,"As an XD user, I'd like to have a REST endpoint that returns job composition graph, so I can use it to build visual representation of parent-child relationship.   ",3,2.4193385
XD-3575,Add visual representation of job workflow in executions list page,"As an XD user, I'd like to be able to visually differentiate between job-composition workflow and single job.",5,2.4315364
XD-3576,Add support to retrieve job details ,"As an XD user, I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.",5,2.6503053
XD-3577,Compute progress information for job composition,"As an XD user, I'd like to see an aggregated progress bar for a job that is embeds multiple jobs within itself. ",3,2.9785402
XD-3578,Add support to restart job composition,"As an XD user, I'd like have support restart an existing composed job, so I could re-launch it at will.",1,3.082972
XD-3579,Spike: Explore integration options with Kafka 0.9 release,"As an s-c-d developer, I'd like to investigate integration options with the 0.9 release of Kafka, so I can identify areas of improvements. ",3,2.4727275
XD-3580,Spike: Explore options to setup bare-metal deployment of s-c-d using Lattice,"As a s-c-d developer, I'd like to explore options to bootstrap and setup Lattice based infrastructure for s-c-d's bare metal deployment.",5,2.6650624
XD-3581,Add support for Tuple and JSON SpEL property accessors in spring-cloud-stream,"As a spring-cloud-stream user, I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.",3,3.0308373
XD-3582,Add support for tab completion in shell,"As an s-c-d user, I'd like to have tab completion on shell, so I can interact with the modules and its available options.",8,1.796484
XD-3583,Implement Mesos SPI,"As an s-c-d user, I'd like to deploy s-c-d on Mesos.",2,3.6331377
XD-3584,Have consistent file format requirements in Spring XD and Hadoop,"When the following format is specified  -  {noformat}   home: file://hadoop/xd/custom-modules  {noformat}  There is no root-path ('/') following the 'file://' scheme. That makes the Hadoop job launcher interpret what follows as a host name and will look for '/xd/custom-modules' on the host 'hadoop'. This results in ""java.net.UnknownHostException: hadoop"".    This format works for module upload though. The module upload relies on resource location resolution from Spring Framework which is more lenient [1]. The MapReduce job submission uses code from the Apache Hadoop project and uses a more stringent resolution.     This results in ambiguity 'file://my/directory' and requires the root path to be specified.  [1] http://docs.spring.io/autorepo/docs/spring/4.2.x/spring-framework-reference/html/resources.html#resources-filesystemresource-caveats",2,2.0584671
XD-3585,Move Redis @Rule to a separate repo,"As an s-c-d developer, I'd like to move redis {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",1,2.2305346
XD-3586,Move Kafka @Rule to a separate repo,"As an s-c-d developer, I'd like to move kafka {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",1,2.4487665
XD-3587,Move Rabbit @Rule to a separate repo,"As an s-c-d developer, I'd like to move rabbit {{@Rule}} to a separate repo, so I can consume the test fixtures in different projects.",1,2.3949146
XD-3589,Create Composed Job Module ,"h2. Narrative  As an XD developer, I need to be able to create a composed job module as XML from the DSL an store it in the Module File repository.   While the user uses the composed job as if it is a normal job including seeing only the DSL.  In the background the JobFactory will deploy the composed job module.    * When the user destroys the job the module will be deleted from the file module repository.  * When the user creates the job a module will be created in the file Module repository.  h2. Back story  For the composed job story, we need to create a ""real"" job module to be expressed in XML, so that we can take advantage of the job execution tasklet in XD-3556, so that each job can be executed as a step in the composed job.",8,3.5075607
XD-3590,Fix datatype mismatch on admin-ui,"As a XD developer, I'd like to reproduce and fix anomalies as listed [here|https://github.com/spring-projects/spring-xd-admin-ui-client/issues/9].",1,2.6324315
XD-3591,Accessing Admin REST APIs on CF returns unexpected results,"As an s-c-d user, I'm trying to access {{admin}} REST endpoints running on CF but I'm getting SSL authentication errors.  ",1,2.9733052
XD-3592,Harmonize REST features between deployment profiles,"As an s-c-d user, I'd like to take advantage of admin running on variety of platforms such as Lattice, YARN or CF. I'd like to access REST APIs consistently across these platforms.",5,3.857402
XD-3593,Add support to register artifacts as libraries,"As a SCDF user, I want to be able to register artifacts as libraries, so that I can reference them in include and exclude statements.",2,2.2025938
XD-3594,Add support for named channels,"As an s-c-d user, I'd like to have the option to use _named channels_, so I can create streaming pipelines without source or sink modules. ",3,3.2722278
XD-3595,Add test coverage for StreamController,"As a s-c-d developer, I'd like to add test coverage for {{StreamController}}, so I can verify API contracts at build time. ",3,2.9315376
XD-3596,Prevent streams with duplicate name,"As a s-c-d user, I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time. ",1,3.1622093
XD-3597,Separate Lifecycle of Input and Output adapter endpoints,"Described in https://github.com/spring-cloud/spring-cloud-stream/issues/144    As a developer, I want Input enpoints to be started after all the beans in the context, so that received messages can be delivered to components.   ",3,3.6311767
XD-3598,Set Bean Name in ConsumerEndpointFactoryBean,{{LocalMessageBus}} and {{CompositeModule}}.,1,2.927472
XD-3599,Add Kinesis as s-c-s source,"As a s-c-s user, I'd like to use {{kinesis}} module, so I can use it as {{source}} module to build streaming pipeline.",2,1.3005061
XD-3600,Add Kinesis as s-c-s sink,"As a s-c-s user, I'd like to use {{kinesis}} module, so I can use it as {{sink}} module to build streaming pipeline.",2,3.5611594
XD-3601,JMX MBean name clash when using labels with s-c-d deployment,"We need to make sure that JMX MBean names are unique, even in the case of labeled modules.    The following stream fails for example: ""http | filter | filter2: filter | log""    A good candidate could be stream name (group) + module label.",3,5.3054485
XD-3602,Port Log as s-c-s sink,"As a developer, I'd like to port {{Log}} module from XD to s-c-s repo, so I can use it as {{sink}} modules to build streaming pipeline.",2,3.2507515
XD-3604,Container process id's still showing after shutting them down,"In my test case, I have security enabled. I tested this on distributed mode. I have a few Streams deployed.  * Started 3 XD containers.   * Issue *Shutdown* from UI  * The containers don't show up on the UI any more  * jps lists the process id of 2 ContainerServerApplication(there should be none listed)    I have noticed different test results every time, like at times 2 out of 3 containers are terminated and at times 1 out of 3 are terminated. Please let me know if you have issues replicating this.  ",2,2.7768114
XD-3605,Port field-value-counter as s-c-s sink,"As a developer, I'd like to port {{field-value-counter}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,3.1850398
XD-3606,Port aggregate-counter as s-c-s sink,"As a developer, I'd like to port {{aggregate-counter}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,3.534552
XD-3607,Port Gauge as s-c-s sink,"As a developer, I'd like to port {{gauge}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,3.3921757
XD-3608,Port rich-gauge as s-c-s sink,"As a developer, I'd like to port {{rich-gauge}} module from XD to s-c-s repo, so I can use it as {{sink}} module to build streaming pipeline.",2,3.6102335
XD-3609,Spike: Study integration operations with Flink,"As a data scientist, I'd like to have the option to process data using {{flink}} processor, so I can take advantage of the streaming machine learning abstractions implemented on top of Flink. ",5,3.0224419
XD-3610,Kafka source and sink headers shouldn't interfere with bus functionality,"The Kafka sink should not make use of the message headers sent by the Kafka receivers in the Kafka bus.     Similarly, the headers received from the Kafka source should not be propagated when sending to the Kakfa bus.     https://github.com/spring-projects/spring-xd/issues/1804",1,2.7325315
XD-3611,SqoopTasklet doesn't use keytab configuration from hadoop.properties file,"Hey Guys,    I have been using the sqoopTasklet for a while but I found an unexpected problem. Basically I'm not able to configure kerberos authentication from hadoop.properties file as follow:    <util:properties id=""hadoopProperties"" location=""${xd.config.home}/hadoop.properties"" />            <bean id=""sqoopTasklet"" class=""org.springframework.xd.sqoop.SqoopTasklet"">                  <property name=""arguments"">                          <list>                                  <value>import</value>                                  <value>--connect otheroptions</value>                          </list>                  </property>                  <property name=""hadoopProperties"" ref=""hadoopProperties"" />          </bean>    hadoop.properties file:    fs.defaultFS=hdfs://hdfshost:8020  yarn.resourcemanager.hostname=host001  yarn.resourcemanager.address=host001:8032  yarn.resourcemanager.scheduler.address=host001:8030  mapreduce.jobhistory.address=host003:10020  yarn.application.classpath=$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*  mapreduce.framework.name=yarn  spring.hadoop.security.authMethod=kerberos  spring.hadoop.security.userPrincipal=user1@COMPANY.COM  spring.hadoop.security.userKeytab=/home/user1/user1.keytab  spring.hadoop.security.namenodePrincipal=hdfs/_HOST@COMPANY.COM  spring.hadoop.security.rmManagerPrincipal=yarn/_HOST@COMPANY.COM  spring.hadoop.security.jobHistoryPrincipal=mapred/_HOST@COMPANY.COM    or     fs.defaultFS=hdfs://hdfshost:8020  yarn.resourcemanager.hostname=host001  yarn.resourcemanager.address=host001:8032  yarn.resourcemanager.scheduler.address=host001:8030  mapreduce.jobhistory.address=host003:10020  yarn.application.classpath=$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*  mapreduce.framework.name=yarn  security.authMethod=kerberos  security.userPrincipal=user1@COMPANY.COM  security.userKeytab=/home/user1/user1.keytab  security.namenodePrincipal=hdfs/_HOST@COMPANY.COM  security.rmManagerPrincipal=yarn/_HOST@COMPANY.COM  security.jobHistoryPrincipal=mapred/_HOST@COMPANY.COM    Running the job I'm getting the following error:    Encountered IOException running import job: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS    So it means the sqooptasklet isn't setting the kerberos authentication, this basically because in the SqoopTasklet class is adding some prefix to the configurations (SPRING_HADOOP_CONFIG_PREFIX)    https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/SqoopTasklet.java    Really doesn't make sense for me add those prefix and remove it later in the next call in the SqoopRunner class.     https://github.com/spring-projects/spring-xd/blob/master/extensions/spring-xd-extension-sqoop/src/main/java/org/springframework/xd/sqoop/SqoopRunner.java    If I inject  the security.* configurations directly to the list arguments it works.     I'm sure you guys have a good reason to add the prefix  but I don't see why. Unfortunately is  annoying when you are developing in a local VM where you can test the  simple authentication and after move the job to dev/prod environments with kerberos auth, the above because you must change your sqooptasklet configuration injecting the new parameters. If the SqoopTasklet allows inject those parameters directly from the hadoop.properties file you don't need change tasklet  configurations to run your jobs with different authentication methods.     Thanks in advance.   Héctor",1,2.1496325
XD-3612,Redis Message Bus still accessed when using direct binding,"I have a distributed XD Cluster with one admin and two containers using Redis as the message bus. In certain cases I want to use direct binding to remove communication with the message bus and deploy all modules to all containers with the aim of improving performance. I’ve found that even when using direct binding, XD still communicates with Redis when it shouldn’t need to. This could have an impact on performance.    This is easily reproducible in our 2 container cluster as follows:    Use the redis-cli monitor command to monitor Redis.    Create and deploy a simple stream with direct binding:    {code}  stream create --definition ""http | log"" --name httpLog  stream deploy --name httpLog --properties ""module.*.count=0""  {code}    As expected both modules get deployed to both nodes. Testing shows messages sent to the http endpoint of one container always come out in the log for that container implying direct binding is in play as expected.    However once the streams are deployed the Redis monitor starts showing a Redis queue being accessed from both XD conatiners:    {code}  1444731527.086325 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""  1444731528.086304 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""  1444731529.086341 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""  1444731530.086317 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""  1444731531.086340 [0 10.0.1.8:57454] ""brpop"" ""queue.httpLog.0"" ""1""  1444731532.086505 [0 10.0.1.4:37337] ""brpop"" ""queue.httpLog.0"" ""1""  {code}    This shouldn’t need to happen in direct binding. These messages stop once the stream is undeployed.  ",5,3.1180627
XD-3613,Multiple module instances consuming from taps or topics get duplicate messages on redis Message Bus,"If I deploy more than one instance of a module (eg using module.name.count > 1 or module.name.count =0) that consumes from a tap or topic then I get duplicate messages if I’m using Redis as the message bus. It looks like this is the same issue as XD-3100 but the fix for that only fixed Rabbit as the message bus.    This is easy to reproduce on a 2 container cluster using a Redis Message Bus:    Create and deploy streams as follows:    {code}  stream create --definition ""http | log"" --name httpLog  stream deploy --name httpLog --properties ""module.*.count=0""  stream create --definition ""tap:stream:httpLog > transform --expression='payload.toString() + \"" TAPPED\""' | log"" --name httpLogTap   stream deploy --name httpLogTap --properties ""module.*.count=0""  {code}    On container 1 send a message:    {code}  curl --data ""test message 001"" http://localhost:9000/httpLog  {code}    Container 1 logs are then:    {code}  2015-10-13 14:16:28.853  INFO 22774 --- [ol-28-thread-18] xd.sink.httpLog                          : test message 001  2015-10-13 14:16:28.855  INFO 22774 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  {code}    and container 2:    {code}  2015-10-13 14:16:28.859  INFO 22719 --- [enerContainer-4] xd.sink.httpLogTap                       : test message 001 TAPPED  {code}    Ie the tapped message is duplicated (picked up by both tap module instances)    Similarly for topics create and deploy these streams:    {code}  stream create --definition ""http > topic:mytopic"" --name httpTopic  stream deploy --name httpTopic --properties ""module.*.count=0""  stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 1\""' | log"" --name topicConsumer1  stream deploy --name topicConsumer1 --properties ""module.*.count=0""  stream create --definition ""topic:mytopic > transform --expression='payload.toString() + \"" TOPIC CONSUMER 2\""' | log"" --name topicConsumer2  stream deploy --name topicConsumer2 --properties ""module.*.count=0""  {code}    On container 1 send a message:    {code}  curl --data ""test message 002"" http://localhost:9000/httpLog  {code}    Container 1 logs are then:    {code}  2015-10-13 14:34:23.168  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2  2015-10-13 14:34:23.172  INFO 22774 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1  {code}    and container 2:    {code}  2015-10-13 14:34:23.173  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer2                   : test message 002 TOPIC CONSUMER 2  2015-10-13 14:34:23.177  INFO 22719 --- [enerContainer-2] xd.sink.topicConsumer1                   : test message 002 TOPIC CONSUMER 1  {code}    Ie the topic message is picked up by each instance of the module in each stream. In this case I would expect each stream to pick up the message once   ie I would get a single output for each stream     test message 002 TOPIC CONSUMER 2  once (on either container)  test message 002 TOPIC CONSUMER 1  once (on either container)",5,2.675664
XD-3614,Harmonize common deployer runtime properties applied to modules,"Most, if not all, of the deployers have some concept of customization of the deployed modules: be it memory, or cpu, disk, etc.    This ticket is about harmonizing the handling of such properties, with the assumption that we want a per-deployer set of defaults and overridability at deployment time.",3,3.4946318
XD-3615,"Modules/SCD Deployers: How to provide ""cloud connector"" support","Currently, s-c-s modules all come with baked in support for multiple cloud binding technologies:    {code:xml}  		<!-- Lattice core dependency that activates cloud,lattice profiles when running on Lattice -->  		<dependency>  			<groupId>org.springframework.cloud</groupId>  			<artifactId>spring-cloud-lattice-core</artifactId>  			<version>${spring-cloud-lattice.version}</version>  			<optional>true</optional>  		</dependency>  		<!-- Cloud connector dependencies -->  		<!-- Lattice connector dependency to create services info from lattice -->  		<dependency>  			<groupId>org.springframework.cloud</groupId>  			<artifactId>spring-cloud-lattice-connector</artifactId>  			<version>${spring-cloud-lattice.version}</version>  			<optional>true</optional>  		</dependency>  		<!-- CF connector dependency to create services info from CF -->  		<dependency>  			<groupId>org.springframework.cloud</groupId>  			<artifactId>spring-cloud-cloudfoundry-connector</artifactId>  			<optional>true</optional>  		</dependency>  		<!-- dependency to connect to detected cloud services -->  		<dependency>  			<groupId>org.springframework.cloud</groupId>  			<artifactId>spring-cloud-spring-service-connector</artifactId>  			<optional>true</optional>  		</dependency>  {code}    Should the deployers add those at runtime instead?",5,2.8486245
XD-3616,Add standardized way to pass props from Deployers/Admin to ModuleLauncher,"There is a need to customize the ModuleLauncher behavior (itself, NOT pass options to modules that are launched, which is already supported) for example to set the location of the maven repository.    ",3,2.5976138
XD-3617,Update build to use SHDP 2.3.0.RC1,,2,0.4097791
XD-3618,"Add ""runtime info"" shell command","As a s-c-d user, I'd like to have {{runtime info}} as shell command, so I can use this to list the details about the module such as {{host}}, {{port}} and the like.",5,1.9582372
XD-3619,Study YARN SPI gaps,"As a s-c-d user, I'd like to deploy data flow on YARN, so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.",2,3.9552016
XD-3620,JDBC connection pool errors,"We are seeing JDBC connection pool errors when running 'jdbchdfs' jobs and 'jdbc' streams. The exception is:    {code}  Caused by: java.sql.SQLException: Failed to validate a newly established connection.          at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)          at org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)          at org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)          at org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)          at org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:204)          ... 21 more  {code}    A workaround is to specify ""--testOnBorrow=false"" when creating the job.    This has also been reported on SO (http://stackoverflow.com/questions/33148929/springxd-issue-in-mysql-as-source-failed-to-validate-a-newly-established-connec).",5,3.25939
XD-3621,Add support for custom headers with the Kafka bus,"Currently, the Kafka Message Bus does not have the ability to configure a set of custom headers to persist in the `embeddedHeaders` mode (only the message-bus specific) message headers are persisted. ",3,4.310938
XD-3622,Port File as s-c-s source,"As a developer, I'd like to port {{file}} module from XD to s-c-s repo, so I can use it as {{source}} module to build streaming pipeline.",3,1.062883
XD-3623,Job in unknown state after run long sqooptasklet,"Hello guys,    I hope you are doing good. I found a problem when I try run long sqoop imports (4 hours or more). For some reason when the sqoop step finish the system is not able to save the meta data for the current sqoop step however the sqoop import finish without problems.    2015-10-17T03:04:03-0400 1.2.0.RELEASE ERROR SimpleAsyncTaskExecutor-4 step.AbstractStep - Encountered an error saving batch meta data for step import-logs in job ingestion-flow. This job is now in an unknown state and should not be restarted.    Please see attached log file for more details.   Could you please let me know if you need other details to find what is the problem?     Thanks in advance  Héctor    ",5,2.1957052
XD-3624,Add support to build Admin with individual SPI deployers,"As a s-c-d developer, I'd like to break the build lifecycle to bundle SPI deployers individually, so I don't have to build {{admin}} with all the deployer variations as one whole thing.",8,2.2816925
XD-3625,Move binder to SCS project,Move project out of https://github.com/pperalta/geode-scdf into https://github.com/spring-cloud/spring-cloud-stream,2,2.41373
XD-3626,Support partitioning properties,"Using these as a starting point, support the standard binder partitioning properties:    https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/BinderProperties.java#L69    https://github.com/spring-cloud/spring-cloud-stream/blob/master/spring-cloud-stream-binders/spring-cloud-stream-binder-spi/src/main/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupport.java#L663",5,2.9609115
XD-3627,Get rid of XDRuntimeException,"As a developer, I'd like to get rid off {{XDRuntimeException}} from XD.",1,3.0694435
XD-3628,Ambari plugin doesn't work with security_enabled,"It seems like springxd_shell will pull jhs principal and keytab from mapred-site.xml. When springxd_shell is installed in edge node, Amabri returns ""can't find jhs keytab"" and failed.    Details [here|https://github.com/spring-projects/spring-xd-ambari/issues/8].",1,2.7710218
XD-3629,Turning on HA via Ambari plugin requires custom configuration,"As a user, I'd like to enable HA on {{namenode}} without having to enable custom configuration.     More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].",3,2.6620064
XD-3630,Launch GF cache server for integration tests,The comments in [22|https://github.com/spring-cloud/spring-cloud-stream-modules/pull/22] indicate that we also need to run a gemfire cache server in order for the tests to pass. We should create an embedded cache server since it would be much easier not have to have an XD or gemfire install in order to test the sink.,5,3.2107112
XD-3631,Upgrade GF sink to 8.2,"As a user, I'd like to use the latest release of {{gemfire}} sink, so I can create a streaming pipeline to land data in gemfire. ",2,2.252001
XD-3633,Add SFTP source to default registry,"As a user, I'd like to use SFTP source module, so I can create streaming pipeline with it. However, I cannot see SFTP as OOTB module listed on: {{module list}} and as well as the module bits are not available in [maven repo|http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/]. ",1,3.534213
XD-3634,Allow support for authentication to maven repos (AetherModuleResolver),See discussion at https://github.com/spring-cloud/spring-cloud-stream/issues/159,3,2.2847867
XD-3635,Resolve remaining gaps with CI,"As a developer, I'd like to resolve remaining gaps wrt CI pipelines for Data Flow and the family, so I can continuously evaluate functionalities on every commit.",8,2.2206743
XD-3636,"Add support for global ""options"" in DSL","As a Flo user, I'd like to have {{timeout}} and {{pollInterval}} as global options at the DSL level, so I can override the defaults at will. ",1,3.1179042
XD-3637,Upgrade to SI 4.2.1,"As a developer, I'd like to upgrade to SI 4.2.1 release, so I can take advantage of the latest improvements.",1,1.7189786
XD-3638,Support Map Payloads in field-value-counter,"The {{FieldValueCounterHandler}} handles {{POJO}}, {{Tuple}}, and {{JSON}}.    {{#jsonPath}} emits a {{LinkedHashMap}}.    The handler should natively support a {{Map}}.    See http://stackoverflow.com/questions/33270926/springxds-field-value-counter-doesnt-work-after-splitting-json-object-array-in/33281783#33281783",1,1.9273397
XD-3639,Create bridge processor,"See https://github.com/spring-cloud/spring-cloud-dataflow/issues/128    This is needed to support ""channel > channel"" type constructs",2,3.601216
XD-3640,Library support changes at shell level,"Following merge of https://github.com/spring-cloud/spring-cloud-dataflow/commit/5cb81c49a240304be14bcf5d724cfd36df403d39, the following changes need to happen at shell/REST level:    {{module list}} should not show libraries  {{library list}} should be added to show libs  {{module register}} should not accept type=library  {{library register}} should be added  {{module info}} should not accept libs  {{library info}} should be added",5,2.4810948
XD-3641,Job composition improvements,"As a developer, I'd like to review and refactor {{JobLaunchingTasklet}}, so I can improve performance characteristics. ",3,3.9012485
XD-3642,Spring XD unable to save metadata for long steps,"Hey Guys,    We are facing an annoying problem and I can't figure out how solve it. For some reason when we run a step that takes long time (4 hours or more), spring XD is unable to save the metadata and throws the following error.     2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error executing step ingest-logs in job ingest-logs-flow  org.springframework.orm.jpa.JpaSystemException: commit failed; nested exception is org.hibernate.TransactionException: commit failed    org.springframework.orm.jpa.vendor.HibernateJpaDialect.convertHibernateAccessException(HibernateJpaDialect.java:244) ~[na:na]    org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:155) ~[na:na]    org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:521) ~[na:na]    org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:757) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:150) ~[spring-tx-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.step.tasklet.TaskletStep$2.doInChunkContext(TaskletStep.java:271) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.scope.context.StepContextRepeatCallback.doInIteration(StepContextRepeatCallback.java:77) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.getNextResult(RepeatTemplate.java:368) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.executeInternal(RepeatTemplate.java:215) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.repeat.support.RepeatTemplate.iterate(RepeatTemplate.java:144) ~[spring-batch-infrastructure-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:257) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127) [spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207) [spring-aop-4.1.6.RELEASE.jar:4.1.6.RELEASE]    com.sun.proxy.$Proxy53.run(Unknown Source) [na:na]    org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50) [spring-batch-integration-3.0.3.RELEASE.jar:3.0.3.RELEASE]    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:129) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330) [spring-expression-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:287) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:245) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95) [spring-messaging-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:231) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:154) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:102) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50) [spring-core-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292) [spring-integration-core-4.1.5.RELEASE.jar:na]    org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81) [spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_67]    java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_67]    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178) [na:1.7.0_67]    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292) [na:1.7.0_67]    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_67]    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_67]    java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]  Caused by: org.hibernate.TransactionException: commit failed    org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:187) ~[na:na]    org.hibernate.jpa.internal.TransactionImpl.commit(TransactionImpl.java:77) ~[na:na]    org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517) ~[na:na]  	... 97 common frames omitted  Caused by: org.hibernate.TransactionException: unable to commit against JDBC connection    org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:116) ~[na:na]    org.hibernate.engine.transaction.spi.AbstractTransactionImpl.commit(AbstractTransactionImpl.java:180) ~[na:na]  	... 99 common frames omitted  Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: Communications link failure during commit(). Transaction resolution unknown.    sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]    sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]    sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]    java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]    com.mysql.jdbc.Util.handleNewInstance(Util.java:389) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.Util.getInstance(Util.java:372) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:958) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:937) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:926) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.SQLError.createSQLException(SQLError.java:872) ~[mysql-connector-java-5.1.34.jar:5.1.34]    com.mysql.jdbc.ConnectionImpl.commit(ConnectionImpl.java:1616) ~[mysql-connector-java-5.1.34.jar:5.1.34]    org.apache.commons.dbcp.DelegatingConnection.commit(DelegatingConnection.java:301) ~[commons-dbcp-1.4.jar:1.4]    org.apache.commons.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.commit(PoolingDataSource.java:200) ~[commons-dbcp-1.4.jar:1.4]    org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.doCommit(JdbcTransaction.java:112) ~[na:na]  	... 100 common frames omitted  2015-10-25T09:49:10-0400 1.2.0.RELEASE ERROR task-scheduler-2 step.AbstractStep - Encountered an error saving batch meta data for step ingest-logs in job ingest-logs-flow. This job is now in an unknown state and should not be restarted.  org.springframework.dao.OptimisticLockingFailureException: Attempt to update step execution id=8 with wrong version (1), where current version is 2    org.springframework.batch.core.repository.dao.JdbcStepExecutionDao.updateStepExecution(JdbcStepExecutionDao.java:255) ~[spring-batch-core-3.0.3.RELEASE.jar:3.0.3.RELEASE]    We are using a MySQL database with the following configurations.     spring:    datasource:      url: jdbc:mysql://hosttomysql:3306/singnode      username: admin      password: admin      driverClassName: com.mysql.jdbc.Driver      validationQuery: select 1      testOnBorrow: true      If you guys know this issue or have some ideas how solve, please let me know. Thanks in advance.  Héctor",3,3.0051093
XD-3643,Allow sending to multiple named channels at once,"Currently it’s possible to do this via   {code}  source | router --expression=''queue:queue1,queue:queue2''  {code}  but this involves an additional hop to the message bus for the pipe between the source and router.    It would be better if this was supported directly with the existing named channel syntax to remove this pipe ie  {code}  source > queue:queue1,queue:queue2  {code}  This would be useful as a possible solution in the scenario described in XD-3613 as an alternative to using topics on the Redis message bus which don’t support having multiple instances of the same consumer.  ",5,1.9832845
XD-3644,Add test coverage for batch DSL and XML generation variants,"As a developer, I'd like to enhance test coverage to capture DSL and XML generation variants. ",5,3.0436478
XD-3645,Tuple unable to serialize objects with nested arrays of objects,"Serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. The error is:    {noformat}  Caused by: com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.springframework.xd.tuple.DefaultTupleConversionService and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: java.util.ArrayList[0]->org.springframework.xd.tuple.DefaultTuple[""values""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.xd.tuple.DefaultTuple[""conversionService""])    com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5]    com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5]    org.springframework.xd.tuple.TupleToJsonStringConverter.convert(TupleToJsonStringConverter.java:37) ~[spring-xd-tuple-1.3.0.M1.jar:1.3.0.M1]  {noformat}  when the input string (read from a Kafka topic in my case) looks something like:    {noformat}  {      ""body"": [          {              ""dataType"": ""har"",              ""har"": {                  ""log"": {                      ""browser"": {                          ""name"": ""Google Chrome"",                          ""version"": ""44.0.2403.155""                      },                      ""creator"": {                          ""name"": ""My extension"",                          ""version"": ""0.23.6""                      },                      ""pages"": [                          {                              ""_requestTimings"": {                                  ""blocked"": -1,                                  ""connect"": -1,                                  ""dns"": -1,                                  ""receive"": 11,                                  ""send"": -1,                                  ""ssl"": -1,                                  ""wait"": 244                              },                              ""_requestUrl"": ""https://google.com""                          },                          {                              ""_requestTimings"": {                                  ""blocked"": -1,                                  ""connect"": -1,                                  ""dns"": -1,                                  ""receive"": 11,                                  ""send"": -1,                                  ""ssl"": -1,                                  ""wait"": 244                              },                              ""_requestUrl"": ""https://google.com""                          }                      ],                      ""version"": ""1.2""                  }              },              ""testId"": 1          }      ],      ""bodyType"": ""models.MultiMessage"",      ""headers"": {          ""appInstance"": ""localhost/127.0.0.1:8080"",          ""clientIp"": ""0:0:0:0:0:0:0:1"",          ""host"": ""localhost:8080"",          ""requestId"": ""27acf948-33ff-491c-8be7-1beb4b8c95d9"",          ""requestMethod"": ""POST"",          ""requestUrl"": ""http://localhost:8080/har"",          ""timestamp"": 1445914510549,          ""userPrincipal"": ""235""      }  }  {noformat}  If the inner array (the Pages array) is just an object, it works, when it is an array, it fails.     The stream used:  kafka --topic=agent_mixed --outputType=application/x-xd-tuple | splitter --expression=payload.body | log",2,1.8112817
XD-3646,Composite Multiple Sink Module,"This would allow multiple individual sink modules to be combined via the shell DSL so that each message sent to the composite sink module will be sent to each of the individual sink modules in turn.   Internally this would probably use a recipient list router to send to each individual sink.    Module options for each individual sink would be combined to create the overall options for the composite sink module in a similar way to existing composite modules.    This would allow construction of streams with less communication with the message bus for example as an alternative to using a named topic in the message bus.    Using this in conjunction with sinks built using existing composite module functionality (as a combination of processors and a sink) would allow more sophisticated combinations to be constructed and deployed as a single module (with no message bus communication).    One particular application of this would be with tap and counter functionality. If multiple fields in a message need counted this currently needs to be done as separate streams tapping the original with the overhead of the tapped message being read from the message bus multiple times potentially on different nodes, this enhancement would allow all the counters to be combined to make a more cohesive composite counter module so that the tapped message would only need to be read once.  ",5,2.4763105
XD-3647,Update support for Hortonworks to HDP 2.3.2,We currently support HDP 2.3.0. The most recent HDP version is 2.3.2. This latest HDP release also changes Spark version to 1.4.1.,2,1.4703978
XD-3648,Job Executions without Deployed Job (deleted) shall not be restartable,,1,2.991565
XD-3649,Make SpEL usage consistent across all including custom modules,"As a user, I'd like to use SpEL expressions inline at the stream definition level, so I can operate on the payload consistently while using any OOTB, including the custom modules. ",8,4.0349894
XD-3651,The JsonStringToTupleConverter converts all values to String,As a module developer I would like the JsonStringToTupleConverter in the Spring Cloud Streams project to maintain the types provided in the JSON string and not convert everything to a String representation.,1,2.3446736
XD-3652,The shell processor module cannot be stopped while blocked in receive(),"Both lifecycle and send/receive methods are synchronized, so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script, the stop() method can't acquire the object lock and proceed stopping the instance, and therefore the module. ",5,2.6431327
XD-3653,Admin UI does not load on master build,"As a user, I cannot use {{admin-ui}} on the master build. It won't come up. ",2,2.0402787
XD-3654,Documentation: Flo for XD Batch,"As a user, I'd like to refer to 'job orchestration' documentation, so I can use it as guideline for building batch workflows.  ",3,4.170612
XD-3655,Document admin-ui improvements,,1,3.1600232
XD-3656,Add 'undeployed' status for YARN SPI,"As a developer, I'd like to add {{undeployed}} status for YARN SPI, so I can represent the correct status instead of the current {{unknown}} state.",3,4.057247
XD-3657,Unable to find an option for restart Sqoop Job automatically when it is failed,"I am able to run a Sqoop Job to copy data from oracle to Hadoop and I can relaunch the job manually through shell command or admin UI. But I don't see option to set some number or auto retry option, so that when ever failure happens, system will automatically retry some number of times that we specify.",5,2.4780762
XD-3658,"Validator interface doesn't contains any Job details like ID, name etc","org.apache.sqoop.validation.Validator interface doesn't contain any job information and it has only ValidationContext object reference. I am trying to write custom class that implements Validator class and trying to store the source count and destination count into data base. But I need some reference about Job like job ID, name, start time, end time etc. I think we can have org.apache.hadoop.mapreduce.Job instance or any other reference to the Job would help.",3,2.172696
XD-3659,Create admin artifact for each Hadoop distro,"As a developer, I'd like to split {{admin}} artifact packaged with hadoop distro specific libraries, so I could avoid adding all variations of hadoop libraries under one project. ",5,2.9307258
XD-3660,Create admin artifact and CI build for YARN,"As a developer, I'd like to create separate repo for YARN SPI, so I don't have to bundle all SPI variants under one admin project.",5,3.8274553
XD-3661,Upgrade to Lattice 0.6.0 release,"As a developer, I'd like to upgrade to {{0.6.0}} release of Lattice, so I can demonstrate data flow on the latest Lattice improvements. ",5,1.7995656
XD-3662,UI: Replace XD with Data Flow,"As a developer, I'd like to replace all references of Spring XD with Spring Cloud Data Flow. ",2,3.5636063
XD-3663,UI: Job modules page wouldn't load,"As a user, I'm trying to load Job - Modules page in admin-ui, but I'm seeing exceptions in console and the page wouldn't load.     {code}  Failed to convert value of type 'java.lang.String' to required type 'org.springframework.cloud.dataflow.core.ArtifactType'; nested exception is org.springframework.core.convert.ConversionFailedException: Failed to convert from type java.lang.String to type @org.springframework.web.bind.annotation.RequestParam org.springframework.cloud.dataflow.core.ArtifactType for value 'job'; nested exception is java.lang.IllegalArgumentException: No enum constant org.springframework.cloud.dataflow.core.ArtifactType.job  {code}",2,3.565558
XD-3664,UI: Replace Job references with Task,"As a developer, I'd like to replace all {{Job(s)}} references with {{Task(s)}}. ",2,3.498173
XD-3665,UI: Task deployment page is not loading,"As a user, I'm trying to load Task, Task Deployment, and Task Executions page, but I'm seeing an error {{(Error fetching data. Is the XD server running?)}} instead. ",1,2.9754896
XD-3666,UI: [Spike] Study PUI theming scope,"As a user, I'd like to use the admin-ui and flo with consistent look and feel. ",1,1.8747599
XD-3667,CF SPI REST calls are not working ,"As a developer, I'd like to troubleshoot and fix {{root}} level access over CF SPI REST calls; they're broke at the moment.     Access for following calls fail:    {code}    href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/streams""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/tasks""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/metrics/counters/{name}"",  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/modules""  href: ""https://s-c-dataflow-admin.cfapps.pez.pivotal.io:80/completions/stream{?start,detailLevel}"",  {code}",1,3.078779
XD-3668,UI: Add SPI type and version to about section,"As a user, I'd like to see the version and SPI type in the `about` section, so I can confirm which build of {{admin-ui}} I'm currently using. ",1,3.0053296
XD-3669,Add Flo screenshots to Batch DSL section,"As a user, I'd like Flo Graphs as screenshots while referring to the batch DSL, so it will be easy for me to relate to concepts. ",1,3.5370543
XD-3670,Spike: Revisit the core design and document gaps,"As a developer, I'd like to revisit the existing design and identify known limitations and/or the gaps. ",5,2.8806412
XD-3671,Spike: Explore options to scale modules from shell,"As a user, I'd like to have direct shell commands to scale up/down a given module instance, so I can avoid SPI specific CLI commands that needs run outside of data flow.",5,1.700344
XD-3672,Move Mesos SPI to a separate repo,"As a developer, I'd like to submit a PR for existing work on Mesos SPI. ",2,2.5073595
XD-3673,Multiple module instances produces duplicate messages ,"As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629], we would want to fix this experience for Kafka message bus.",5,3.1634889
XD-3674,Create admin artifact and CI build for CF,"As a developer, I'd like to create separate repo for CF SPI, so I don't have to bundle all SPI variants under one admin project.",3,3.826527
XD-3675,Create admin artifact and CI build for Lattice,"As a developer, I'd like to create separate repo for Lattice SPI, so I don't have to bundle all SPI variants under one admin project.",3,2.893124
XD-3676,Create admin artifact and CI build for K8s,"As a developer, I'd like to create separate repo for K8s SPI, so I don't have to bundle all SPI variants under one admin project.  ",3,2.893124
XD-3677,Create admin artifact and CI build for Mesos,"As a developer, I'd like to create separate repo for Mesos SPI, so I don't have to bundle all SPI variants under one admin project.  ",3,3.034069
XD-3678,Add 'undeployed' status for CF SPI,"As a developer, I'd like to add {{undeployed}} status for CF SPI, so I can represent the correct status instead of the current {{unknown}} state.",3,4.067341
XD-3679,Add 'undeployed' status for Lattice SPI,"As a developer, I'd like to add {{undeployed}} status for Lattice SPI, so I can represent the correct status instead of the current {{unknown}} state.",3,3.9281309
XD-3680,"Add consistent support for ""undeployed"" state across the deployers","As a developer, I'd like to add support for {{undeployed}} status consistently across all the deployers, so I can present the correct status instead of the current {{unknown}}. This is applicable for existing streams without any deployment context associated with it. ",1,2.0358272
XD-3681,Add 'undeployed' status for k8s SPI,"As a developer, I'd like to add {{undeployed}} status for k8s SPI, so I can represent the correct status instead of the current {{unknown}} state.",1,3.9281309
XD-3682,Add 'undeployed' status for Mesos SPI,"As a developer, I'd like to add {{undeployed}} status for Mesos SPI, so I can represent the correct status instead of the current {{unknown}} state.",3,4.028616
XD-3683,Fix composed job error message,"As a user, I'm trying to compose a job just with one definition; however, I'm getting the following error message, which could be misinterpreted.    {code}  xd:>job create salsa --definition timestampfile  Successfully created job 'salsa'  xd:>job create foo --definition ""salsa || salsa""  Successfully created job 'foo'  xd:>job create foo222 --definition ""salsa""  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'salsa' and type 'job'  {code}",1,2.4591694
XD-3684,Job composition fails for large transitions,"As a user, I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.",3,2.1578293
XD-3685,Job Definitions page fails to display definitions if page ,In this scenario we created 30 jobs that can be used for a composed job.    if the composed job uses jobs in its composition that are not present on the first page of the of the result set the following exception is thrown.      {noformat}  2015-11-02T14:47:17-0500 1.3.0.SNAP ERROR qtp1587928736-26 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at: fff    org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:244) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]    org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:209) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]    org.springframework.xd.dirt.rest.JobsController.list(JobsController.java:128) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]    sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source) ~[na:na]    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]    java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]    org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    javax.servlet.http.HttpServlet.service(HttpServlet.java:735) [javax.servlet-3.0.0.v201112011016.jar:na]    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]    javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]    org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]    org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]    java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]  {noformat},3,1.9090263
XD-3686,log4j/log4j-over-slf4j logging issue,"I got below error when executing modules on yarn and it was written in appmaster stderr output.  {code}  Exception in thread ""Thread-2"" java.lang.NoClassDefFoundError: org/apache/log4j/spi/ThrowableInformation          at org.apache.log4j.spi.LoggingEvent.<init>(LoggingEvent.java:165)          at org.apache.log4j.Category.forcedLog(Category.java:391)          at org.apache.log4j.Category.log(Category.java:856)          at org.slf4j.impl.Log4jLoggerAdapter.log(Log4jLoggerAdapter.java:595)          at org.apache.commons.logging.impl.SLF4JLocationAwareLog.warn(SLF4JLocationAwareLog.java:192)          at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:969)          at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.doClose(EmbeddedWebApplicationContext.java:150)          at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:893)  {code}    `LoggingEvent` is found from both `log4j-over-slf4j-1.7.12.jar` and `log4j-1.2.17.jar`. I suppose it depends on which one is used first to load this class.    Here's what we have in admin and appmaster jar files(spring-cloud-dataflow-yarn-build-tests is my local new sub-project to run tests on a hadoop minicluster):  {code}  unzip -l target/spring-cloud-dataflow-yarn-build-tests/spring-cloud-dataflow-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar|grep jar|grep -i log      62050  2013-05-16 22:04   lib/commons-logging-1.1.3.jar     489884  2012-05-06 13:24   lib/log4j-1.2.17.jar       8860  2015-03-26 21:56   lib/slf4j-log4j12-1.7.12.jar       2234  2015-09-03 16:30   lib/spring-boot-starter-logging-1.3.0.M5.jar      24567  2015-03-26 21:57   lib/log4j-over-slf4j-1.7.12.jar      40824  2015-08-18 12:39   lib/tomcat-embed-logging-juli-8.0.26.jar      66802  2015-05-28 09:49   lib/jboss-logging-3.3.0.Final.jar  {code}    {code}  unzip -l spring-cloud-dataflow-admin/target/spring-cloud-dataflow-admin-1.0.0.BUILD-SNAPSHOT.jar |grep jar|grep -i log      62050  2013-05-16 22:04   lib/commons-logging-1.1.3.jar     489884  2012-05-06 13:24   lib/log4j-1.2.17.jar      40824  2015-08-18 12:39   lib/tomcat-embed-logging-juli-8.0.26.jar      66802  2015-05-28 09:49   lib/jboss-logging-3.3.0.Final.jar       2234  2015-09-03 16:30   lib/spring-boot-starter-logging-1.3.0.M5.jar     280928  2015-03-24 12:06   lib/logback-classic-1.1.3.jar     455041  2015-03-24 12:05   lib/logback-core-1.1.3.jar      24567  2015-03-26 21:57   lib/log4j-over-slf4j-1.7.12.jar  {code}    Error went away when I removed `log4j-over-slf4j-1.7.12.jar` from maven deps for yarn appmaster jar. I suppose we have same issue with admin server.  ",1,2.8299541
XD-3687,Update Docs to add configs changes for Composed jobs,Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:  1) uncomment and change the following from  :  ```spring:    batch:  # Configure other Spring Batch repository values.  Most are typically not needed      isolationLevel: ISOLATION_SERIALIZATION  ```  to  ```spring:    batch:  # Configure other Spring Batch repository values.  Most are typically not needed      isolationLevel: ISOLATION_READ_COMMITTED  ```    And update the hsqldb datasource to:  spring:    datasource:      url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc,1,1.3729175
XD-3688,Rabbit Binder Cleaner REST API,"As a developer, I'd like to be able to clean Rabbit binder broker artifacts using the REST API.    When the Rabbit Bus was ported from XD, the bus cleaner was ported as {{RabbitBindingCleaner}} but the REST API to invoke it was not ported over.",2,3.8932018
XD-3689,Update default configs to support Composed Jobs,Users want the ability to use Composed Jobs (specifically parallel Jobs) without having to update the configurations for the hsqldb and the Isolation Level for spring batch.  These should be set by default.  ,3,1.9920132
XD-3690,"Improve ""Server Configuration - Database Configuration"" section",Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653,1,2.7897215
XD-3691,Ensure Job definitions are escaped in UI,"If using the definition <aaa || bbb> where the definition starts with a ""<"" and ends with a "">"" the definition for the composed job does not appear on the definition page.",2,3.8154488
XD-3692,Optimize YARN deployer,"As a developer, I'd like to optimize YARN deployer, so I can deploy stream and the modules part of the definition rapidly.",5,3.3141654
XD-3693,Add Timestamp to XD Message History,I don't recall why [this commit | https://github.com/garyrussell/spring-xd/commit/ba15a1390f7e448dbc723ee76a45c2e239e0994e] was not applied to master but having the timestamp for each step in the history will be useful.    See [this github issue | https://github.com/spring-projects/spring-xd-modules/issues/24#issuecomment-154436643].  ,1,3.2050352
XD-3694,Remove unnecessary SI EvalCtx injection in modules,"With the inclusion of https://github.com/spring-cloud/spring-cloud-stream/commit/80b1d28be1c8b9a23099b145fe2dcf472bfa9697, any module that explicitly injected/looked up the SI EC don't need to do so anymore.    This issue is about simplifying those",1,3.2900963
XD-3695,Upgrade to SHDP 2.2.1.GA,"As a developer, I'd like to upgrade to 2.2.1 GA release, so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.",1,0.25415772
XD-3696,Upgrade to SI 4.2.2.GA,"As a developer, I'd like to upgrade to SI 4.2.2.GA release, so I can leverage the latest improvements.",1,0.31716758
XD-3697,Output modules cannot use minPartitionCount when sending to named channels,"If the output module is connected to a named channel, cannot be set up the property minPartitionCount, it is giving an exception.    Streams:  stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log""   stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log""  stream deploy --name f --properties ""module.transform.count=2""  stream deploy --name b --properties ""module.transform.count=2""    stream create r --definition ""time | router --expression=payload.contains('10')?'queue:foo':'queue:bar'""  stream deploy --name r --properties ""module.router.producer.minPartitionCount=20""    The error is:  Caused by: java.lang.IllegalArgumentException: KafkaMessageBus does not support producer property: minPartitionCount for queue:bar.  at org.springframework.xd.dirt.integration.bus.MessageBusSupport.validateProperties(MessageBusSupport.java:781) ~[spring-xd-messagebus-spi-1.2.1.RELEASE.jar:1.2.1.RELEASE]",1,2.6701398
XD-3698,Execution list page includes child jobs in pagination scope,"As a user, I created a composed job with over 10 child jobs in the workflow; I expected to see 'a' job in the execution list page without any pagination, but instead I noticed empty pagination to skip to next page.",1,2.0202613
XD-3699,Remove hardcoded buildpack commit reference,"As a developer, I'd like to remove the hardcoded buildpack reference since the latest 1.6.2 ER release includes all the features required by Data Flow. ",1,2.327555
XD-3700,Stream deployment validation,"In our system we have built quite a few custom modules. It is currently possible for the end user to mess up the configuration of these custom modules when creating multiple streams. They can create conflicting configuration in multiple streams. The conflicting config is nothing to do with spring-xd itself, it is related to our data flow and business process.    It would be nice to have some sort of StreamDeployValidator that I could implement and write my custom validation code. If this decides that the stream definition is not valid (according to my rules) then it could stop the deployment of a stream. The validator would need to be aware of the other streams somehow.    ",20,3.1461911
XD-3701,Improve Shell Connection Diagnostics,"When a problem occurs connecting to admin, we just get {{Unable to contact Data Flow Admin}} even if the connection is successful and some problem occurs when interpreting the result.    The exception is eaten.    Log an error including the exception.    Currently investigating an NPE in DataFlowTemplate @ line 77.",1,4.208001
XD-3702,Support partitioning for Kafka even if count == 1,"As a developer, I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module, so that I can take advantage of the native Kafka partitioning and message ordering support.",3,2.379676
XD-3703,Add SSL and attachments to mail sink,Add SSL and attachments to Mail sink module. see XD-2076 & XD-2498.  ,3,3.7312405
XD-3704,Gemfire modules fail to deploy when SSL enabled,"See the attatched log (xd.out) showing :  {{  Caused by: java.lang.IllegalStateException: A connection to a distributed system already exists in this VM.  It has the following configuration:    ack-severe-alert-threshold=""0""    ack-wait-threshold=""15""    archive-disk-space-limit=""0""    archive-file-size-limit=""0""    async-distribution-timeout=""0""    async-max-queue-size=""8""    async-queue-timeout=""60000""    bind-address=""""    cache-xml-file=""cache.xml""    cluster-ssl-ciphers=""any""    cluster-ssl-enabled=""true""    cluster-ssl-keystore=""/Users/dturanski/trusted.keystore""    cluster-ssl-keystore-password=""password""    cluster-ssl-keystore-type=""jks""    cluster-ssl-protocols=""any""    cluster-ssl-require-authentication=""true""    cluster-ssl-truststore=""/Users/dturanski/trusted.keystore""    cluster-ssl-truststore-password=""password""  ...  }}    Steps to reproduce:    Refer to: http://gemfire.docs.pivotal.io/latest/managing/security/ssl_example.html    1) Install the the attached keystore  2) Install attached gemfire.properties in $XD_INSTALL/xd/config  3) Install a copy of gemfire.properties in the server path,  e.g., if using the gemfire server app installed with the distribution,  $XD_INSTALL/gemfire,  and run bin/gemfire  4) Start the gemfire server  5) Start xd singlenode  6) Start the shell and deploy a stream using a gemfire module (this was reported with gemfire-json-server sink, but in theory it will affect any since it occurs during client cache creation).     Note: I verified this SSL configuration works with a simple SDG client against the XD server. (Use SDG 1.6.2, and gemfire 8.0.0).  Also, the gemfire-json-server example in the XD reference works as expected without the SSL configuration.     This may to be related to the module using a its own class loader. `java.lang.IllegalStateException: A connection to a distributed system already exists in this VM` happens because there are 2 instances of DistributedSystem created (one for each class loader?). This happens even when all the module jars are moved to xd/lib to force all gemfire classes to be loaded in the parent class loader.     ",8,2.7080145
XD-3705,Bump Boot and spring-cloud-build Versions,"As a developer, I'd like to upgrade Boot and Spring Cloud Build revisions, so I can leverage the latest updates.",5,2.816061
XD-3706,Counter sink does not accept SpEL expressions,"As a user, I'm trying to use {{counter}} sink with {SpEL}} expression, but I'm not able to use them in combination. It [throws|https://github.com/spring-cloud/spring-cloud-stream-modules/blob/master/counter-sink/src/main/java/org/springframework/cloud/stream/module/metrics/CounterSinkProperties.java#L77] {{exactly one of 'name' and 'nameExpression' must be set}} as error message.    ",1,3.4469612
XD-3707,Job definitions request limits 20 results by default,"As a user, I'm trying to get all job definitions, but the first 20 alone are returned.    Job samples:  {code}  job create aaa --definition ""hello"" --deploy  job create bbb --definition ""hello"" --deploy  job create ccc --definition ""hello"" --deploy  job create ddd --definition ""hello"" --deploy  job create eee --definition ""hello"" --deploy  job create fff --definition ""hello"" --deploy  job create ggg --definition ""hello"" --deploy  job create hhh --definition ""hello"" --deploy  job create iii --definition ""hello"" --deploy  job create jjj --definition ""hello"" --deploy  job create kkk --definition ""hello"" --deploy  job create lll --definition ""hello"" --deploy  job create mmm --definition ""hello"" --deploy  job create nnn --definition ""hello"" --deploy  job create ooo --definition ""hello"" --deploy  job create ppp --definition ""hello"" --deploy  job create qqq --definition ""hello"" --deploy  job create rrr --definition ""hello"" --deploy  job create sss --definition ""hello"" --deploy  job create ttt --definition ""hello"" --deploy  job create uuu --definition ""hello"" --deploy  job create vvv --definition ""hello"" --deploy  job create www --definition ""hello"" --deploy  job create xxx --definition ""hello"" --deploy  job create yyy --definition ""hello"" --deploy  job create zzz --definition ""hello"" --deploy  job create aaa1 --definition ""hello"" --deploy  job create bbb1 --definition ""hello"" --deploy  job create ccc1 --definition ""hello"" --deploy  job create ddd1 --definition ""hello"" --deploy  job create eee1 --definition ""hello"" --deploy  {code}    Request:  {{http://localhost:9393/jobs/definitions.json}} - returns top 20; the other experiments with page size of either 0 or -1 still brings the top 20.",1,2.3971317
XD-3708,Document limitations with HSQL when using composed jobs,"As a developer, I'd want to document the limitations of HSQL DB when using composed jobs. ",1,2.008725
XD-3709,Duplicate MBean Names With router Sink,"For some reason, the Integration {{MBeanExporterHelper}} is not preventing the standard context {{MBeanExporter}} from exporting the {{AbstractMessageRouter}}. This should be suppressed (when an IMBE is present) because it's annotated {{@IntegrationManagedResource}}.    Causes {{InstanceAlreadyExistsException}}.    Workaround in the stack overflow answer.    http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0    Could be an SI issue, but investigation needed. However, we should probably include the stream/job name in all MBeans for the stream (as is done for the integration exporter).",1,3.9638839
XD-3710,Facing issue while running Spring XD batch job on HDP version 2.3.2.0-2950,"***Version  	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn  	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64   	Java Version: java version ""1.7.0_65""    ***Description  	The simple word count map reduce job using spring xd is failing with inline error message.    ***Steps to recreate the problem  	1. Created a jar for simple word count map reduce job.  	2. Created jar using information given in ( http://docs.spring.io/spring-hadoop/docs/2.0.2.RELEASE/reference/html/hadoop.html#hadoop:tasklet )  	3. Once the final jar was ready, uploaded using ""module upload --name test_mr_module --type job --file /home/user/jar/samplemrjob.jar""  	4. After that created and deployed job using ""job create --name test_mr_job --definition test_mr_module --deploy""  	5. Finally launched using ""job launch test_mr_job"" which failed with inline error.    ***Describe XD Deployment : Distributed     Deployment Type : Distributed - YARN ( on AWS EC2 cloud )  Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers       ***Describe Other Components    Transport: Redis 3.0.1  ZooKeeper: Version 3.4.6.2.3.2.0-2950      Hadoop deployment  Data Platform : Hortonworks HDP 2.3.2.0-2950  RDBMS: MySQL       ***Error Message:     *****************************************************  05:29:52,673   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'test_mr_job'  05:29:53,655   INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@6e5af900 moduleName = 'test_mr_module', moduleLabel = 'test_mr_module', group = 'test_mr_job', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]  05:30:24,351  ERROR inbound.job:test_mr_job-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step teststep in job test_mr_job  java.lang.IllegalArgumentException: Unable to parse '/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework' as a URI, check the setting for mapreduce.application.framework.path          at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:443)   	.  	.	  	.          at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:54)          at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:323)          at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)          at java.lang.Thread.run(Thread.java:745)  Caused by: java.net.URISyntaxException: Illegal character in path at index 11: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework          at java.net.URI$Parser.fail(URI.java:2848)          at java.net.URI$Parser.checkChars(URI.java:3021)          at java.net.URI$Parser.parseHierarchical(URI.java:3105)          at java.net.URI$Parser.parse(URI.java:3063)          at java.net.URI.<init>(URI.java:588)          at org.apache.hadoop.mapreduce.JobSubmitter.addMRFrameworkToDistributedCache(JobSubmitter.java:441)  *****************************************************",8,1.8720447
XD-3711,XD  / Zookeeper connection lost.,"XD container loose connection with Zookeeper.    I'm in a distributed environnement:  - 3 XD container nodes (1.2.1)  - 1 XD admin  - 3 Zookeeper  - 3 RabbitMQ  - 3 Redis/Sentinel    Logs:    *zookeeper.log*  {noformat}  2015-11-25 06:53:07,235 [myid:3] - INFO  [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:ZooKeeperServer@617] - Established session 0x251250651910006 with negotiated timeout 40000 for client /172.20.1.9:58070  2015-11-25 06:54:08,525 [myid:3] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@357] - caught end of stream exception  EndOfStreamException: Unable to read additional data from client sessionid 0x251250651910006, likely client has closed socket          at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)          at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)          at java.lang.Thread.run(Thread.java:745)  2015-11-25 06:54:08,621 [myid:3] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1007] - Closed socket connection for client /172.20.1.9:58070 which had sessionid 0x251250651910006  {noformat}    *container.log*  {noformat}  2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR main-EventThread curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (34187)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.getZooKeeper(CuratorFrameworkImpl.java:474) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) [curator-framework-2.6.0.jar:na]          at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) [curator-framework-2.6.0.jar:na]          at org.springframework.xd.dirt.server.container.DeploymentListener$StreamModuleWatcher.process(DeploymentListener.java:596) [spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67) [curator-framework-2.6.0.jar:na]          at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) [zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) [zookeeper-3.4.6.jar:3.4.6-1569965]  2015-11-25T06:53:37+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (34189)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]          at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]  2015-11-25T06:53:39+0100 1.2.1.RELEASE ERROR CuratorFramework-0 curator.ConnectionState - Connection timed out for connection string (172.20.1.1:2181,172.20.1.8:2181,172.20.1.9:2181) and timeout (30000) / elapsed (36191)  org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss          at org.apache.curator.ConnectionState.checkTimeouts(ConnectionState.java:198) [curator-client-2.6.0.jar:na]          at org.apache.curator.ConnectionState.getZooKeeper(ConnectionState.java:88) [curator-client-2.6.0.jar:na]          at org.apache.curator.CuratorZookeeperClient.getZooKeeper(CuratorZookeeperClient.java:115) [curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:793) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:779) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$400(CuratorFrameworkImpl.java:58) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:265) [curator-framework-2.6.0.jar:na]  [...]  2015-11-25T06:54:34+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 26 seconds)...  2015-11-25T06:55:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 57 seconds)...  2015-11-25T06:56:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 117 seconds)...  2015-11-25T06:57:05+0100 1.2.1.RELEASE INFO ConnectionStateManager-0 container.ContainerRegistrar - Waiting for supervisor to clean up prior deployments (elapsed time 177 seconds)...  {noformat}    *admin.log*  {noformat}  2015-11-25T06:54:23+0100 1.2.1.RELEASE ERROR DeploymentSupervisor-0 cache.PathChildrenCache -  org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/b1de9530-1837-42c0-a6bc-840b1b15aefc/JOB_TRIGGER.source.trigger.1          at org.apache.zookeeper.KeeperException.create(KeeperException.java:111) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.KeeperException.create(KeeperException.java:51) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155) ~[zookeeper-3.4.6.jar:3.4.6-1569965]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107) ~[curator-client-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279) ~[curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41) ~[curator-framework-2.6.0.jar:na]          at org.springframework.xd.dirt.server.admin.deployment.zk.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:116) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.springframework.xd.dirt.server.admin.deployment.zk.ContainerListener.childEvent(ContainerListener.java:140) ~[spring-xd-dirt-1.2.1.RELEASE.jar:1.2.1.RELEASE]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]          at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]          at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]          at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_60]          at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_60]          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_60]          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_60]          at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]  {noformat}    If a module is deployed on the node which has lost the connection, it's not redeployed on one of the two others.    The only difference between node, is that the node in error has less memory.    When this occurs, node doesn't appear anymore on the admin ui. And deployed streams do not appear as incomplete, but they should if a node has disappear and deployment property _module.*.count_ is set to the number of nodes.    Thanks.    Mickaël",5,3.3328779
XD-3712,spring xd  supported active/standby mode?,XD spring deployment capabilities are supported by the active/standby?    example:  module.log.criteria=groups.contains('group1')    Above example is random selection? ,1,3.1609652
XD-3713,The batch-hashtag-count example from spring-xd-samples is giving java.lang.ClassNotFoundException Exception,"***Version  	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn  	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64   	Java Version: java version ""1.7.0_65""    ***Description  	The batch-hashtag-count example from spring-xd-samples ran using spring xd is failing with inline error message.    ***Steps to recreate the problem  	1. Followed steps present in README.asciidoc present at the Git repository link given below   		https://github.com/spring-projects/spring-xd-samples/tree/master/batch-hashtag-count  	    	    ***Describe XD Deployment : Distributed     Deployment Type : Distributed - YARN ( on AWS EC2 cloud )  Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers       ***Describe Other Components    Transport: Redis 3.0.1  ZooKeeper: Version 3.4.6.2.3.2.0-2950      Hadoop deployment  Data Platform : Hortonworks HDP 2.3.2.0-2950  RDBMS: MySQL       ***Error Message:     *****************************************************  2015-11-23 17:56:16,527 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.lang.ClassNotFoundException: Class or  g.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found          at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)          at org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)          at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:745)          at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)          at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)          at java.security.AccessController.doPrivileged(Native Method)          at javax.security.auth.Subject.doAs(Subject.java:422)          at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)          at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)  Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not found          at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)          at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)          ... 8 more  *****************************************************",5,2.029261
XD-3714,Upgrade XD Ambari release to 1.3 ,"As a developer, I'd like to upgrade Spring XD's ambari plugin to 1.3 release.",3,2.1889207
XD-3715,Move k8s SPI to a separate repo,"As a developer, I'd like to move k8s SPI to it's own repo.",5,2.4971857
XD-3716,Support Configuring the RabbitMessageBus MessagePropertiesConverter LongString Limit,http://stackoverflow.com/questions/34053997/passing-headerinformation-as-jsonobject-in-header-in-spring-xd,2,2.1545742
XD-3717,Improvement to SpringXDTemplate to enable getting executions for a specific job,I would like to be able to use the SpringXDTemplate to find all executions for a specific job    Currently I use xdTemplate.jobOperations().listJobExecutions() then loop through all executions filtering the ones for the job I'm interested in.    It would be nice if JobOperations had something like this    {code:java}  /**   * List all Job Executions.   * @param jobInstanceId The instance of the job to get all executions for.   */  public PagedResources<JobExecutionInfoResource> listJobExecutions(long jobInstanceId);  {code},5,3.0779626
XD-3718,Kafka message bus must accept partitioning properties for named queues,"As a user, I want to be able to provide the partitioning logic for a named destination, so that I can control the ordering of outbound messages.",1,3.6930492
XD-3719,Spring flo issue with unexpected char,In Flo when creating a stream if you use asterisk you get an error. See the image attached.,2,3.1143985
XD-3720,Custom job with RabbitMq dependencies ,"Hi,    I've develop a custom Job which have to publish message on RabbitMq when it's finished.    To develop this module, I'veto include this libraries:  * com.rabbitmq:amqp-client:jar  * org.springframework.amqp:spring-rabbit:jar  * org.springframework.amqp:spring-amqp:jar    My job use this writer: org.springframework.batch.item.amqp.AmqpItemWriter    I've this error log:  {noformat}   support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]  {noformat}    This is typically due to a library loaded several times.    What is the solution to resolve this?    I'd like to use the same libraries has RabbitMq Source/Sink or the transport bus.    Does module classloader isolated from others?    Thanks    Mickaël",2,1.8952621
XD-3721,XD Admin UI log out does not function properly,"I am using XD 1.2.1.RELEASE. I have following environment variables     XD_CONFIG_NAME = mycompany  And   SPRING_PROFILE_ACTIVE= prod, admin    i have XD configuration file (mycompany-prod.yml) with following security configuration    # Config to enable security on administration endpoints (consider adding ssl)  spring:    profiles: prod  security:    basic:      enabled: true # false to disable security settings (default)      realm: SpringXD  xd:    security:      authentication:        file:          enabled: true           users:            xdadmin: pwd, ROLE_ADMIN,ROLE_VIEW,ROLE_CREATE    I get a login screen, login works alright. When i logout - i still see all the tabs and contents in all the tabs. See the attached screenshot.  ",1,2.6065252
XD-3722,Admin UI does not respond after login in IE 11 ,I have IE 11. The XD admin UI stops responding after the login prompt and I have to kill the browser every time. It's not functional. I have not tried it with security turned off. Attach is the screenshot of the version.,1,3.598984
XD-3723,Improve support for custom headers when using Kafka Message Bus,"I understand Kafka natively does not have the concept of message headers. However, Spring Integration messages do and a lot of SI components are built specifically for dealing with message headers (header-enricher, header-filter, header-value-router, etc...). In addition, message headers are very useful for tracking meta-information about messages as they progress through a system.    With the implementation of https://jira.spring.io/browse/XD-3621; Spring XD has limited support for custom headers when using Kafka as a transport. I say limited, because it is required to list all custom headers explicitly in servers.yml in order for the headers to be retained by the MessageBus.    This is less than ideal because it means that it is necessary to know all potential custom header values a user will require before starting the environment.    It would be nice to extend this functionality so that it is not necessary to list custom headers in the configuration. Instead, when operating in mode=embeddedHeaders, Spring XD will simply embeds ALL headers in the Kafka message. Or alternatively, allow for a wildcard in the 'headers' configuration option so that it is not necessary to exhaustively list all possible custom header values prior to starting the system.",5,2.9628544
XD-3724,Add Job RDBMS config in Ambari plugin,Spring XD Ambari plugin only supports HDB as job db. HDB is not good in production environment. It will be great if we can specify RDB in spring xd installation/config process.   ,2,2.1628935
XD-3725,EmbeddedHeadersMessageConverter Buffer Overflow,See https://github.com/spring-projects/spring-xd/issues/1871,1,3.6699274
XD-3726,Processor module does not load classes from custom module package, The processor module which is failing to load castor classes from the module path.The code works fine with eclipse DIRT based test cases. I am attaching the code to this email. The jar that it built has the jars that it need at runtime in /module../lib folder.     The code worked fine when i put all the custom jars and application jar in xd/lib. Spoke to Thomas Risberg and confirm this is broken and need to be fixing.[^attachment-name.zip],5,2.6760423
XD-3727,xd.module.sequence Property Missing,Two separate reports of problems with this property:    http://stackoverflow.com/questions/34439296/spring-xd-stream-deployment-failure    http://stackoverflow.com/questions/34514393/issue-in-spring-xd-cluster-when-deploying-my-module,3,2.2829995
XD-3728,batch-hive module from spring-xd-samples project is not working,"***Version  	Spring XD Version : spring-xd-1.3.0.RELEASE, spring-xd-1.3.0.RELEASE-yarn  	OS & Version: Linux 2.6.32-431.29.2.el6.x86_64   	Java Version: java version ""1.7.0_65""    ***Description  	The batch-hive job in the spring-xd-samples project (link: https://github.com/spring-projects/spring-xd-samples/tree/master/batch-hive ) is failing with inline error message.    ***Steps to recreate the problem  1. Created a jar for batch-hive job.  	2. Once the final jar was ready, uploaded using ""module upload --name test_hive_module --type job --file /home/user/jar/batch_hive.jar""  3. After that created and deployed job using ""job create --name test_hive_job --definition test_hive_module --deploy""  	4. Finally launched using ""job launch test_hive_job"" which failed with inline error.    ***Describe XD Deployment : Distributed     Deployment Type : Distributed - YARN ( on AWS EC2 cloud )  Number of xd-admin’s and xd-container’s  : 1 Admin and 3 Containers       ***Describe Other Components    Transport: Redis 3.0.1  ZooKeeper: Version 3.4.6.2.3.2.0-2950      Hadoop deployment  Data Platform : Hortonworks HDP 2.3.2.0-2950  RDBMS: MySQL       ***Error Message:     *****************************************************  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'test_hive_job': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive': Cannot resolve reference to bean 'hive-tasklet' while setting bean property 'tasklet'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive-tasklet': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient          at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)          at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1481)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)          at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)          at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)          at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)          at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)          at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:753)          at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:835)          at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:537)          at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)          at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)          at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)          at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:213)          at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)          at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)          at org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365)          at org.springframework.xd.dirt.server.container.DeploymentListener.deployJobModule(DeploymentListener.java:291)          at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)          at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)          at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)          at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)          at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)          at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)          at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)          at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)          at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)          at java.util.concurrent.FutureTask.run(FutureTask.java:266)          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)          at java.util.concurrent.FutureTask.run(FutureTask.java:266)          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)          at java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'hive-tasklet': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:553)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)          at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)          at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)          at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)          at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)          at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)          ... 37 more  Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/service/HiveClient          at java.lang.Class.getDeclaredMethods0(Native Method)          at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)          at java.lang.Class.getDeclaredMethods(Class.java:1975)          at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:606)          at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:518)          at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:504)          at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:241)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1069)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)          at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305)          at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)          at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301)          at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:196)          at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)          at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1481)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1226)          at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)          ... 43 more  Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.service.HiveClient          at java.net.URLClassLoader.findClass(URLClassLoader.java:381)          at java.lang.ClassLoader.loadClass(ClassLoader.java:424)          at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)          at java.lang.ClassLoader.loadClass(ClassLoader.java:357)          ... 63 more  }  *****************************************************  ",5,2.0343394
XD-3729,Make module class loader or module available to implementation of custom module ,"Requirements: Make the class loader of the custom XD module available to the code of the custom module.    Javassist's toClass method uses the thread's local class loader to [load classes|https://jboss-javassist.github.io/javassist/html/javassist/CtClass.html#toClass--]. This is most definitely inappropriate in the case of Spring XD modules, since many classes come from the lib/ directory of the module. Those will produce a ClassDefNotFound exception in javassist.    Currently the ModuleFactory basically ""throws away"" the class loader, after generating it:    {code}  	private Module createSimpleModule(ModuleDescriptor moduleDescriptor, ModuleOptions moduleOptions,  			ModuleDeploymentProperties deploymentProperties) {  		if (log.isInfoEnabled()) {  			log.info(""creating simple module "" + moduleDescriptor);  		}  		SimpleModuleDefinition definition = (SimpleModuleDefinition) moduleDescriptor.getModuleDefinition();  		ClassLoader moduleClassLoader = ModuleUtils.createModuleRuntimeClassLoader(definition, moduleOptions, this.parentClassLoader);    		Class<? extends SimpleModule> moduleClass = determineModuleClass((SimpleModuleDefinition) moduleDescriptor.getModuleDefinition(),  				moduleOptions);  		Assert.notNull(moduleClass,  				String.format(""Required module artifacts are either missing or invalid. Unable to determine module type for module definition: '%s:%s'."",  						moduleDescriptor.getType(), moduleDescriptor.getModuleName()));  		return SimpleModuleCreator  				.createModule(moduleDescriptor, deploymentProperties, moduleClassLoader, moduleOptions, moduleClass);  	}  {code}    I think it would be sufficient if either the current module or the class loader itself could be injected into the custom classes of the custom XD module. As far as I can see I cannot get a grip on the Module instance in the current state of XD system.",3,2.3689954
XD-3730,NPE in spring-integration when using kafka as message bus when using aggrzgation module,as stated in https://jira.spring.io/browse/INT-3908 sprint-integration in springxd can't use kafka as message bus in most case. Could it spring-xd integrat this fix for us to use it?,3,2.2274127
XD-3731,Clean Up Compiler/Javadoc Warnings,"{noformat}  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:96: warning: [rawtypes] found raw type: DomainRepository  			DomainRepository instanceRepository, String jobName,  			^    missing type arguments for generic class DomainRepository<T,ID>    where T,ID are type-variables:      T extends Object declared in interface DomainRepository      ID extends Serializable,Comparable<ID> declared in interface DomainRepository  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:116: warning: [rawtypes] found raw type: DomainRepository  			DomainRepository instanceRepository, String jobName,  			^    missing type arguments for generic class DomainRepository<T,ID>    where T,ID are type-variables:      T extends Object declared in interface DomainRepository      ID extends Serializable,Comparable<ID> declared in interface DomainRepository  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:127: warning: [unchecked] unchecked conversion  		this.instanceRepository = instanceRepository;  		                          ^    required: DomainRepository<JobDefinition,String>    found:    DomainRepository  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/ModuleException.java:23: warning: [serial] serializable class ModuleException has no definition of serialVersionUID  public class ModuleException extends RuntimeException {         ^  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/support/ModuleDefinitionService.java:130: warning: [try] explicit call to close() on an auto-closeable resource  			target.close();  			      ^  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/StreamException.java:23: warning: [serial] serializable class StreamException has no definition of serialVersionUID  public class StreamException extends RuntimeException {         ^  /Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'value()' in type 'SuppressWarnings': class file for edu.umd.cs.findbugs.annotations.SuppressWarnings not found  /Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'justification()' in type 'SuppressWarnings'  3 warnings  /Users/grussell/Development/spring-xd/spring-xd-tuple/src/test/java/org/springframework/xd/tuple/TupleJsonMarshallerTests.java:77: warning: [unchecked] unchecked cast  		List<Tuple> body = (List<Tuple>) tuple.getValue(""body"");  		                                               ^    required: List<Tuple>    found:    Object  :api  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:151: warning - @return tag has no arguments.  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:166: warning - @return tag has no arguments.  /Users/grussell/Development/spring-xd/spring-xd-rest-domain/src/main/java/org/springframework/xd/rest/domain/JobExecutionInfoResource.java:252: warning - @return tag cannot be used in method with void return type.  /Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer  {noformat}",1,1.7340391
XD-3732,Overrides to servers.yml file aren't taken into account,"As a developer, I'm adding new overrides to {{server.yml}} file; however, the overridden properties do not reflect even after the restart of server. ",2,2.1958866
XD-3733,Document redis pool properties in servers.yml,"Add spring.redis.pool.*  properties to server.yml, commented out to show default values., e.g.,        maxIdle: 8,     minIdle: 0,      maxActive: 8,     maxWait: -1  ",1,1.47596
XD-3734,AutoBindDLQ Incompatible with Partitioned Streams (Producer Side).,See http://stackoverflow.com/questions/34817906/spring-xd-rabbitmq-partitioned-stream-deployment-in-failure,1,2.4972095
XD-3735,Splunk sink - add option to write to index ,Add option to write to Splunk named index as an alternative to tcp.,1,1.8400991
XD-3736,Rabbit Pub/Sub Consumers Should Support Concurrency,PubSub consumers can support concurrency since the threads are competing consumers on the queue.    ,2,2.9901938
XD-3737,REST - Do not redirect after logout,"In the following PR we removed the *RestLogoutSuccessHandler*.     https://github.com/spring-projects/spring-xd/pull/1562    This is necessary, though, for REST calls and the Admin UI. Otherwise some weird UI behavior might occur due to the HTTP redirect.",1,3.9298146
XD-3738,Encrypt secret information in XD configuration files,"Spring XD keeps passwords in text files such sas servers.yml, properties files, and module configuration files. Some users have requested a way to store encrypted values rather than clear text.  XD should provide a ""hook"" for users to provide a custom component to detect encrypted property values and decrypt them during container, admin, and module initialization.",2,3.4361126
XD-3739,Incorrect refresh period for groovy scripts,"All modules that allow groovy implementations (filter, script, transform, router, tcpclient) allow automatic refresh of the script when it changes. In the XD documentation it is stated that this refresh occurs every minute eg for filter at http://docs.spring.io/spring-xd/docs/1.3.0.RELEASE/reference/html/#filter ""The script is checked for updates every 60 seconds, so it may be replaced in a running system. ""     This set up can be seen in the spring xml for the modules - eg (again for filter)    {code:xml}  <filter input-channel=""to.script"" output-channel=""output"">  	<int-groovy:script location=""${script:filter.groovy}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/>  </filter>  {code}    However from the spring integration documentation http://docs.spring.io/spring-integration/docs/4.2.4.RELEASE/reference/html/messaging-endpoints-chapter.html#scripting-config  it specifies that the refresh-check-delay parameter is actually in milliseconds - ie the above XD configuration would recheck the script every 60 milliseconds which may be a performance concern as it will be checking the lastmodified time of the script file.     Ideally this parameter would be configurable - in our case we would usually eliminate the refresh check altogether (set to -1) as our scripts will not change (or if they did a redeploy of the module would pick it up)    ",5,3.0196238
XD-3740,Kafka message bus maxWait property is not set up,"The maxWait property from server.yml in the message bus section for kafka is not propagated through the code, it is ignored.",1,2.039894
XD-3741,[Flo] Stream creation/definitions doesn't show any component," As a Flo for Spring XD user, I would like to be able to create a new stream using the graphicat UI.     This flow should be shown in a graphical way also in definition tab.  !http://example.com/image.png!  Right now it doesn't happen due to a javascript error.    {code}  TypeError: this.node.getTransformToElement is not a function      at Object.VElement.bbox (http://localhost:9393/admin-ui/lib/joint/src/vectorizer.js:323:36)      at joint.dia.ElementView.joint.dia.CellView.extend.positionRelative (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2740:51)      at null.<anonymous> (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2710:18)      at http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1177:23      at eval (eval at createIterator (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1:0), <anonymous>:10:9)      at Function.forEach (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:3645:9)      at joint.dia.ElementView.joint.dia.CellView.extend.update (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2700:11)      at bound [as update] (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1005:21)      at joint.dia.ElementView.joint.dia.CellView.extend.render (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2903:14)      at joint.dia.Paper.Backbone.View.extend.addCell (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:5004:14)(anonymous function) @ :9393/admin-ui/lib/angular/angular.js:11500  :9393!attachment-name.jpg|thumbnail!  {code}  ",1,2.8106596
XD-3742,Enable in line SSL properties as an alternative to external properties files,The following XD components have been identified to support SSL via an `sslProperties` property which points to the location of a properties file. The properties encryption extension for 1.3.1 does not currently apply to these:      * Rabbit Message Bus    * Rabbit Source    * Rabbit Sink    * Http Source (NettyHttpInboundChannelAdapter).     This can be made to work in the case of Rabbit since the latest RabbitConnectionFactoryBean supports individual SSL properties settings as an alternative to the properties file. The http source may be extended to use the same approach.,3,3.333061
XD-3743,Update to Spring Integration 4.2.5 When Available (Fix Metrics),See INT-3956,1,1.9681678
XD-3744,Suppress DeliveryMode Header in RabbitMQ Source,"Related to XD-2567 which fixed this problem, but only in the bus.    {quote}  2016-02-19T18:25:24-0500 1.2.1.RELEASE WARN SimpleAsyncTaskExecutor-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]  {quote}",1,3.6875117
XD-3745,"Update Spring-AMQP to 3.6, RabbitMQ Client to 1.5.4",Update to amqp-client 3.6.0 and spring-amqp 1.5.4,1,1.4814459
XD-3746,Update Spring Framework to 4.2.4,,1,1.1067082
XD-3747,Rabbit Bus: Expose ChannelCacheSize on CachingConnectionFactory,http://stackoverflow.com/questions/35563064/processing-messages-through-namedchannels-with-prefetch-1/35584333#35584333,1,2.475894
XD-3748,Unable to register the JMX bean MessageHistory from Spring Integration,"If I try to use <int:message-history/> when developing a Spring XD module, it fails when try to export the JMX bean. I've seen that the naming strategy used is org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy    The stackTrace:  {code}  2016-02-24T10:40:39+0000 1.3.1.RELEASE ERROR DeploymentsPathChildrenCache-0 container.DeploymentListener - Exception deploying module  org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.history.MessageHistoryConfigurer@24902b5f] with key 'messageHistoryConfigurer'; nested exception is javax.management.MalformedObjectNameException: Key properties cannot be empty    org.springframework.integration.monitor.IntegrationMBeanExporter.registerBeanInstance(IntegrationMBeanExporter.java:375) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]    org.springframework.integration.monitor.IntegrationMBeanExporter.afterSingletonsInstantiated(IntegrationMBeanExporter.java:288) ~[spring-integration-jmx-4.2.5.RELEASE.jar:na]    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:792) ~[spring-beans-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.SpringApplication.run(SpringApplication.java:320) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) ~[spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:213) ~[spring-xd-module-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.deployStreamModule(DeploymentListener.java:334) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149) [spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92) [curator-framework-2.6.0.jar:na]    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) [guava-16.0.1.jar:na]    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83) [curator-framework-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35) [curator-recipes-2.6.0.jar:na]    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762) [curator-recipes-2.6.0.jar:na]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]    java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_72]    java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_72]    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_72]    java.lang.Thread.run(Thread.java:745) [na:1.8.0_72]  Caused by: javax.management.MalformedObjectNameException: Key properties cannot be empty    javax.management.ObjectName.construct(ObjectName.java:483) ~[na:1.8.0_72]    javax.management.ObjectName.<init>(ObjectName.java:1382) ~[na:1.8.0_72]    javax.management.ObjectName.getInstance(ObjectName.java:1273) ~[na:1.8.0_72]    org.springframework.jmx.support.ObjectNameManager.getInstance(ObjectNameManager.java:62) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]    org.springframework.xd.dirt.module.jmx.ModuleObjectNamingStrategy.getObjectName(ModuleObjectNamingStrategy.java:50) ~[spring-xd-dirt-1.3.1.RELEASE.jar:1.3.1.RELEASE]    org.springframework.jmx.export.MBeanExporter.getObjectName(MBeanExporter.java:751) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]  {code}",1,3.3202598
XD-3749,Provisioning of Custom input/output Converters is Broken,"Custom conversion is broken.    If the custom {{MimeType}} does not match any of those in {{MessageConverterUtils.getJavaTypeForContentType}} then the channel configuration fails with    {code}  			throw new ModuleConfigurationException(""Content type is not supported for "" +  					channel.getComponentName() + ""Type="" + contentType);  {code}    The code needs to consult custom converters to see what {{MimeType}} (s) they support - and the output Java type.      See http://stackoverflow.com/questions/35639975/adding-a-custom-type-converter-to-spring-xd",5,2.3802207
XD-3750,Cant completely remove custom module after putting properties in /config/modules/job/xx/xx.properties,"if we put a custom module static properties in `/config/modules/job/module-name/module-name.properties` then we cannot completely remove the module -  you can delete module but you cannot upload new jar with the same name as it gives an error  - there is module already with the same name.    May be important to note that we had a zookeeper data corruption on which support asked us to upgrade. We couldn't upgrade just yet, so I cleaned up zookeeper and recreated all streams/job from original scripts.     I have observed this behavior after the corruption - I cannot tell for sure if the behavior was there or not before the corruption. In case it is not easily reproducible then it could be environment specific issue.    I may update JIRA once i get time to try it on my local distributed mode.  ",1,3.6364045
XD-3751,gpfdist may fail to shutdown with backlog,"In a case where reactor's ringbuffer is full and thus handling backpressure by blocking `onNext`, shutdown phase where `onComplete` is send will cause a deadlock.    This is shown by a thread dump during a shutdown. This will basically break further deployments for this stream in distributed mode while single node will show more errors during undeployment.    {code}  ""pool-7-thread-1"" #58 prio=5 os_prio=0 tid=0x979fe800 nid=0x54de runnable [0x986ad000]     java.lang.Thread.State: TIMED_WAITING (parking)    sun.misc.Unsafe.park(Native Method)    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)    reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)    reactor.core.processor.util.RingBufferSubscriberUtils.onNext(RingBufferSubscriberUtils.java:30)    reactor.core.processor.RingBufferProcessor.onNext(RingBufferProcessor.java:575)  {code}    {code}  ""main-EventThread"" #19 daemon prio=5 os_prio=0 tid=0x9b93a400 nid=0x54b1 runnable [0x9aefe000]     java.lang.Thread.State: TIMED_WAITING (parking)    sun.misc.Unsafe.park(Native Method)    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:338)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:122)    reactor.jarjar.com.lmax.disruptor.SingleProducerSequencer.next(SingleProducerSequencer.java:97)    reactor.jarjar.com.lmax.disruptor.RingBuffer.next(RingBuffer.java:246)    reactor.core.processor.util.RingBufferSubscriberUtils.onComplete(RingBufferSubscriberUtils.java:54)    reactor.core.processor.RingBufferProcessor.onComplete(RingBufferProcessor.java:585)    org.springframework.xd.greenplum.gpfdist.GPFDistMessageHandler.doStop(GPFDistMessageHandler.java:170)  {code}    I've been crafting workaround for this by trying to wait reactor stream/buffer to get drained by gpdb and finally as last resort, forcing processor in reactor to shutdown.",5,1.8693994
XD-3752,Admin UI login Page failing to load due to require.js timeout - FE,"When i use the admin-ui web portal which runs on port 9393, there is a load timeout issue by require.js, failing to load the login screen. Could the team please look into this issue ASAP, or give me some other alternative !sping-ui-issue.png|thumbnail!",20,2.157068
XD-3753,"Add ""yarn.resourcemanager.scheduler.address"" to mapreduce samples","The MapReduce samples should have ""yarn.resourcemanager.scheduler.address"" since it might be needed in a multi node production cluster.",2,1.844964
XD-3754,Composed Module Child Module Validated Too Early,"{{module compose foo --definition ""time --fixedDelay=5 | shell --command=my.sh""}}    {code}  xd:>stream create bar --definition ""foo | log"" --deploy  Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module foo of type source:      command: may not be empty      command: may not be null  {code}    The problem stems from the fact that the options metadata validation is performed on the shell module before the property from the composed module is injected.    Disabling the validation annotations on the metadata avoids the problem.    {code}  //	@NotEmpty  //	@NotNull  public String getCommand() {  	return command;  }  {code}",5,3.2231174
XD-3755,Composed Modules Can't Have Duplicate Processors,"{code}  xd:>module compose foo --definition ""time --fixedDelay=5 | t1:transform --expression=payload+'a' | t2:transform --expression=payload.toUpperCase()  {code}    Produces {{2016-05-02 17:27:20aa}} - the first transform is applied twice.  ",5,3.0703516
XD-3756,wordcount failed to run in cloudera VM 5.7,"I download the spring XD example projects, and run through the steps acccording the README file for the project. I tried to change the hadoop-site.xml, server.yml and wordcount.xml files, but I failed get the . I am blocked by this issue. Thank you very much in advance for help. Best Regards.",3,2.8476098
XD-3757,Dead Letter is not created on all RabbitMQ queues for partionned stream,"Hi,    If I use the module.[name].producer.paritionKeyExpression, and the module as also autoBindDLG enabled, the creates RabbbitMQ queues do not have the DeadLetter policy.  The first queue has it (xdbus.<stream>.0-0) but others do not have it (xdbus.<stream>.0-N).    Thanks    Mickaël    ",4,2.980548
XD-3758,flo don't work,"i  unzip flo-spring-xd-admin-ui-client-1.3.1.RELEASE.jar to replace the existing spring-xd-admin-ui-client-1.3.1.RELEASE.jar,and clear my browser cache  then restart the  xd-singlenode，but i can't access Flo for Spring XD at the following URI endpoints :http://HOST_NAME:PORT/admin-ui/#/streams/create , i can't find the ""flo"" page!  ",4,3.511294
XD-3759,Composed job endpoint is missing from the defined authorization rules,More details in the support ticket: https://issuetracker.springsource.com/browse/VESC-679    Following entires should be added to {{application.yml}} file.    {code}          - POST   /tools/parseJobToGraph                      => hasRole('ROLE_CREATE')          - POST   /tools/parseJobToGraph.*                   => hasRole('ROLE_CREATE')          - POST   /tools/convertJobGraphToText            => hasRole('ROLE_CREATE')          - POST   /tools/convertJobGraphToText.*          => hasRole('ROLE_CREATE')  {code},1,2.6197221
