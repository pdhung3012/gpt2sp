{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27e9908",
   "metadata": {},
   "source": [
    "### ABE0 with Hyperopt - Within Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e91eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 32/32 [00:33<00:00,  1.06s/trial, best loss: 1.5335119047619048]\n",
      "100%|████████████████████████████████████████████████| 32/32 [00:11<00:00,  2.81trial/s, best loss: 0.9992291905307369]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [01:41<00:00,  3.17s/trial, best loss: 2.392136622101083]\n",
      "100%|████████████████████████████████████████████████| 32/32 [01:54<00:00,  3.57s/trial, best loss: 2.3625957943189797]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:48<00:00,  1.51s/trial, best loss: 3.462289600863719]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:28<00:00,  1.11trial/s, best loss: 4.240739686016794]\n",
      "100%|████████████████████████████████████████████████| 32/32 [00:18<00:00,  1.69trial/s, best loss: 2.6912651558433316]\n",
      "100%|████████████████████████████████████████████████| 32/32 [00:22<00:00,  1.45trial/s, best loss: 3.7320596636119645]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    reg = KNeighborsRegressor(**params)\n",
    "    mae = cross_val_score(reg, X_train, y_train, scoring='neg_mean_absolute_error').mean()\n",
    "    # fmin() tries to minimize the objective, so we need to redirect neg_mean_absolute_error with \"-\"\n",
    "    return {'loss': -mae, 'status': STATUS_OK}\n",
    "\n",
    "SEARCH_SPACE = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'n_neighbors': hp.choice('n_neighbors', list(np.arange(2, 10+1, 1, dtype=int))),\n",
    "        'weights': hp.choice('weights', ['uniform', 'distance']),\n",
    "        'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "        'leaf_size': hp.choice('leaf_size', list(np.arange(10, 50+1, 10, dtype=int))),\n",
    "        'p': hp.choice('p', list(np.arange(1, 2+1, 1, dtype=int))),\n",
    "        'n_jobs': hp.choice('n_jobs', [16])\n",
    "    }\n",
    "])\n",
    "\n",
    "PATH = \"../sp_dataset/marked_data/\"\n",
    "# cross project - within repo\n",
    "WITHIN_REPO = [\n",
    "                {'train': ['mesos'], 'test': ['usergrid']},\n",
    "                {'train': ['usergrid'], 'test': ['mesos']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
    "                {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
    "                {'train': ['aptanastudio'], 'test': ['titanium']},\n",
    "                {'train': ['mule'], 'test': ['mulestudio']},\n",
    "                {'train': ['mulestudio'], 'test': ['mule']}\n",
    "              ]\n",
    "\n",
    "report = []\n",
    "for pair in WITHIN_REPO:\n",
    "    # split to 60% training and 40% validation\n",
    "    data = pd.read_csv(PATH + pair[\"train\"][0] + \".csv\")\n",
    "    \n",
    "    train_data = data[: int(len(data)*0.6)]\n",
    "    train_data = data\n",
    "    \n",
    "    X_train = train_data[\"title\"].tolist()\n",
    "    y_train = train_data[\"storypoint\"].tolist()\n",
    "    val_data = data[int(len(data)*0.6):]\n",
    "\n",
    "    test_data = pd.read_csv(PATH + pair[\"test\"][0] + \".csv\")\n",
    "    X_test = test_data[\"title\"].tolist()\n",
    "    y_test = np.array(test_data[\"storypoint\"].tolist())\n",
    "    \n",
    "    # apply BoW feature extraction\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    vectorizer = vectorizer.fit(X_train)\n",
    "    vectorizer = vectorizer.fit(X_test)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "\n",
    "    algo = tpe.suggest\n",
    "    with mlflow.start_run():\n",
    "        best_result = fmin(fn=objective, \n",
    "                           space=SEARCH_SPACE,\n",
    "                           algo=algo,\n",
    "                           max_evals=32)\n",
    "    best_model = hyperopt.space_eval(SEARCH_SPACE, best_result)    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=best_model['n_neighbors'],\n",
    "                                weights=best_model['weights'],\n",
    "                                algorithm=best_model['algorithm'],\n",
    "                                leaf_size=best_model['leaf_size'],\n",
    "                                p=best_model['p'])\n",
    "    neigh.fit(X_train, y_train)\n",
    "    preds = neigh.predict(X_test)\n",
    "    mae = round(sum(abs(preds - y_test)) / len(preds), 2)\n",
    "    report.append(f\"\"\"Train {pair[\"train\"][0]} | Test {pair[\"test\"][0]}: {mae}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c19da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mesos | Test usergrid: 1.19\n",
      "Train usergrid | Test mesos: 1.57\n",
      "Train appceleratorstudio | Test aptanastudio: 4.22\n",
      "Train appceleratorstudio | Test titanium: 3.45\n",
      "Train titanium | Test appceleratorstudio: 2.45\n",
      "Train aptanastudio | Test titanium: 4.16\n",
      "Train mule | Test mulestudio: 3.45\n",
      "Train mulestudio | Test mule: 2.93\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "train_file = []\n",
    "test_file = []\n",
    "\n",
    "for record in report:\n",
    "    print(record)\n",
    "    train_file.append(record.split(\" \")[1])\n",
    "    test_file.append(record.split(\" \")[4].strip(\":\"))\n",
    "    mae_val = record.split(\":\")[-1]\n",
    "    mae_val = float(mae_val.strip())\n",
    "    maes.append(mae_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb7d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"train_file\": train_file,\n",
    "                   \"test_file\": test_file,\n",
    "                   \"mae\": maes}).to_csv(\"within_repo_abe0_hyperopt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976877c",
   "metadata": {},
   "source": [
    "### ABE0 with Hyperopt - Cross Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca69c44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 32/32 [00:15<00:00,  2.04trial/s, best loss: 3.4074143829663925]\n",
      "100%|████████████████████████████████████████████████| 32/32 [00:23<00:00,  1.35trial/s, best loss: 1.0738987442694836]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:39<00:00,  1.25s/trial, best loss: 3.831566938151462]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:30<00:00,  1.06trial/s, best loss: 2.839010982035168]\n",
      "100%|████████████████████████████████████████████████| 32/32 [01:02<00:00,  1.96s/trial, best loss: 3.7783367168756854]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [00:43<00:00,  1.35s/trial, best loss: 4.383114341627062]\n",
      "100%|████████████████████████████████████████████████| 32/32 [01:33<00:00,  2.92s/trial, best loss: 2.3658354284640146]\n",
      "100%|█████████████████████████████████████████████████| 32/32 [01:17<00:00,  2.42s/trial, best loss: 2.324721680490613]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    reg = KNeighborsRegressor(**params)\n",
    "    mae = cross_val_score(reg, X_train, y_train, scoring='neg_mean_absolute_error').mean()\n",
    "    # fmin() tries to minimize the objective, so we need to redirect neg_mean_absolute_error with \"-\"\n",
    "    return {'loss': -mae, 'status': STATUS_OK}\n",
    "\n",
    "SEARCH_SPACE = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'n_neighbors': hp.choice('n_neighbors', list(np.arange(2, 10+1, 1, dtype=int))),\n",
    "        'weights': hp.choice('weights', ['uniform', 'distance']),\n",
    "        'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "        'leaf_size': hp.choice('leaf_size', list(np.arange(10, 50+1, 10, dtype=int))),\n",
    "        'p': hp.choice('p', list(np.arange(1, 2+1, 1, dtype=int))),\n",
    "        'n_jobs': hp.choice('n_jobs', [16])\n",
    "    }\n",
    "])\n",
    "\n",
    "PATH = \"../sp_dataset/marked_data/\"\n",
    "\n",
    "# cross project - cross repo\n",
    "CROSS_REPO = [\n",
    "                {'train': ['clover'], 'test': ['usergrid']},\n",
    "                {'train': ['talendesb'], 'test': ['mesos']},\n",
    "                {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
    "                {'train': ['mule'], 'test': ['titanium']},\n",
    "                {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
    "                {'train': ['mulestudio'], 'test': ['titanium']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
    "             ]\n",
    "report = []\n",
    "for pair in CROSS_REPO:\n",
    "    # split to 60% training and 40% validation\n",
    "    data = pd.read_csv(PATH + pair[\"train\"][0] + \".csv\")\n",
    "    \n",
    "    train_data = data[: int(len(data)*0.6)]\n",
    "    train_data = data\n",
    "    \n",
    "    X_train = train_data[\"title\"].tolist()\n",
    "    y_train = train_data[\"storypoint\"].tolist()\n",
    "    val_data = data[int(len(data)*0.6):]\n",
    "\n",
    "    test_data = pd.read_csv(PATH + pair[\"test\"][0] + \".csv\")\n",
    "    X_test = test_data[\"title\"].tolist()\n",
    "    y_test = np.array(test_data[\"storypoint\"].tolist())\n",
    "    \n",
    "    # apply BoW feature extraction\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    vectorizer = vectorizer.fit(X_train)\n",
    "    vectorizer = vectorizer.fit(X_test)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "\n",
    "    algo = tpe.suggest\n",
    "    with mlflow.start_run():\n",
    "        best_result = fmin(fn=objective, \n",
    "                           space=SEARCH_SPACE,\n",
    "                           algo=algo,\n",
    "                           max_evals=32)\n",
    "    best_model = hyperopt.space_eval(SEARCH_SPACE, best_result)    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=best_model['n_neighbors'],\n",
    "                                weights=best_model['weights'],\n",
    "                                algorithm=best_model['algorithm'],\n",
    "                                leaf_size=best_model['leaf_size'],\n",
    "                                p=best_model['p'])\n",
    "    neigh.fit(X_train, y_train)\n",
    "    preds = neigh.predict(X_test)\n",
    "    mae = round(sum(abs(preds - y_test)) / len(preds), 2)\n",
    "    report.append(f\"\"\"Train {pair[\"train\"][0]} | Test {pair[\"test\"][0]}: {mae}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57be655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train clover | Test usergrid: 1.51\n",
      "Train talendesb | Test mesos: 1.57\n",
      "Train talenddataquality | Test aptanastudio: 4.2\n",
      "Train mule | Test titanium: 3.32\n",
      "Train talenddataquality | Test appceleratorstudio: 2.7\n",
      "Train mulestudio | Test titanium: 4.73\n",
      "Train appceleratorstudio | Test mulestudio: 3.51\n",
      "Train appceleratorstudio | Test mule: 2.71\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "train_file = []\n",
    "test_file = []\n",
    "\n",
    "for record in report:\n",
    "    print(record)\n",
    "    train_file.append(record.split(\" \")[1])\n",
    "    test_file.append(record.split(\" \")[4].strip(\":\"))\n",
    "    mae_val = record.split(\":\")[-1]\n",
    "    mae_val = float(mae_val.strip())\n",
    "    maes.append(mae_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0766bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"train_file\": train_file,\n",
    "                   \"test_file\": test_file,\n",
    "                   \"mae\": maes}).to_csv(\"cross_repo_abe0_hyperopt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5ede7",
   "metadata": {},
   "source": [
    "### ABE0 without Hyperopt - Within Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e856c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PATH = \"../sp_dataset/marked_data/\"\n",
    "# cross project - within repo\n",
    "WITHIN_REPO = [\n",
    "                {'train': ['mesos'], 'test': ['usergrid']},\n",
    "                {'train': ['usergrid'], 'test': ['mesos']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['aptanastudio']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['titanium']},\n",
    "                {'train': ['titanium'], 'test': ['appceleratorstudio']},\n",
    "                {'train': ['aptanastudio'], 'test': ['titanium']},\n",
    "                {'train': ['mule'], 'test': ['mulestudio']},\n",
    "                {'train': ['mulestudio'], 'test': ['mule']}\n",
    "              ]\n",
    "\n",
    "report = []\n",
    "for pair in WITHIN_REPO:\n",
    "    # split to 60% training and 40% validation\n",
    "    data = pd.read_csv(PATH + pair[\"train\"][0] + \".csv\")\n",
    "    \n",
    "    train_data = data[: int(len(data)*0.6)]\n",
    "    train_data = data\n",
    "    \n",
    "    X_train = train_data[\"title\"].tolist()\n",
    "    y_train = train_data[\"storypoint\"].tolist()\n",
    "    val_data = data[int(len(data)*0.6):]\n",
    "\n",
    "    test_data = pd.read_csv(PATH + pair[\"test\"][0] + \".csv\")\n",
    "    X_test = test_data[\"title\"].tolist()\n",
    "    y_test = np.array(test_data[\"storypoint\"].tolist())\n",
    "    \n",
    "    # apply BoW feature extraction\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    vectorizer = vectorizer.fit(X_train)\n",
    "    vectorizer = vectorizer.fit(X_test)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    preds = neigh.predict(X_test)\n",
    "    mae = round(sum(abs(preds - y_test)) / len(preds), 2)\n",
    "    report.append(f\"\"\"Train {pair[\"train\"][0]} | Test {pair[\"test\"][0]}: {mae}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f502b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mesos | Test usergrid: 1.24\n",
      "Train usergrid | Test mesos: 1.63\n",
      "Train appceleratorstudio | Test aptanastudio: 4.27\n",
      "Train appceleratorstudio | Test titanium: 3.61\n",
      "Train titanium | Test appceleratorstudio: 2.62\n",
      "Train aptanastudio | Test titanium: 3.6\n",
      "Train mule | Test mulestudio: 3.82\n",
      "Train mulestudio | Test mule: 3.04\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "train_file = []\n",
    "test_file = []\n",
    "\n",
    "for record in report:\n",
    "    print(record)\n",
    "    train_file.append(record.split(\" \")[1])\n",
    "    test_file.append(record.split(\" \")[4].strip(\":\"))\n",
    "    mae_val = record.split(\":\")[-1]\n",
    "    mae_val = float(mae_val.strip())\n",
    "    maes.append(mae_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdfe7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"train_file\": train_file,\n",
    "                   \"test_file\": test_file,\n",
    "                   \"mae\": maes}).to_csv(\"within_repo_abe0_no_hyperopt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4304e",
   "metadata": {},
   "source": [
    "### ABE0 without Hyperopt - Cross Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d713007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PATH = \"../sp_dataset/marked_data/\"\n",
    "\n",
    "# cross project - cross repo\n",
    "CROSS_REPO = [\n",
    "                {'train': ['clover'], 'test': ['usergrid']},\n",
    "                {'train': ['talendesb'], 'test': ['mesos']},\n",
    "                {'train': ['talenddataquality'], 'test': ['aptanastudio']},\n",
    "                {'train': ['mule'], 'test': ['titanium']},\n",
    "                {'train': ['talenddataquality'], 'test': ['appceleratorstudio']},\n",
    "                {'train': ['mulestudio'], 'test': ['titanium']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['mulestudio']},\n",
    "                {'train': ['appceleratorstudio'], 'test': ['mule']}\n",
    "             ]\n",
    "\n",
    "report = []\n",
    "for pair in CROSS_REPO:\n",
    "    # split to 60% training and 40% validation\n",
    "    data = pd.read_csv(PATH + pair[\"train\"][0] + \".csv\")\n",
    "    \n",
    "    train_data = data[: int(len(data)*0.6)]\n",
    "    train_data = data\n",
    "    \n",
    "    X_train = train_data[\"title\"].tolist()\n",
    "    y_train = train_data[\"storypoint\"].tolist()\n",
    "    val_data = data[int(len(data)*0.6):]\n",
    "\n",
    "    test_data = pd.read_csv(PATH + pair[\"test\"][0] + \".csv\")\n",
    "    X_test = test_data[\"title\"].tolist()\n",
    "    y_test = np.array(test_data[\"storypoint\"].tolist())\n",
    "    \n",
    "    # apply BoW feature extraction\n",
    "    vectorizer = TfidfVectorizer(norm='l2')\n",
    "    vectorizer = vectorizer.fit(X_train)\n",
    "    vectorizer = vectorizer.fit(X_test)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    preds = neigh.predict(X_test)\n",
    "    mae = round(sum(abs(preds - y_test)) / len(preds), 2)\n",
    "    report.append(f\"\"\"Train {pair[\"train\"][0]} | Test {pair[\"test\"][0]}: {mae}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655221fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train clover | Test usergrid: 1.02\n",
      "Train talendesb | Test mesos: 1.56\n",
      "Train talenddataquality | Test aptanastudio: 4.05\n",
      "Train mule | Test titanium: 3.62\n",
      "Train talenddataquality | Test appceleratorstudio: 3.18\n",
      "Train mulestudio | Test titanium: 8.13\n",
      "Train appceleratorstudio | Test mulestudio: 3.58\n",
      "Train appceleratorstudio | Test mule: 3.27\n"
     ]
    }
   ],
   "source": [
    "maes = []\n",
    "train_file = []\n",
    "test_file = []\n",
    "\n",
    "for record in report:\n",
    "    print(record)\n",
    "    train_file.append(record.split(\" \")[1])\n",
    "    test_file.append(record.split(\" \")[4].strip(\":\"))\n",
    "    mae_val = record.split(\":\")[-1]\n",
    "    mae_val = float(mae_val.strip())\n",
    "    maes.append(mae_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c811f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\"train_file\": train_file,\n",
    "                   \"test_file\": test_file,\n",
    "                   \"mae\": maes}).to_csv(\"cross_repo_abe0_no_hyperopt.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
